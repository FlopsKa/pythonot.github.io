

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Python modules &mdash; POT Python Optimal Transport 0.7.0b documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery-dataframe.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="POT Examples" href="auto_examples/index.html" />
    <link rel="prev" title="Quick start guide" href="quickstart.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> POT Python Optimal Transport
          

          
          </a>

          
            
            
              <div class="version">
                0.7.0b
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">POT: Python Optimal Transport</a></li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quick start guide</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Python modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-ot">ot</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-ot.lp">ot.lp</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-ot.bregman">ot.bregman</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ot-smooth">ot.smooth</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-ot.gromov">ot.gromov</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-ot.optim">ot.optim</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-ot.da">ot.da</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ot-gpu">ot.gpu</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-ot.dr">ot.dr</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-ot.utils">ot.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-ot.datasets">ot.datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-ot.plot">ot.plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-ot.stochastic">ot.stochastic</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-ot.unbalanced">ot.unbalanced</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-ot.partial">ot.partial</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="auto_examples/index.html">POT Examples</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">POT Python Optimal Transport</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Python modules</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/all.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="python-modules">
<h1>Python modules<a class="headerlink" href="#python-modules" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-ot">
<span id="ot"></span><h2>ot<a class="headerlink" href="#module-ot" title="Permalink to this headline">¶</a></h2>
<p>This is the main module of the POT toolbox. It provides easy access to
a number of sub-modules and functions described below.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Here is a list of the submodules and short description of what they contain.</p>
<ul class="simple">
<li><p><a class="reference internal" href="#module-ot.lp" title="ot.lp"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ot.lp</span></code></a> contains OT solvers for the exact (Linear Program) OT problems.</p></li>
<li><p><a class="reference internal" href="#module-ot.bregman" title="ot.bregman"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ot.bregman</span></code></a> contains OT solvers for the entropic OT problems using
Bregman projections.</p></li>
<li><p><a class="reference internal" href="#module-ot.lp" title="ot.lp"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ot.lp</span></code></a> contains OT solvers for the exact (Linear Program) OT problems.</p></li>
<li><p><a class="reference internal" href="#module-ot.smooth" title="ot.smooth"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ot.smooth</span></code></a> contains OT solvers for the regularized (l2 and kl) smooth OT
problems.</p></li>
<li><p><a class="reference internal" href="#module-ot.gromov" title="ot.gromov"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ot.gromov</span></code></a> contains solvers for Gromov-Wasserstein and Fused Gromov
Wasserstein problems.</p></li>
<li><p><a class="reference internal" href="#module-ot.optim" title="ot.optim"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ot.optim</span></code></a> contains generic solvers OT based optimization problems</p></li>
<li><p><a class="reference internal" href="#module-ot.da" title="ot.da"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ot.da</span></code></a> contains classes and function related to Monge mapping
estimation and Domain Adaptation (DA).</p></li>
<li><p><code class="xref any docutils literal notranslate"><span class="pre">ot.gpu</span></code> contains GPU (cupy) implementation of some OT solvers</p></li>
<li><p><a class="reference internal" href="#module-ot.dr" title="ot.dr"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ot.dr</span></code></a> contains Dimension Reduction (DR) methods such as Wasserstein
Discriminant Analysis.</p></li>
<li><p><a class="reference internal" href="#module-ot.utils" title="ot.utils"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ot.utils</span></code></a> contains utility functions such as distance computation and
timing.</p></li>
<li><p><a class="reference internal" href="#module-ot.datasets" title="ot.datasets"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ot.datasets</span></code></a> contains toy dataset generation functions.</p></li>
<li><p><a class="reference internal" href="#module-ot.plot" title="ot.plot"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ot.plot</span></code></a> contains visualization functions</p></li>
<li><p><a class="reference internal" href="#module-ot.stochastic" title="ot.stochastic"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ot.stochastic</span></code></a> contains stochastic solvers for regularized OT.</p></li>
<li><p><a class="reference internal" href="#module-ot.unbalanced" title="ot.unbalanced"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ot.unbalanced</span></code></a> contains solvers for regularized unbalanced OT.</p></li>
<li><p><a class="reference internal" href="#module-ot.partial" title="ot.partial"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ot.partial</span></code></a> contains solvers for partial OT.</p></li>
</ul>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The list of automatically imported sub-modules is as follows:
<a class="reference internal" href="#module-ot.lp" title="ot.lp"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ot.lp</span></code></a>, <a class="reference internal" href="#module-ot.bregman" title="ot.bregman"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ot.bregman</span></code></a>, <a class="reference internal" href="#module-ot.optim" title="ot.optim"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ot.optim</span></code></a>
<a class="reference internal" href="#module-ot.utils" title="ot.utils"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ot.utils</span></code></a>, <a class="reference internal" href="#module-ot.datasets" title="ot.datasets"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ot.datasets</span></code></a>,
<a class="reference internal" href="#module-ot.gromov" title="ot.gromov"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ot.gromov</span></code></a>, <a class="reference internal" href="#module-ot.smooth" title="ot.smooth"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ot.smooth</span></code></a>
<a class="reference internal" href="#module-ot.stochastic" title="ot.stochastic"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ot.stochastic</span></code></a></p>
<p>The following sub-modules are not imported due to additional dependencies:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#module-ot.dr" title="ot.dr"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ot.dr</span></code></a> : depends on <code class="code docutils literal notranslate"><span class="pre">pymanopt</span></code> and <code class="code docutils literal notranslate"><span class="pre">autograd</span></code>.</p></li>
<li><p><code class="xref any docutils literal notranslate"><span class="pre">ot.gpu</span></code> : depends on <code class="code docutils literal notranslate"><span class="pre">cupy</span></code> and a CUDA GPU.</p></li>
<li><p><a class="reference internal" href="#module-ot.plot" title="ot.plot"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">ot.plot</span></code></a> : depends on <code class="code docutils literal notranslate"><span class="pre">matplotlib</span></code></p></li>
</ul>
</div>
<dl class="py function">
<dt id="ot.emd">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">emd</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">100000</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">center_dual</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/lp.html#emd"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.emd" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the Earth Movers distance problem and returns the OT matrix</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F\\s.t. \gamma 1 = a
     \gamma^T 1= b
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the metric cost matrix</p></li>
<li><p>a and b are the sample weights</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Note that the M matrix needs to be a C-order numpy.array in float64
format.</p>
</div>
<p>Uses the algorithm proposed in <a href="#id224"><span class="problematic" id="id1">[1]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>(</em><em>ns</em><em>,</em><em>) </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><em>float64</em>) – Source histogram (uniform weight if empty list)</p></li>
<li><p><strong>b</strong> (<em>(</em><em>nt</em><em>,</em><em>) </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><em>float64</em>) – Target histogram (uniform weight if empty list)</p></li>
<li><p><strong>M</strong> (<em>(</em><em>ns</em><em>,</em><em>nt</em><em>) </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><em>float64</em>) – Loss matrix (c-order array with type float64)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=100000</em><em>)</em>) – The maximum number of iterations before stopping the optimization
algorithm if it has not converged.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If True, returns a dictionary containing the cost and dual
variables. Otherwise returns only the optimal transportation matrix.</p></li>
<li><p><strong>center_dual</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, centers the dual potential using function
<span class="xref std std-ref">center_ot_dual</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) numpy.ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – If input log is true, a dictionary containing the cost and dual
variables and exit status</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Simple example with obvious solution. The function emd accepts lists and
perform automatic conversion to numpy arrays</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span><span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span><span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span><span class="mf">1.</span><span class="p">],[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">emd</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">M</span><span class="p">)</span>
<span class="go">array([[0.5, 0. ],</span>
<span class="go">       [0. , 0.5]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id2"><span class="brackets">1</span></dt>
<dd><p>Bonneel, N., Van De Panne, M., Paris, S., &amp; Heidrich, W.
(2011, December).  Displacement interpolation using Lagrangian mass
transport. In ACM Transactions on Graphics (TOG) (Vol. 30, No. 6, p.
158). ACM.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.bregman.sinkhorn" title="ot.bregman.sinkhorn"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn()</span></code></a></dt><dd><p>Entropic regularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.emd2">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">emd2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">processes</span><span class="o">=</span><span class="default_value">36</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">100000</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">return_matrix</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">center_dual</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/lp.html#emd2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.emd2" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the Earth Movers distance problem and returns the loss</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F\\s.t. \gamma 1 = a
     \gamma^T 1= b
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the metric cost matrix</p></li>
<li><p>a and b are the sample weights</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Note that the M matrix needs to be a C-order numpy.array in float64
format.</p>
</div>
<p>Uses the algorithm proposed in <a href="#id225"><span class="problematic" id="id3">[1]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>(</em><em>ns</em><em>,</em><em>) </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><em>float64</em>) – Source histogram (uniform weight if empty list)</p></li>
<li><p><strong>b</strong> (<em>(</em><em>nt</em><em>,</em><em>) </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><em>float64</em>) – Target histogram (uniform weight if empty list)</p></li>
<li><p><strong>M</strong> (<em>(</em><em>ns</em><em>,</em><em>nt</em><em>) </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><em>float64</em>) – Loss matrix (c-order array with type float64)</p></li>
<li><p><strong>processes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=nb cpu</em><em>)</em>) – Nb of processes used for multiple emd computation (not used on windows)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=100000</em><em>)</em>) – The maximum number of iterations before stopping the optimization
algorithm if it has not converged.</p></li>
<li><p><strong>log</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If True, returns a dictionary containing the cost and dual
variables. Otherwise returns only the optimal transportation cost.</p></li>
<li><p><strong>return_matrix</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If True, returns the optimal transportation matrix in the log.</p></li>
<li><p><strong>dense</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, returns math:<cite>gamma</cite> as a dense ndarray of shape (ns, nt).
Otherwise returns a sparse representation using scipy’s <cite>coo_matrix</cite>
format.</p></li>
<li><p><strong>center_dual</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, centers the dual potential using function
<span class="xref std std-ref">center_ot_dual</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dictnp</em>) – If input log is true, a dictionary containing the cost and dual
variables and exit status</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Simple example with obvious solution. The function emd accepts lists and
perform automatic conversion to numpy arrays</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span><span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span><span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span><span class="mf">1.</span><span class="p">],[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">emd2</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">M</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id4"><span class="brackets">1</span></dt>
<dd><p>Bonneel, N., Van De Panne, M., Paris, S., &amp; Heidrich, W.
(2011, December).  Displacement interpolation using Lagrangian mass
transport. In ACM Transactions on Graphics (TOG) (Vol. 30, No. 6, p.
158). ACM.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.bregman.sinkhorn" title="ot.bregman.sinkhorn"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn()</span></code></a></dt><dd><p>Entropic regularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.emd_1d">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">emd_1d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x_a</span></em>, <em class="sig-param"><span class="n">x_b</span></em>, <em class="sig-param"><span class="n">a</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">b</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">'sqeuclidean'</span></em>, <em class="sig-param"><span class="n">p</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">dense</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/lp.html#emd_1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.emd_1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the Earth Movers distance problem between 1d measures and returns
the OT matrix</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma \sum_i \sum_j \gamma_{ij} d(x_a[i], x_b[j])\\s.t. \gamma 1 = a,
     \gamma^T 1= b,
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>d is the metric</p></li>
<li><p>x_a and x_b are the samples</p></li>
<li><p>a and b are the sample weights</p></li>
</ul>
<p>When ‘minkowski’ is used as a metric, <span class="math notranslate nohighlight">\(d(x, y) = |x - y|^p\)</span>.</p>
<p>Uses the algorithm detailed in <a href="#id226"><span class="problematic" id="id5">[1]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_a</strong> (<em>(</em><em>ns</em><em>,</em><em>) or </em><em>(</em><em>ns</em><em>, </em><em>1</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em>) – Source dirac locations (on the real line)</p></li>
<li><p><strong>x_b</strong> (<em>(</em><em>nt</em><em>,</em><em>) or </em><em>(</em><em>ns</em><em>, </em><em>1</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em>) – Target dirac locations (on the real line)</p></li>
<li><p><strong>a</strong> (<em>(</em><em>ns</em><em>,</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em><em>, </em><em>optional</em>) – Source histogram (default is uniform weight)</p></li>
<li><p><strong>b</strong> (<em>(</em><em>nt</em><em>,</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em><em>, </em><em>optional</em>) – Target histogram (default is uniform weight)</p></li>
<li><p><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='sqeuclidean'</em><em>)</em>) – Metric to be used. Only strings listed in <a class="reference internal" href="#ot.dist" title="ot.dist"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.dist()</span></code></a> are accepted.
Due to implementation details, this function runs faster when
<cite>‘sqeuclidean’</cite>, <cite>‘cityblock’</cite>,  or <cite>‘euclidean’</cite> metrics are used.</p></li>
<li><p><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1.0</em><em>)</em>) – The p-norm to apply for if metric=’minkowski’</p></li>
<li><p><strong>dense</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, returns math:<cite>gamma</cite> as a dense ndarray of shape (ns, nt).
Otherwise returns a sparse representation using scipy’s <cite>coo_matrix</cite>
format. Due to implementation details, this function runs faster when
<cite>‘sqeuclidean’</cite>, <cite>‘minkowski’</cite>, <cite>‘cityblock’</cite>,  or <cite>‘euclidean’</cite> metrics
are used.</p></li>
<li><p><strong>log</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If True, returns a dictionary containing the cost.
Otherwise returns only the optimal transportation matrix.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns, nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – If input log is True, a dictionary containing the cost</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Simple example with obvious solution. The function emd_1d accepts lists and
performs automatic conversion to numpy arrays</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_a</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_b</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">emd_1d</span><span class="p">(</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="go">array([[0. , 0.5],</span>
<span class="go">       [0.5, 0. ]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">emd_1d</span><span class="p">(</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">)</span>
<span class="go">array([[0. , 0.5],</span>
<span class="go">       [0.5, 0. ]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id6"><span class="brackets">1</span></dt>
<dd><p>Peyré, G., &amp; Cuturi, M. (2017). “Computational Optimal
Transport”, 2018.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>EMD for multidimensional distributions</p>
</dd>
<dt><a class="reference internal" href="#ot.lp.emd2_1d" title="ot.lp.emd2_1d"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd2_1d()</span></code></a></dt><dd><p>EMD for 1d distributions (returns cost instead of the transportation matrix)</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.sinkhorn">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">sinkhorn</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'sinkhorn'</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#sinkhorn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.sinkhorn" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the entropic regularization optimal transport problem and return the OT matrix</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (dim_a, dim_b) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p>a and b are source and target weights (histograms, both sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the Sinkhorn-Knopp matrix scaling algorithm as proposed in <a href="#id227"><span class="problematic" id="id7">[2]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_b</em><em>,</em><em>) or </em><em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_b</em><em>, </em><em>n_hists</em><em>)</em>) – samples in the target domain, compute sinkhorn with multiple targets
and fixed M if b is a matrix (return OT loss + dual variables in log)</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – method used for the solver either ‘sinkhorn’, ‘greenkhorn’, ‘sinkhorn_stabilized’ or
‘sinkhorn_epsilon_scaling’, see those function for specific parameters</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>ndarray, shape (dim_a, dim_b)</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">sinkhorn</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">array([[0.36552929, 0.13447071],</span>
<span class="go">       [0.13447071, 0.36552929]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id8"><span class="brackets">2</span></dt>
<dd><ol class="upperalpha simple" start="13">
<li><p>Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal Transport, Advances in Neural Information Processing Systems (NIPS) 26, 2013</p></li>
</ol>
</dd>
<dt class="label" id="id9"><span class="brackets">9</span></dt>
<dd><p>Schmitzer, B. (2016). Stabilized Sparse Scaling Algorithms for Entropy Regularized Transport Problems. arXiv preprint arXiv:1610.06519.</p>
</dd>
<dt class="label" id="id10"><span class="brackets">10</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016). Scaling algorithms for unbalanced transport problems. arXiv preprint arXiv:1607.05816.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.bregman.sinkhorn_knopp" title="ot.bregman.sinkhorn_knopp"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn_knopp()</span></code></a></dt><dd><p>Classic Sinkhorn [2]</p>
</dd>
<dt><a class="reference internal" href="#ot.bregman.sinkhorn_stabilized" title="ot.bregman.sinkhorn_stabilized"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn_stabilized()</span></code></a></dt><dd><p>Stabilized sinkhorn [9][10]</p>
</dd>
<dt><a class="reference internal" href="#ot.bregman.sinkhorn_epsilon_scaling" title="ot.bregman.sinkhorn_epsilon_scaling"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn_epsilon_scaling()</span></code></a></dt><dd><p>Sinkhorn with epslilon scaling [9][10]</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.sinkhorn2">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">sinkhorn2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'sinkhorn'</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#sinkhorn2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.sinkhorn2" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the entropic regularization optimal transport problem and return the loss</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}W = \min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (dim_a, dim_b) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p>a and b are source and target weights (histograms, both sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the Sinkhorn-Knopp matrix scaling algorithm as proposed in <a href="#id228"><span class="problematic" id="id11">[2]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_b</em><em>,</em><em>) or </em><em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_b</em><em>, </em><em>n_hists</em><em>)</em>) – samples in the target domain, compute sinkhorn with multiple targets
and fixed M if b is a matrix (return OT loss + dual variables in log)</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – method used for the solver either ‘sinkhorn’,  ‘sinkhorn_stabilized’ or
‘sinkhorn_epsilon_scaling’, see those function for specific parameters</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>W</strong> (<em>(n_hists) ndarray or float</em>) – Optimal transportation loss for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">sinkhorn2</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">array([0.26894142])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id12"><span class="brackets">2</span></dt>
<dd><ol class="upperalpha simple" start="13">
<li><p>Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal Transport, Advances in Neural Information Processing Systems (NIPS) 26, 2013</p></li>
</ol>
</dd>
<dt class="label" id="id13"><span class="brackets">9</span></dt>
<dd><p>Schmitzer, B. (2016). Stabilized Sparse Scaling Algorithms for Entropy Regularized Transport Problems. arXiv preprint arXiv:1610.06519.</p>
</dd>
<dt class="label" id="id14"><span class="brackets">10</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016). Scaling algorithms for unbalanced transport problems. arXiv preprint arXiv:1607.05816.</p>
<p>[21] Altschuler J., Weed J., Rigollet P. : Near-linear time approximation algorithms for optimal transport via Sinkhorn iteration, Advances in Neural Information Processing Systems (NIPS) 31, 2017</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.bregman.sinkhorn_knopp" title="ot.bregman.sinkhorn_knopp"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn_knopp()</span></code></a></dt><dd><p>Classic Sinkhorn [2]</p>
</dd>
<dt><a class="reference internal" href="#ot.bregman.greenkhorn" title="ot.bregman.greenkhorn"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.greenkhorn()</span></code></a></dt><dd><p>Greenkhorn [21]</p>
</dd>
<dt><a class="reference internal" href="#ot.bregman.sinkhorn_stabilized" title="ot.bregman.sinkhorn_stabilized"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn_stabilized()</span></code></a></dt><dd><p>Stabilized sinkhorn [9][10]</p>
</dd>
<dt><a class="reference internal" href="#ot.bregman.sinkhorn_epsilon_scaling" title="ot.bregman.sinkhorn_epsilon_scaling"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn_epsilon_scaling()</span></code></a></dt><dd><p>Sinkhorn with epslilon scaling [9][10]</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.tic">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">tic</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#tic"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.tic" title="Permalink to this definition">¶</a></dt>
<dd><p>Python implementation of Matlab tic() function</p>
</dd></dl>

<dl class="py function">
<dt id="ot.toc">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">toc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">message</span><span class="o">=</span><span class="default_value">'Elapsed time : {} s'</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#toc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.toc" title="Permalink to this definition">¶</a></dt>
<dd><p>Python implementation of Matlab toc() function</p>
</dd></dl>

<dl class="py function">
<dt id="ot.toq">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">toq</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#toq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.toq" title="Permalink to this definition">¶</a></dt>
<dd><p>Python implementation of Julia toc() function</p>
</dd></dl>

<dl class="py function">
<dt id="id0">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">emd_1d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x_a</span></em>, <em class="sig-param"><span class="n">x_b</span></em>, <em class="sig-param"><span class="n">a</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">b</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">'sqeuclidean'</span></em>, <em class="sig-param"><span class="n">p</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">dense</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/lp.html#emd_1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#id0" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the Earth Movers distance problem between 1d measures and returns
the OT matrix</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma \sum_i \sum_j \gamma_{ij} d(x_a[i], x_b[j])\\s.t. \gamma 1 = a,
     \gamma^T 1= b,
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>d is the metric</p></li>
<li><p>x_a and x_b are the samples</p></li>
<li><p>a and b are the sample weights</p></li>
</ul>
<p>When ‘minkowski’ is used as a metric, <span class="math notranslate nohighlight">\(d(x, y) = |x - y|^p\)</span>.</p>
<p>Uses the algorithm detailed in <a href="#id229"><span class="problematic" id="id15">[1]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_a</strong> (<em>(</em><em>ns</em><em>,</em><em>) or </em><em>(</em><em>ns</em><em>, </em><em>1</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em>) – Source dirac locations (on the real line)</p></li>
<li><p><strong>x_b</strong> (<em>(</em><em>nt</em><em>,</em><em>) or </em><em>(</em><em>ns</em><em>, </em><em>1</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em>) – Target dirac locations (on the real line)</p></li>
<li><p><strong>a</strong> (<em>(</em><em>ns</em><em>,</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em><em>, </em><em>optional</em>) – Source histogram (default is uniform weight)</p></li>
<li><p><strong>b</strong> (<em>(</em><em>nt</em><em>,</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em><em>, </em><em>optional</em>) – Target histogram (default is uniform weight)</p></li>
<li><p><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='sqeuclidean'</em><em>)</em>) – Metric to be used. Only strings listed in <a class="reference internal" href="#ot.dist" title="ot.dist"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.dist()</span></code></a> are accepted.
Due to implementation details, this function runs faster when
<cite>‘sqeuclidean’</cite>, <cite>‘cityblock’</cite>,  or <cite>‘euclidean’</cite> metrics are used.</p></li>
<li><p><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1.0</em><em>)</em>) – The p-norm to apply for if metric=’minkowski’</p></li>
<li><p><strong>dense</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, returns math:<cite>gamma</cite> as a dense ndarray of shape (ns, nt).
Otherwise returns a sparse representation using scipy’s <cite>coo_matrix</cite>
format. Due to implementation details, this function runs faster when
<cite>‘sqeuclidean’</cite>, <cite>‘minkowski’</cite>, <cite>‘cityblock’</cite>,  or <cite>‘euclidean’</cite> metrics
are used.</p></li>
<li><p><strong>log</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If True, returns a dictionary containing the cost.
Otherwise returns only the optimal transportation matrix.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns, nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – If input log is True, a dictionary containing the cost</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Simple example with obvious solution. The function emd_1d accepts lists and
performs automatic conversion to numpy arrays</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_a</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_b</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">emd_1d</span><span class="p">(</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="go">array([[0. , 0.5],</span>
<span class="go">       [0.5, 0. ]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">emd_1d</span><span class="p">(</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">)</span>
<span class="go">array([[0. , 0.5],</span>
<span class="go">       [0.5, 0. ]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id16"><span class="brackets">1</span></dt>
<dd><p>Peyré, G., &amp; Cuturi, M. (2017). “Computational Optimal
Transport”, 2018.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>EMD for multidimensional distributions</p>
</dd>
<dt><a class="reference internal" href="#ot.lp.emd2_1d" title="ot.lp.emd2_1d"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd2_1d()</span></code></a></dt><dd><p>EMD for 1d distributions (returns cost instead of the transportation matrix)</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.emd2_1d">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">emd2_1d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x_a</span></em>, <em class="sig-param"><span class="n">x_b</span></em>, <em class="sig-param"><span class="n">a</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">b</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">'sqeuclidean'</span></em>, <em class="sig-param"><span class="n">p</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">dense</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/lp.html#emd2_1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.emd2_1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the Earth Movers distance problem between 1d measures and returns
the loss</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma \sum_i \sum_j \gamma_{ij} d(x_a[i], x_b[j])\\s.t. \gamma 1 = a,
     \gamma^T 1= b,
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>d is the metric</p></li>
<li><p>x_a and x_b are the samples</p></li>
<li><p>a and b are the sample weights</p></li>
</ul>
<p>When ‘minkowski’ is used as a metric, <span class="math notranslate nohighlight">\(d(x, y) = |x - y|^p\)</span>.</p>
<p>Uses the algorithm detailed in <a href="#id230"><span class="problematic" id="id17">[1]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_a</strong> (<em>(</em><em>ns</em><em>,</em><em>) or </em><em>(</em><em>ns</em><em>, </em><em>1</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em>) – Source dirac locations (on the real line)</p></li>
<li><p><strong>x_b</strong> (<em>(</em><em>nt</em><em>,</em><em>) or </em><em>(</em><em>ns</em><em>, </em><em>1</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em>) – Target dirac locations (on the real line)</p></li>
<li><p><strong>a</strong> (<em>(</em><em>ns</em><em>,</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em><em>, </em><em>optional</em>) – Source histogram (default is uniform weight)</p></li>
<li><p><strong>b</strong> (<em>(</em><em>nt</em><em>,</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em><em>, </em><em>optional</em>) – Target histogram (default is uniform weight)</p></li>
<li><p><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='sqeuclidean'</em><em>)</em>) – Metric to be used. Only strings listed in <a class="reference internal" href="#ot.dist" title="ot.dist"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.dist()</span></code></a> are accepted.
Due to implementation details, this function runs faster when
<cite>‘sqeuclidean’</cite>, <cite>‘minkowski’</cite>, <cite>‘cityblock’</cite>,  or <cite>‘euclidean’</cite> metrics
are used.</p></li>
<li><p><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1.0</em><em>)</em>) – The p-norm to apply for if metric=’minkowski’</p></li>
<li><p><strong>dense</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, returns math:<cite>gamma</cite> as a dense ndarray of shape (ns, nt).
Otherwise returns a sparse representation using scipy’s <cite>coo_matrix</cite>
format. Only used if log is set to True. Due to implementation details,
this function runs faster when dense is set to False.</p></li>
<li><p><strong>log</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If True, returns a dictionary containing the transportation matrix.
Otherwise returns only the loss.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>loss</strong> (<em>float</em>) – Cost associated to the optimal transportation</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – If input log is True, a dictionary containing the Optimal transportation
matrix for the given parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Simple example with obvious solution. The function emd2_1d accepts lists and
performs automatic conversion to numpy arrays</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_a</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_b</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">emd2_1d</span><span class="p">(</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="go">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">emd2_1d</span><span class="p">(</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">)</span>
<span class="go">0.5</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id18"><span class="brackets">1</span></dt>
<dd><p>Peyré, G., &amp; Cuturi, M. (2017). “Computational Optimal
Transport”, 2018.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd2" title="ot.lp.emd2"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd2()</span></code></a></dt><dd><p>EMD for multidimensional distributions</p>
</dd>
<dt><a class="reference internal" href="#ot.lp.emd_1d" title="ot.lp.emd_1d"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd_1d()</span></code></a></dt><dd><p>EMD for 1d distributions (returns the transportation matrix instead of the cost)</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.wasserstein_1d">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">wasserstein_1d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x_a</span></em>, <em class="sig-param"><span class="n">x_b</span></em>, <em class="sig-param"><span class="n">a</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">b</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p</span><span class="o">=</span><span class="default_value">1.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/lp.html#wasserstein_1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.wasserstein_1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the p-Wasserstein distance problem between 1d measures and returns
the distance</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\min_\gamma \left( \sum_i \sum_j \gamma_{ij} \|x_a[i] - x_b[j]\|^p \right)^{1/p}\\s.t. \gamma 1 = a,
     \gamma^T 1= b,
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>x_a and x_b are the samples</p></li>
<li><p>a and b are the sample weights</p></li>
</ul>
<p>Uses the algorithm detailed in <a href="#id231"><span class="problematic" id="id19">[1]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_a</strong> (<em>(</em><em>ns</em><em>,</em><em>) or </em><em>(</em><em>ns</em><em>, </em><em>1</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em>) – Source dirac locations (on the real line)</p></li>
<li><p><strong>x_b</strong> (<em>(</em><em>nt</em><em>,</em><em>) or </em><em>(</em><em>ns</em><em>, </em><em>1</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em>) – Target dirac locations (on the real line)</p></li>
<li><p><strong>a</strong> (<em>(</em><em>ns</em><em>,</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em><em>, </em><em>optional</em>) – Source histogram (default is uniform weight)</p></li>
<li><p><strong>b</strong> (<em>(</em><em>nt</em><em>,</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em><em>, </em><em>optional</em>) – Target histogram (default is uniform weight)</p></li>
<li><p><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1.0</em><em>)</em>) – The order of the p-Wasserstein distance to be computed</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>dist</strong> – p-Wasserstein distance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Simple example with obvious solution. The function wasserstein_1d accepts
lists and performs automatic conversion to numpy arrays</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_a</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_b</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">wasserstein_1d</span><span class="p">(</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="go">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">wasserstein_1d</span><span class="p">(</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">)</span>
<span class="go">0.5</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id20"><span class="brackets">1</span></dt>
<dd><p>Peyré, G., &amp; Cuturi, M. (2017). “Computational Optimal
Transport”, 2018.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd_1d" title="ot.lp.emd_1d"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd_1d()</span></code></a></dt><dd><p>EMD for 1d distributions</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.dist">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">dist</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x1</span></em>, <em class="sig-param"><span class="n">x2</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">'sqeuclidean'</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#dist"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.dist" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute distance between samples in x1 and x2 using function scipy.spatial.distance.cdist</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n1</em><em>,</em><em>d</em><em>)</em>) – matrix with n1 samples of size d</p></li>
<li><p><strong>x2</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n2</em><em>,</em><em>d</em><em>)</em><em>, </em><em>optional</em>) – matrix with n2 samples of size d (if None then x2=x1)</p></li>
<li><p><strong>metric</strong> (<em>str | callable</em><em>, </em><em>optional</em>) – Name of the metric to be computed (full list in the doc of scipy),  If a string,
the distance function can be ‘braycurtis’, ‘canberra’, ‘chebyshev’, ‘cityblock’,
‘correlation’, ‘cosine’, ‘dice’, ‘euclidean’, ‘hamming’, ‘jaccard’, ‘kulsinski’,
‘mahalanobis’, ‘matching’, ‘minkowski’, ‘rogerstanimoto’, ‘russellrao’, ‘seuclidean’,
‘sokalmichener’, ‘sokalsneath’, ‘sqeuclidean’, ‘wminkowski’, ‘yule’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>M</strong> – distance matrix computed with given metric</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>np.array (n1,n2)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.unif">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">unif</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#unif"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.unif" title="Permalink to this definition">¶</a></dt>
<dd><p>return a uniform histogram of length n (simplex)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>n</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – number of bins in the histogram</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>h</strong> – histogram of length n such that h_i=1/n for all i</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>np.array (n,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.barycenter">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">barycenter</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">A</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">weights</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'sinkhorn'</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">10000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">0.0001</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#barycenter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.barycenter" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the entropic regularized wasserstein barycenter of distributions A</p>
<blockquote>
<div><p>The function solves the following optimization problem:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[\mathbf{a} = arg\min_\mathbf{a} \sum_i W_{reg}(\mathbf{a},\mathbf{a}_i)\]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(W_{reg}(\cdot,\cdot)\)</span> is the entropic regularized Wasserstein distance (see ot.bregman.sinkhorn)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}_i\)</span> are training distributions in the columns of matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span></p></li>
<li><p>reg and <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> are respectively the regularization term and the cost matrix for OT</p></li>
</ul>
<p>The algorithm used for solving the problem is the Sinkhorn-Knopp matrix scaling algorithm as proposed in <a href="#id232"><span class="problematic" id="id21">[3]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>A</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim</em><em>, </em><em>n_hists</em><em>)</em>) – n_hists training distributions a_i of size dim</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim</em><em>, </em><em>dim</em><em>)</em>) – loss matrix for OT</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em> (</em><em>optional</em><em>)</em>) – method used for the solver either ‘sinkhorn’ or ‘sinkhorn_stabilized’</p></li>
<li><p><strong>weights</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_hists</em><em>,</em><em>)</em>) – Weights of each histogram a_i on the simplex (barycentric coodinates)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>a</strong> (<em>(dim,) ndarray</em>) – Wasserstein barycenter</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id22"><span class="brackets">3</span></dt>
<dd><p>Benamou, J. D., Carlier, G., Cuturi, M., Nenna, L., &amp; Peyré, G. (2015). Iterative Bregman projections for regularized transportation problems. SIAM Journal on Scientific Computing, 37(2), A1111-A1138.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.sinkhorn_lpl1_mm">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">sinkhorn_lpl1_mm</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">labels_a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">eta</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">numInnerItermax</span><span class="o">=</span><span class="default_value">200</span></em>, <em class="sig-param"><span class="n">stopInnerThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#sinkhorn_lpl1_mm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.sinkhorn_lpl1_mm" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the entropic regularization optimal transport problem with nonconvex
group lasso regularization</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega_e(\gamma)
+ \eta \Omega_g(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (ns,nt) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega_e\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega_e
(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega_g\)</span> is the group lasso  regularization term
<span class="math notranslate nohighlight">\(\Omega_g(\gamma)=\sum_{i,c} \|\gamma_{i,\mathcal{I}_c}\|^{1/2}_1\)</span>
where  <span class="math notranslate nohighlight">\(\mathcal{I}_c\)</span> are the index of samples from class c
in the source domain.</p></li>
<li><p>a and b are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the generalized conditional
gradient as proposed in  <a href="#id233"><span class="problematic" id="id23">[5]_</span></a> <a href="#id234"><span class="problematic" id="id24">[7]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>labels_a</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – labels of samples in the source domain</p></li>
<li><p><strong>b</strong> (<em>np.ndarray</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – samples weights in the target domain</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term for entropic regularization &gt;0</p></li>
<li><p><strong>eta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term  for group lasso regularization &gt;0</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>numInnerItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations (inner sinkhorn solver)</p></li>
<li><p><strong>stopInnerThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (inner sinkhorn solver) (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id25"><span class="brackets">5</span></dt>
<dd><p>N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,
“Optimal Transport for Domain Adaptation,” in IEEE
Transactions on Pattern Analysis and Machine Intelligence ,
vol.PP, no.99, pp.1-1</p>
</dd>
<dt class="label" id="id26"><span class="brackets">7</span></dt>
<dd><p>Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015).
Generalized conditional gradient: analysis of convergence
and applications. arXiv preprint arXiv:1510.06567.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.bregman.sinkhorn" title="ot.bregman.sinkhorn"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn()</span></code></a></dt><dd><p>Entropic regularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.sinkhorn_unbalanced">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">sinkhorn_unbalanced</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">reg_m</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'sinkhorn'</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-06</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/unbalanced.html#sinkhorn_unbalanced"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.sinkhorn_unbalanced" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the unbalanced entropic regularization optimal transport problem
and return the OT plan</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}W = \min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma) + reg_m KL(\gamma 1, a) + reg_m KL(\gamma^T 1, b)\\s.t.
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (dim_a, dim_b) metric cost matrix</p></li>
<li><dl class="simple">
<dt><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization</dt><dd><p>term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p>
</dd>
</dl>
</li>
<li><p>a and b are source and target unbalanced distributions</p></li>
<li><p>KL is the Kullback-Leibler divergence</p></li>
</ul>
<dl class="simple">
<dt>The algorithm used for solving the problem is the generalized</dt><dd><p>Sinkhorn-Knopp matrix scaling algorithm as proposed in [10, 23]_</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – Unnormalized histogram of dimension dim_a</p></li>
<li><p><strong>b</strong> (<em>np.ndarray</em><em> (</em><em>dim_b</em><em>,</em><em>) or </em><em>np.ndarray</em><em> (</em><em>dim_b</em><em>, </em><em>n_hists</em><em>)</em>) – One or multiple unnormalized histograms of dimension dim_b
If many, compute all the OT distances (a, b_i)</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Entropy regularization term &gt; 0</p></li>
<li><p><strong>reg_m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Marginal relaxation term &gt; 0</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – method used for the solver either ‘sinkhorn’,  ‘sinkhorn_stabilized’ or
‘sinkhorn_reg_scaling’, see those function for specific parameters</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul>
<li><p><em>if n_hists == 1</em> –</p>
<dl class="simple">
<dt>gamma<span class="classifier">(dim_a x dim_b) ndarray</span></dt><dd><p>Optimal transportation matrix for the given parameters</p>
</dd>
<dt>log<span class="classifier">dict</span></dt><dd><p>log dictionary returned only if <cite>log</cite> is <cite>True</cite></p>
</dd>
</dl>
</li>
<li><p><em>else</em> –</p>
<dl class="simple">
<dt>ot_distance<span class="classifier">(n_hists,) ndarray</span></dt><dd><p>the OT distance between <cite>a</cite> and each of the histograms <cite>b_i</cite></p>
</dd>
<dt>log<span class="classifier">dict</span></dt><dd><p>log dictionary returned only if <cite>log</cite> is <cite>True</cite></p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">sinkhorn_unbalanced</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">array([[0.51122823, 0.18807035],</span>
<span class="go">       [0.18807035, 0.51122823]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id27"><span class="brackets">2</span></dt>
<dd><p>M. Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal
Transport, Advances in Neural Information Processing Systems
(NIPS) 26, 2013</p>
</dd>
<dt class="label" id="id28"><span class="brackets">9</span></dt>
<dd><p>Schmitzer, B. (2016). Stabilized Sparse Scaling Algorithms for
Entropy Regularized Transport Problems. arXiv preprint arXiv:1610.06519.</p>
</dd>
<dt class="label" id="id29"><span class="brackets">10</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016).
Scaling algorithms for unbalanced transport problems. arXiv preprint
arXiv:1607.05816.</p>
</dd>
<dt class="label" id="id30"><span class="brackets">25</span></dt>
<dd><p>Frogner C., Zhang C., Mobahi H., Araya-Polo M., Poggio T. :
Learning with a Wasserstein Loss,  Advances in Neural Information
Processing Systems (NIPS) 2015</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.unbalanced.sinkhorn_knopp_unbalanced" title="ot.unbalanced.sinkhorn_knopp_unbalanced"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.unbalanced.sinkhorn_knopp_unbalanced()</span></code></a></dt><dd><p>Unbalanced Classic Sinkhorn [10]</p>
</dd>
<dt><a class="reference internal" href="#ot.unbalanced.sinkhorn_stabilized_unbalanced" title="ot.unbalanced.sinkhorn_stabilized_unbalanced"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.unbalanced.sinkhorn_stabilized_unbalanced()</span></code></a></dt><dd><p>Unbalanced Stabilized sinkhorn [9][10]</p>
</dd>
<dt><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.unbalanced.sinkhorn_reg_scaling_unbalanced()</span></code></dt><dd><p>Unbalanced Sinkhorn with epslilon scaling [9][10]</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.barycenter_unbalanced">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">barycenter_unbalanced</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">A</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">reg_m</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'sinkhorn'</span></em>, <em class="sig-param"><span class="n">weights</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-06</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/unbalanced.html#barycenter_unbalanced"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.barycenter_unbalanced" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the entropic unbalanced wasserstein barycenter of A.</p>
<blockquote>
<div><p>The function solves the following optimization problem with a</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[\mathbf{a} = arg\min_\mathbf{a} \sum_i Wu_{reg}(\mathbf{a},\mathbf{a}_i)\]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Wu_{reg}(\cdot,\cdot)\)</span> is the unbalanced entropic regularized</p></li>
</ul>
<p>Wasserstein distance (see ot.unbalanced.sinkhorn_unbalanced)
- <span class="math notranslate nohighlight">\(\mathbf{a}_i\)</span> are training distributions in the columns of matrix
<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>
- reg and <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> are respectively the regularization term and
the cost matrix for OT
- reg_mis the marginal relaxation hyperparameter
The algorithm used for solving the problem is the generalized
Sinkhorn-Knopp matrix scaling algorithm as proposed in <a href="#id235"><span class="problematic" id="id31">[10]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>A</strong> (<em>np.ndarray</em><em> (</em><em>dim</em><em>, </em><em>n_hists</em><em>)</em>) – <cite>n_hists</cite> training distributions a_i of dimension dim</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>dim</em><em>, </em><em>dim</em><em>)</em>) – ground metric matrix for OT.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Entropy regularization term &gt; 0</p></li>
<li><p><strong>reg_m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Marginal relaxation term &gt; 0</p></li>
<li><p><strong>weights</strong> (<em>np.ndarray</em><em> (</em><em>n_hists</em><em>,</em><em>) </em><em>optional</em>) – Weight of each distribution (barycentric coodinates)
If None, uniform weights are used.</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt; 0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>a</strong> (<em>(dim,) ndarray</em>) – Unbalanced Wasserstein barycenter</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id32"><span class="brackets">3</span></dt>
<dd><p>Benamou, J. D., Carlier, G., Cuturi, M., Nenna, L., &amp; Peyré, G.
(2015). Iterative Bregman projections for regularized transportation
problems. SIAM Journal on Scientific Computing, 37(2), A1111-A1138.</p>
</dd>
<dt class="label" id="id33"><span class="brackets">10</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016).
Scaling algorithms for unbalanced transport problems. arXiv preprin
arXiv:1607.05816.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.sinkhorn_unbalanced2">
<code class="sig-prename descclassname">ot.</code><code class="sig-name descname">sinkhorn_unbalanced2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">reg_m</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'sinkhorn'</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-06</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/unbalanced.html#sinkhorn_unbalanced2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.sinkhorn_unbalanced2" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the entropic regularization unbalanced optimal transport problem and
return the loss</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}W = \min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma) + reg_m KL(\gamma 1, a) + reg_m KL(\gamma^T 1, b)\\s.t.
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (dim_a, dim_b) metric cost matrix</p></li>
<li><dl class="simple">
<dt><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term</dt><dd><p><span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p>
</dd>
</dl>
</li>
<li><p>a and b are source and target unbalanced distributions</p></li>
<li><p>KL is the Kullback-Leibler divergence</p></li>
</ul>
<p>The algorithm used for solving the problem is the generalized
Sinkhorn-Knopp matrix scaling algorithm as proposed in [10, 23]_</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – Unnormalized histogram of dimension dim_a</p></li>
<li><p><strong>b</strong> (<em>np.ndarray</em><em> (</em><em>dim_b</em><em>,</em><em>) or </em><em>np.ndarray</em><em> (</em><em>dim_b</em><em>, </em><em>n_hists</em><em>)</em>) – One or multiple unnormalized histograms of dimension dim_b
If many, compute all the OT distances (a, b_i)</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Entropy regularization term &gt; 0</p></li>
<li><p><strong>reg_m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Marginal relaxation term &gt; 0</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – method used for the solver either ‘sinkhorn’,  ‘sinkhorn_stabilized’ or
‘sinkhorn_reg_scaling’, see those function for specific parameters</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>ot_distance</strong> (<em>(n_hists,) ndarray</em>) – the OT distance between <cite>a</cite> and each of the histograms <cite>b_i</cite></p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary returned only if <cite>log</cite> is <cite>True</cite></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">10</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">unbalanced</span><span class="o">.</span><span class="n">sinkhorn_unbalanced2</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
<span class="go">array([0.31912866])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id34"><span class="brackets">2</span></dt>
<dd><p>M. Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal
Transport, Advances in Neural Information Processing Systems
(NIPS) 26, 2013</p>
</dd>
<dt class="label" id="id35"><span class="brackets">9</span></dt>
<dd><p>Schmitzer, B. (2016). Stabilized Sparse Scaling Algorithms for
Entropy Regularized Transport Problems. arXiv preprint arXiv:1610.06519.</p>
</dd>
<dt class="label" id="id36"><span class="brackets">10</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016).
Scaling algorithms for unbalanced transport problems. arXiv preprint
arXiv:1607.05816.</p>
</dd>
<dt class="label" id="id37"><span class="brackets">25</span></dt>
<dd><p>Frogner C., Zhang C., Mobahi H., Araya-Polo M., Poggio T. :
Learning with a Wasserstein Loss,  Advances in Neural Information
Processing Systems (NIPS) 2015</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.unbalanced.sinkhorn_knopp()</span></code></dt><dd><p>Unbalanced Classic Sinkhorn [10]</p>
</dd>
<dt><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.unbalanced.sinkhorn_stabilized()</span></code></dt><dd><p>Unbalanced Stabilized sinkhorn [9][10]</p>
</dd>
<dt><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.unbalanced.sinkhorn_reg_scaling()</span></code></dt><dd><p>Unbalanced Sinkhorn with epslilon scaling [9][10]</p>
</dd>
</dl>
</div>
</dd></dl>

</div>
<div class="section" id="module-ot.lp">
<span id="ot-lp"></span><h2>ot.lp<a class="headerlink" href="#module-ot.lp" title="Permalink to this headline">¶</a></h2>
<p>Solvers for the original linear program OT problem</p>
<dl class="py function">
<dt id="ot.lp.emd">
<code class="sig-prename descclassname">ot.lp.</code><code class="sig-name descname">emd</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">100000</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">center_dual</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/lp.html#emd"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.lp.emd" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the Earth Movers distance problem and returns the OT matrix</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F\\s.t. \gamma 1 = a
     \gamma^T 1= b
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the metric cost matrix</p></li>
<li><p>a and b are the sample weights</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Note that the M matrix needs to be a C-order numpy.array in float64
format.</p>
</div>
<p>Uses the algorithm proposed in <a href="#id236"><span class="problematic" id="id38">[1]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>(</em><em>ns</em><em>,</em><em>) </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><em>float64</em>) – Source histogram (uniform weight if empty list)</p></li>
<li><p><strong>b</strong> (<em>(</em><em>nt</em><em>,</em><em>) </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><em>float64</em>) – Target histogram (uniform weight if empty list)</p></li>
<li><p><strong>M</strong> (<em>(</em><em>ns</em><em>,</em><em>nt</em><em>) </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><em>float64</em>) – Loss matrix (c-order array with type float64)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=100000</em><em>)</em>) – The maximum number of iterations before stopping the optimization
algorithm if it has not converged.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If True, returns a dictionary containing the cost and dual
variables. Otherwise returns only the optimal transportation matrix.</p></li>
<li><p><strong>center_dual</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, centers the dual potential using function
<span class="xref std std-ref">center_ot_dual</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) numpy.ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – If input log is true, a dictionary containing the cost and dual
variables and exit status</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Simple example with obvious solution. The function emd accepts lists and
perform automatic conversion to numpy arrays</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span><span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span><span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span><span class="mf">1.</span><span class="p">],[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">emd</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">M</span><span class="p">)</span>
<span class="go">array([[0.5, 0. ],</span>
<span class="go">       [0. , 0.5]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id39"><span class="brackets">1</span></dt>
<dd><p>Bonneel, N., Van De Panne, M., Paris, S., &amp; Heidrich, W.
(2011, December).  Displacement interpolation using Lagrangian mass
transport. In ACM Transactions on Graphics (TOG) (Vol. 30, No. 6, p.
158). ACM.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.bregman.sinkhorn" title="ot.bregman.sinkhorn"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn()</span></code></a></dt><dd><p>Entropic regularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.lp.emd2">
<code class="sig-prename descclassname">ot.lp.</code><code class="sig-name descname">emd2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">processes</span><span class="o">=</span><span class="default_value">36</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">100000</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">return_matrix</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">center_dual</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/lp.html#emd2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.lp.emd2" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the Earth Movers distance problem and returns the loss</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F\\s.t. \gamma 1 = a
     \gamma^T 1= b
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the metric cost matrix</p></li>
<li><p>a and b are the sample weights</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Note that the M matrix needs to be a C-order numpy.array in float64
format.</p>
</div>
<p>Uses the algorithm proposed in <a href="#id237"><span class="problematic" id="id40">[1]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>(</em><em>ns</em><em>,</em><em>) </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><em>float64</em>) – Source histogram (uniform weight if empty list)</p></li>
<li><p><strong>b</strong> (<em>(</em><em>nt</em><em>,</em><em>) </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><em>float64</em>) – Target histogram (uniform weight if empty list)</p></li>
<li><p><strong>M</strong> (<em>(</em><em>ns</em><em>,</em><em>nt</em><em>) </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a><em>, </em><em>float64</em>) – Loss matrix (c-order array with type float64)</p></li>
<li><p><strong>processes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=nb cpu</em><em>)</em>) – Nb of processes used for multiple emd computation (not used on windows)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=100000</em><em>)</em>) – The maximum number of iterations before stopping the optimization
algorithm if it has not converged.</p></li>
<li><p><strong>log</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If True, returns a dictionary containing the cost and dual
variables. Otherwise returns only the optimal transportation cost.</p></li>
<li><p><strong>return_matrix</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If True, returns the optimal transportation matrix in the log.</p></li>
<li><p><strong>dense</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, returns math:<cite>gamma</cite> as a dense ndarray of shape (ns, nt).
Otherwise returns a sparse representation using scipy’s <cite>coo_matrix</cite>
format.</p></li>
<li><p><strong>center_dual</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, centers the dual potential using function
<span class="xref std std-ref">center_ot_dual</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dictnp</em>) – If input log is true, a dictionary containing the cost and dual
variables and exit status</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Simple example with obvious solution. The function emd accepts lists and
perform automatic conversion to numpy arrays</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span><span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span><span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span><span class="mf">1.</span><span class="p">],[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">emd2</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">M</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id41"><span class="brackets">1</span></dt>
<dd><p>Bonneel, N., Van De Panne, M., Paris, S., &amp; Heidrich, W.
(2011, December).  Displacement interpolation using Lagrangian mass
transport. In ACM Transactions on Graphics (TOG) (Vol. 30, No. 6, p.
158). ACM.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.bregman.sinkhorn" title="ot.bregman.sinkhorn"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn()</span></code></a></dt><dd><p>Entropic regularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.lp.barycenter">
<code class="sig-prename descclassname">ot.lp.</code><code class="sig-name descname">barycenter</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">A</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">weights</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">solver</span><span class="o">=</span><span class="default_value">'interior-point'</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/lp/cvx.html#barycenter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.lp.barycenter" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the Wasserstein barycenter of distributions A</p>
<blockquote>
<div><p>The function solves the following optimization problem [16]:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[\mathbf{a} = arg\min_\mathbf{a} \sum_i W_{1}(\mathbf{a},\mathbf{a}_i)\]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(W_1(\cdot,\cdot)\)</span> is the Wasserstein distance (see ot.emd.sinkhorn)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}_i\)</span> are training distributions in the columns of matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span></p></li>
</ul>
<p>The linear program is solved using the interior point solver from scipy.optimize.
If cvxopt solver if installed it can use cvxopt</p>
<p>Note that this problem do not scale well (both in memory and computational time).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>A</strong> (<em>np.ndarray</em><em> (</em><em>d</em><em>,</em><em>n</em><em>)</em>) – n training distributions a_i of size d</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>d</em><em>,</em><em>d</em><em>)</em>) – loss matrix   for OT</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>weights</strong> (<em>np.ndarray</em><em> (</em><em>n</em><em>,</em><em>)</em>) – Weights of each histogram a_i on the simplex (barycentric coodinates)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>solver</strong> (<em>string</em><em>, </em><em>optional</em>) – the solver used, default ‘interior-point’ use the lp solver from
scipy.optimize. None, or ‘glpk’ or ‘mosek’ use the solver from cvxopt.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>a</strong> (<em>(d,) ndarray</em>) – Wasserstein barycenter</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id42"><span class="brackets">16</span></dt>
<dd><p>Agueh, M., &amp; Carlier, G. (2011). Barycenters in the Wasserstein space. SIAM Journal on Mathematical Analysis, 43(2), 904-924.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.lp.free_support_barycenter">
<code class="sig-prename descclassname">ot.lp.</code><code class="sig-name descname">free_support_barycenter</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">measures_locations</span></em>, <em class="sig-param"><span class="n">measures_weights</span></em>, <em class="sig-param"><span class="n">X_init</span></em>, <em class="sig-param"><span class="n">b</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">weights</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-07</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/lp.html#free_support_barycenter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.lp.free_support_barycenter" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the free support (locations of the barycenters are optimized, not the weights) Wasserstein barycenter problem (i.e. the weighted Frechet mean for the 2-Wasserstein distance)</p>
<p>The function solves the Wasserstein barycenter problem when the barycenter measure is constrained to be supported on k atoms.
This problem is considered in [1] (Algorithm 2). There are two differences with the following codes:
- we do not optimize over the weights
- we do not do line search for the locations updates, we use i.e. theta = 1 in [1] (Algorithm 2). This can be seen as a discrete implementation of the fixed-point algorithm of [2] proposed in the continuous setting.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>measures_locations</strong> (<em>list of</em><em> (</em><em>k_i</em><em>,</em><em>d</em><em>) </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – The discrete support of a measure supported on k_i locations of a d-dimensional space (k_i can be different for each element of the list)</p></li>
<li><p><strong>measures_weights</strong> (<em>list of</em><em> (</em><em>k_i</em><em>,</em><em>) </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.17)"><em>numpy.ndarray</em></a>) – Numpy arrays where each numpy array has k_i non-negatives values summing to one representing the weights of each discrete input measure</p></li>
<li><p><strong>X_init</strong> (<em>(</em><em>k</em><em>,</em><em>d</em><em>) </em><em>np.ndarray</em>) – Initialization of the support locations (on k atoms) of the barycenter</p></li>
<li><p><strong>b</strong> (<em>(</em><em>k</em><em>,</em><em>) </em><em>np.ndarray</em>) – Initialization of the weights of the barycenter (non-negatives, sum to 1)</p></li>
<li><p><strong>weights</strong> (<em>(</em><em>k</em><em>,</em><em>) </em><em>np.ndarray</em>) – Initialization of the coefficients of the barycenter (non-negatives, sum to 1)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X</strong> – Support locations (on k atoms) of the barycenter</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>(k,d) np.ndarray</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id43"><span class="brackets">1</span></dt>
<dd><p>Cuturi, Marco, and Arnaud Doucet. “Fast computation of Wasserstein barycenters.” International Conference on Machine Learning. 2014.</p>
</dd>
<dt class="label" id="id44"><span class="brackets">2</span></dt>
<dd><p>Álvarez-Esteban, Pedro C., et al. “A fixed-point approach to barycenters in Wasserstein space.” Journal of Mathematical Analysis and Applications 441.2 (2016): 744-762.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.lp.emd_1d">
<code class="sig-prename descclassname">ot.lp.</code><code class="sig-name descname">emd_1d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x_a</span></em>, <em class="sig-param"><span class="n">x_b</span></em>, <em class="sig-param"><span class="n">a</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">b</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">'sqeuclidean'</span></em>, <em class="sig-param"><span class="n">p</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">dense</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/lp.html#emd_1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.lp.emd_1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the Earth Movers distance problem between 1d measures and returns
the OT matrix</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma \sum_i \sum_j \gamma_{ij} d(x_a[i], x_b[j])\\s.t. \gamma 1 = a,
     \gamma^T 1= b,
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>d is the metric</p></li>
<li><p>x_a and x_b are the samples</p></li>
<li><p>a and b are the sample weights</p></li>
</ul>
<p>When ‘minkowski’ is used as a metric, <span class="math notranslate nohighlight">\(d(x, y) = |x - y|^p\)</span>.</p>
<p>Uses the algorithm detailed in <a href="#id238"><span class="problematic" id="id45">[1]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_a</strong> (<em>(</em><em>ns</em><em>,</em><em>) or </em><em>(</em><em>ns</em><em>, </em><em>1</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em>) – Source dirac locations (on the real line)</p></li>
<li><p><strong>x_b</strong> (<em>(</em><em>nt</em><em>,</em><em>) or </em><em>(</em><em>ns</em><em>, </em><em>1</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em>) – Target dirac locations (on the real line)</p></li>
<li><p><strong>a</strong> (<em>(</em><em>ns</em><em>,</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em><em>, </em><em>optional</em>) – Source histogram (default is uniform weight)</p></li>
<li><p><strong>b</strong> (<em>(</em><em>nt</em><em>,</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em><em>, </em><em>optional</em>) – Target histogram (default is uniform weight)</p></li>
<li><p><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='sqeuclidean'</em><em>)</em>) – Metric to be used. Only strings listed in <a class="reference internal" href="#ot.dist" title="ot.dist"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.dist()</span></code></a> are accepted.
Due to implementation details, this function runs faster when
<cite>‘sqeuclidean’</cite>, <cite>‘cityblock’</cite>,  or <cite>‘euclidean’</cite> metrics are used.</p></li>
<li><p><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1.0</em><em>)</em>) – The p-norm to apply for if metric=’minkowski’</p></li>
<li><p><strong>dense</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, returns math:<cite>gamma</cite> as a dense ndarray of shape (ns, nt).
Otherwise returns a sparse representation using scipy’s <cite>coo_matrix</cite>
format. Due to implementation details, this function runs faster when
<cite>‘sqeuclidean’</cite>, <cite>‘minkowski’</cite>, <cite>‘cityblock’</cite>,  or <cite>‘euclidean’</cite> metrics
are used.</p></li>
<li><p><strong>log</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If True, returns a dictionary containing the cost.
Otherwise returns only the optimal transportation matrix.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns, nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – If input log is True, a dictionary containing the cost</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Simple example with obvious solution. The function emd_1d accepts lists and
performs automatic conversion to numpy arrays</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_a</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_b</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">emd_1d</span><span class="p">(</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="go">array([[0. , 0.5],</span>
<span class="go">       [0.5, 0. ]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">emd_1d</span><span class="p">(</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">)</span>
<span class="go">array([[0. , 0.5],</span>
<span class="go">       [0.5, 0. ]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id46"><span class="brackets">1</span></dt>
<dd><p>Peyré, G., &amp; Cuturi, M. (2017). “Computational Optimal
Transport”, 2018.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>EMD for multidimensional distributions</p>
</dd>
<dt><a class="reference internal" href="#ot.lp.emd2_1d" title="ot.lp.emd2_1d"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd2_1d()</span></code></a></dt><dd><p>EMD for 1d distributions (returns cost instead of the transportation matrix)</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.lp.emd2_1d">
<code class="sig-prename descclassname">ot.lp.</code><code class="sig-name descname">emd2_1d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x_a</span></em>, <em class="sig-param"><span class="n">x_b</span></em>, <em class="sig-param"><span class="n">a</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">b</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">'sqeuclidean'</span></em>, <em class="sig-param"><span class="n">p</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">dense</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/lp.html#emd2_1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.lp.emd2_1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the Earth Movers distance problem between 1d measures and returns
the loss</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma \sum_i \sum_j \gamma_{ij} d(x_a[i], x_b[j])\\s.t. \gamma 1 = a,
     \gamma^T 1= b,
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>d is the metric</p></li>
<li><p>x_a and x_b are the samples</p></li>
<li><p>a and b are the sample weights</p></li>
</ul>
<p>When ‘minkowski’ is used as a metric, <span class="math notranslate nohighlight">\(d(x, y) = |x - y|^p\)</span>.</p>
<p>Uses the algorithm detailed in <a href="#id239"><span class="problematic" id="id47">[1]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_a</strong> (<em>(</em><em>ns</em><em>,</em><em>) or </em><em>(</em><em>ns</em><em>, </em><em>1</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em>) – Source dirac locations (on the real line)</p></li>
<li><p><strong>x_b</strong> (<em>(</em><em>nt</em><em>,</em><em>) or </em><em>(</em><em>ns</em><em>, </em><em>1</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em>) – Target dirac locations (on the real line)</p></li>
<li><p><strong>a</strong> (<em>(</em><em>ns</em><em>,</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em><em>, </em><em>optional</em>) – Source histogram (default is uniform weight)</p></li>
<li><p><strong>b</strong> (<em>(</em><em>nt</em><em>,</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em><em>, </em><em>optional</em>) – Target histogram (default is uniform weight)</p></li>
<li><p><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em><em> (</em><em>default='sqeuclidean'</em><em>)</em>) – Metric to be used. Only strings listed in <a class="reference internal" href="#ot.dist" title="ot.dist"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.dist()</span></code></a> are accepted.
Due to implementation details, this function runs faster when
<cite>‘sqeuclidean’</cite>, <cite>‘minkowski’</cite>, <cite>‘cityblock’</cite>,  or <cite>‘euclidean’</cite> metrics
are used.</p></li>
<li><p><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1.0</em><em>)</em>) – The p-norm to apply for if metric=’minkowski’</p></li>
<li><p><strong>dense</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – If True, returns math:<cite>gamma</cite> as a dense ndarray of shape (ns, nt).
Otherwise returns a sparse representation using scipy’s <cite>coo_matrix</cite>
format. Only used if log is set to True. Due to implementation details,
this function runs faster when dense is set to False.</p></li>
<li><p><strong>log</strong> (<em>boolean</em><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – If True, returns a dictionary containing the transportation matrix.
Otherwise returns only the loss.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>loss</strong> (<em>float</em>) – Cost associated to the optimal transportation</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – If input log is True, a dictionary containing the Optimal transportation
matrix for the given parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Simple example with obvious solution. The function emd2_1d accepts lists and
performs automatic conversion to numpy arrays</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_a</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_b</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">emd2_1d</span><span class="p">(</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="go">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">emd2_1d</span><span class="p">(</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">)</span>
<span class="go">0.5</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id48"><span class="brackets">1</span></dt>
<dd><p>Peyré, G., &amp; Cuturi, M. (2017). “Computational Optimal
Transport”, 2018.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd2" title="ot.lp.emd2"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd2()</span></code></a></dt><dd><p>EMD for multidimensional distributions</p>
</dd>
<dt><a class="reference internal" href="#ot.lp.emd_1d" title="ot.lp.emd_1d"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd_1d()</span></code></a></dt><dd><p>EMD for 1d distributions (returns the transportation matrix instead of the cost)</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.lp.wasserstein_1d">
<code class="sig-prename descclassname">ot.lp.</code><code class="sig-name descname">wasserstein_1d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x_a</span></em>, <em class="sig-param"><span class="n">x_b</span></em>, <em class="sig-param"><span class="n">a</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">b</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">p</span><span class="o">=</span><span class="default_value">1.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/lp.html#wasserstein_1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.lp.wasserstein_1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the p-Wasserstein distance problem between 1d measures and returns
the distance</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\min_\gamma \left( \sum_i \sum_j \gamma_{ij} \|x_a[i] - x_b[j]\|^p \right)^{1/p}\\s.t. \gamma 1 = a,
     \gamma^T 1= b,
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>x_a and x_b are the samples</p></li>
<li><p>a and b are the sample weights</p></li>
</ul>
<p>Uses the algorithm detailed in <a href="#id240"><span class="problematic" id="id49">[1]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_a</strong> (<em>(</em><em>ns</em><em>,</em><em>) or </em><em>(</em><em>ns</em><em>, </em><em>1</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em>) – Source dirac locations (on the real line)</p></li>
<li><p><strong>x_b</strong> (<em>(</em><em>nt</em><em>,</em><em>) or </em><em>(</em><em>ns</em><em>, </em><em>1</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em>) – Target dirac locations (on the real line)</p></li>
<li><p><strong>a</strong> (<em>(</em><em>ns</em><em>,</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em><em>, </em><em>optional</em>) – Source histogram (default is uniform weight)</p></li>
<li><p><strong>b</strong> (<em>(</em><em>nt</em><em>,</em><em>) </em><em>ndarray</em><em>, </em><em>float64</em><em>, </em><em>optional</em>) – Target histogram (default is uniform weight)</p></li>
<li><p><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1.0</em><em>)</em>) – The order of the p-Wasserstein distance to be computed</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>dist</strong> – p-Wasserstein distance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Simple example with obvious solution. The function wasserstein_1d accepts
lists and performs automatic conversion to numpy arrays</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_a</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_b</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">wasserstein_1d</span><span class="p">(</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="go">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">wasserstein_1d</span><span class="p">(</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">)</span>
<span class="go">0.5</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id50"><span class="brackets">1</span></dt>
<dd><p>Peyré, G., &amp; Cuturi, M. (2017). “Computational Optimal
Transport”, 2018.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd_1d" title="ot.lp.emd_1d"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd_1d()</span></code></a></dt><dd><p>EMD for 1d distributions</p>
</dd>
</dl>
</div>
</dd></dl>

</div>
<div class="section" id="module-ot.bregman">
<span id="ot-bregman"></span><h2>ot.bregman<a class="headerlink" href="#module-ot.bregman" title="Permalink to this headline">¶</a></h2>
<p>Bregman projections for regularized OT</p>
<dl class="py function">
<dt id="ot.bregman.barycenter">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">barycenter</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">A</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">weights</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'sinkhorn'</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">10000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">0.0001</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#barycenter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.barycenter" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the entropic regularized wasserstein barycenter of distributions A</p>
<blockquote>
<div><p>The function solves the following optimization problem:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[\mathbf{a} = arg\min_\mathbf{a} \sum_i W_{reg}(\mathbf{a},\mathbf{a}_i)\]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(W_{reg}(\cdot,\cdot)\)</span> is the entropic regularized Wasserstein distance (see ot.bregman.sinkhorn)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}_i\)</span> are training distributions in the columns of matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span></p></li>
<li><p>reg and <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> are respectively the regularization term and the cost matrix for OT</p></li>
</ul>
<p>The algorithm used for solving the problem is the Sinkhorn-Knopp matrix scaling algorithm as proposed in <a href="#id241"><span class="problematic" id="id51">[3]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>A</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim</em><em>, </em><em>n_hists</em><em>)</em>) – n_hists training distributions a_i of size dim</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim</em><em>, </em><em>dim</em><em>)</em>) – loss matrix for OT</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em> (</em><em>optional</em><em>)</em>) – method used for the solver either ‘sinkhorn’ or ‘sinkhorn_stabilized’</p></li>
<li><p><strong>weights</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_hists</em><em>,</em><em>)</em>) – Weights of each histogram a_i on the simplex (barycentric coodinates)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>a</strong> (<em>(dim,) ndarray</em>) – Wasserstein barycenter</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id52"><span class="brackets">3</span></dt>
<dd><p>Benamou, J. D., Carlier, G., Cuturi, M., Nenna, L., &amp; Peyré, G. (2015). Iterative Bregman projections for regularized transportation problems. SIAM Journal on Scientific Computing, 37(2), A1111-A1138.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.barycenter_sinkhorn">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">barycenter_sinkhorn</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">A</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">weights</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">0.0001</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#barycenter_sinkhorn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.barycenter_sinkhorn" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the entropic regularized wasserstein barycenter of distributions A</p>
<blockquote>
<div><p>The function solves the following optimization problem:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[\mathbf{a} = arg\min_\mathbf{a} \sum_i W_{reg}(\mathbf{a},\mathbf{a}_i)\]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(W_{reg}(\cdot,\cdot)\)</span> is the entropic regularized Wasserstein distance (see ot.bregman.sinkhorn)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}_i\)</span> are training distributions in the columns of matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span></p></li>
<li><p>reg and <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> are respectively the regularization term and the cost matrix for OT</p></li>
</ul>
<p>The algorithm used for solving the problem is the Sinkhorn-Knopp matrix scaling algorithm as proposed in <a href="#id242"><span class="problematic" id="id53">[3]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>A</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim</em><em>, </em><em>n_hists</em><em>)</em>) – n_hists training distributions a_i of size dim</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim</em><em>, </em><em>dim</em><em>)</em>) – loss matrix for OT</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>weights</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_hists</em><em>,</em><em>)</em>) – Weights of each histogram a_i on the simplex (barycentric coodinates)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>a</strong> (<em>(dim,) ndarray</em>) – Wasserstein barycenter</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id54"><span class="brackets">3</span></dt>
<dd><p>Benamou, J. D., Carlier, G., Cuturi, M., Nenna, L., &amp; Peyré, G. (2015). Iterative Bregman projections for regularized transportation problems. SIAM Journal on Scientific Computing, 37(2), A1111-A1138.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.barycenter_stabilized">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">barycenter_stabilized</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">A</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">tau</span><span class="o">=</span><span class="default_value">10000000000.0</span></em>, <em class="sig-param"><span class="n">weights</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">0.0001</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#barycenter_stabilized"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.barycenter_stabilized" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Compute the entropic regularized wasserstein barycenter of distributions A</dt><dd><blockquote>
<div><p>with stabilization.</p>
</div></blockquote>
<p>The function solves the following optimization problem:</p>
</dd>
</dl>
<div class="math notranslate nohighlight">
\[\mathbf{a} = arg\min_\mathbf{a} \sum_i W_{reg}(\mathbf{a},\mathbf{a}_i)\]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(W_{reg}(\cdot,\cdot)\)</span> is the entropic regularized Wasserstein distance (see ot.bregman.sinkhorn)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}_i\)</span> are training distributions in the columns of matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span></p></li>
<li><p>reg and <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> are respectively the regularization term and the cost matrix for OT</p></li>
</ul>
<p>The algorithm used for solving the problem is the Sinkhorn-Knopp matrix scaling algorithm as proposed in <a href="#id243"><span class="problematic" id="id55">[3]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>A</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim</em><em>, </em><em>n_hists</em><em>)</em>) – n_hists training distributions a_i of size dim</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim</em><em>, </em><em>dim</em><em>)</em>) – loss matrix for OT</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>tau</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – thershold for max value in u or v for log scaling</p></li>
<li><p><strong>weights</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_hists</em><em>,</em><em>)</em>) – Weights of each histogram a_i on the simplex (barycentric coodinates)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>a</strong> (<em>(dim,) ndarray</em>) – Wasserstein barycenter</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id56"><span class="brackets">3</span></dt>
<dd><p>Benamou, J. D., Carlier, G., Cuturi, M., Nenna, L., &amp; Peyré, G. (2015). Iterative Bregman projections for regularized transportation problems. SIAM Journal on Scientific Computing, 37(2), A1111-A1138.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.convolutional_barycenter2d">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">convolutional_barycenter2d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">A</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">weights</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">10000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">stabThr</span><span class="o">=</span><span class="default_value">1e-30</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#convolutional_barycenter2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.convolutional_barycenter2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the entropic regularized wasserstein barycenter of distributions A
where A is a collection of 2D images.</p>
<blockquote>
<div><p>The function solves the following optimization problem:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[\mathbf{a} = arg\min_\mathbf{a} \sum_i W_{reg}(\mathbf{a},\mathbf{a}_i)\]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(W_{reg}(\cdot,\cdot)\)</span> is the entropic regularized Wasserstein distance (see ot.bregman.sinkhorn)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}_i\)</span> are training distributions (2D images) in the mast two dimensions of matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span></p></li>
<li><p>reg is the regularization strength scalar value</p></li>
</ul>
<p>The algorithm used for solving the problem is the Sinkhorn-Knopp matrix scaling algorithm as proposed in <a class="footnote-reference brackets" href="#id58" id="id57">21</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>A</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_hists</em><em>, </em><em>width</em><em>, </em><em>height</em><em>)</em>) – n distributions (2D images) of size width x height</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>weights</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_hists</em><em>,</em><em>)</em>) – Weights of each image on the simplex (barycentric coodinates)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt; 0)</p></li>
<li><p><strong>stabThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stabilization threshold to avoid numerical precision issue</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray, shape (width, height)</em>) – 2D Wasserstein barycenter</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id58"><span class="brackets"><a class="fn-backref" href="#id57">21</a></span></dt>
<dd><p>Solomon, J., De Goes, F., Peyré, G., Cuturi, M., Butscher, A., Nguyen, A. &amp; Guibas, L. (2015).</p>
</dd>
</dl>
<p>Convolutional wasserstein distances: Efficient optimal transportation on geometric domains
ACM Transactions on Graphics (TOG), 34(4), 66</p>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.empirical_sinkhorn">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">empirical_sinkhorn</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X_s</span></em>, <em class="sig-param"><span class="n">X_t</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">a</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">b</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">'sqeuclidean'</span></em>, <em class="sig-param"><span class="n">numIterMax</span><span class="o">=</span><span class="default_value">10000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#empirical_sinkhorn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.empirical_sinkhorn" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the entropic regularization optimal transport problem and return the
OT matrix from empirical data</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(M\)</span> is the (n_samples_a, n_samples_b) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_s</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_samples_a</em><em>, </em><em>dim</em><em>)</em>) – samples in the source domain</p></li>
<li><p><strong>X_t</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_samples_b</em><em>, </em><em>dim</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_samples_a</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_samples_b</em><em>,</em><em>)</em>) – samples weights in the target domain</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>ndarray, shape (n_samples_a, n_samples_b)</em>) – Regularized optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">n_samples_a</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_samples_b</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_samples_a</span><span class="p">),</span> <span class="p">(</span><span class="n">n_samples_a</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples_b</span><span class="p">),</span> <span class="p">(</span><span class="n">n_samples_b</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">empirical_sinkhorn</span><span class="p">(</span><span class="n">X_s</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">reg</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  
<span class="go">array([[4.99977301e-01,  2.26989344e-05],</span>
<span class="go">       [2.26989344e-05,  4.99977301e-01]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id59"><span class="brackets">2</span></dt>
<dd><ol class="upperalpha simple" start="13">
<li><p>Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal Transport, Advances in Neural Information Processing Systems (NIPS) 26, 2013</p></li>
</ol>
</dd>
<dt class="label" id="id60"><span class="brackets">9</span></dt>
<dd><p>Schmitzer, B. (2016). Stabilized Sparse Scaling Algorithms for Entropy Regularized Transport Problems. arXiv preprint arXiv:1610.06519.</p>
</dd>
<dt class="label" id="id61"><span class="brackets">10</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016). Scaling algorithms for unbalanced transport problems. arXiv preprint arXiv:1607.05816.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.empirical_sinkhorn2">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">empirical_sinkhorn2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X_s</span></em>, <em class="sig-param"><span class="n">X_t</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">a</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">b</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">'sqeuclidean'</span></em>, <em class="sig-param"><span class="n">numIterMax</span><span class="o">=</span><span class="default_value">10000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#empirical_sinkhorn2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.empirical_sinkhorn2" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the entropic regularization optimal transport problem from empirical
data and return the OT loss</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}W = \min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(M\)</span> is the (n_samples_a, n_samples_b) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_s</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_samples_a</em><em>, </em><em>dim</em><em>)</em>) – samples in the source domain</p></li>
<li><p><strong>X_t</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_samples_b</em><em>, </em><em>dim</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_samples_a</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_samples_b</em><em>,</em><em>)</em>) – samples weights in the target domain</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>ndarray, shape (n_samples_a, n_samples_b)</em>) – Regularized optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">n_samples_a</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_samples_b</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_samples_a</span><span class="p">),</span> <span class="p">(</span><span class="n">n_samples_a</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples_b</span><span class="p">),</span> <span class="p">(</span><span class="n">n_samples_b</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">empirical_sinkhorn2</span><span class="p">(</span><span class="n">X_s</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">reg</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">array([4.53978687e-05])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id62"><span class="brackets">2</span></dt>
<dd><ol class="upperalpha simple" start="13">
<li><p>Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal Transport, Advances in Neural Information Processing Systems (NIPS) 26, 2013</p></li>
</ol>
</dd>
<dt class="label" id="id63"><span class="brackets">9</span></dt>
<dd><p>Schmitzer, B. (2016). Stabilized Sparse Scaling Algorithms for Entropy Regularized Transport Problems. arXiv preprint arXiv:1610.06519.</p>
</dd>
<dt class="label" id="id64"><span class="brackets">10</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016). Scaling algorithms for unbalanced transport problems. arXiv preprint arXiv:1607.05816.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.empirical_sinkhorn_divergence">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">empirical_sinkhorn_divergence</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X_s</span></em>, <em class="sig-param"><span class="n">X_t</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">a</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">b</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">'sqeuclidean'</span></em>, <em class="sig-param"><span class="n">numIterMax</span><span class="o">=</span><span class="default_value">10000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#empirical_sinkhorn_divergence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.empirical_sinkhorn_divergence" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the sinkhorn divergence loss from empirical data</p>
<p>The function solves the following optimization problems and return the
sinkhorn divergence <span class="math notranslate nohighlight">\(S\)</span>:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}W &amp;= \min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma)\\W_a &amp;= \min_{\gamma_a} &lt;\gamma_a,M_a&gt;_F + reg\cdot\Omega(\gamma_a)\\W_b &amp;= \min_{\gamma_b} &lt;\gamma_b,M_b&gt;_F + reg\cdot\Omega(\gamma_b)\\S &amp;= W - 1/2 * (W_a + W_b)\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\\     \gamma_a 1 = a\\     \gamma_a^T 1= a\\     \gamma_a\geq 0\\     \gamma_b 1 = b\\     \gamma_b^T 1= b\\     \gamma_b\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(M\)</span> (resp. <span class="math notranslate nohighlight">\(M_a, M_b\)</span>) is the (n_samples_a, n_samples_b) metric cost matrix (resp (n_samples_a, n_samples_a) and (n_samples_b, n_samples_b))</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> are source and target weights (sum to 1)</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_s</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_samples_a</em><em>, </em><em>dim</em><em>)</em>) – samples in the source domain</p></li>
<li><p><strong>X_t</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_samples_b</em><em>, </em><em>dim</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_samples_a</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_samples_b</em><em>,</em><em>)</em>) – samples weights in the target domain</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>ndarray, shape (n_samples_a, n_samples_b)</em>) – Regularized optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">n_samples_a</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_samples_b</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_samples_a</span><span class="p">),</span> <span class="p">(</span><span class="n">n_samples_a</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples_b</span><span class="p">),</span> <span class="p">(</span><span class="n">n_samples_b</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">empirical_sinkhorn_divergence</span><span class="p">(</span><span class="n">X_s</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">reg</span><span class="p">)</span>  
<span class="go">array([1.499...])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id65"><span class="brackets">23</span></dt>
<dd><p>Aude Genevay, Gabriel Peyré, Marco Cuturi, Learning Generative Models with Sinkhorn Divergences,  Proceedings of the Twenty-First International Conference on Artficial Intelligence and Statistics, (AISTATS) 21, 2018</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.geometricBar">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">geometricBar</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">weights</span></em>, <em class="sig-param"><span class="n">alldistribT</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#geometricBar"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.geometricBar" title="Permalink to this definition">¶</a></dt>
<dd><p>return the weighted geometric mean of distributions</p>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.geometricMean">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">geometricMean</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">alldistribT</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#geometricMean"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.geometricMean" title="Permalink to this definition">¶</a></dt>
<dd><p>return the  geometric mean of distributions</p>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.greenkhorn">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">greenkhorn</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">10000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#greenkhorn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.greenkhorn" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the entropic regularization optimal transport problem and return the OT matrix</p>
<p>The algorithm used is based on the paper</p>
<dl class="simple">
<dt>Near-linear time approximation algorithms for optimal transport via Sinkhorn iteration</dt><dd><p>by Jason Altschuler, Jonathan Weed, Philippe Rigollet
appeared at NIPS 2017</p>
</dd>
</dl>
<p>which is a stochastic version of the Sinkhorn-Knopp algorithm [2].</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (dim_a, dim_b) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p>a and b are source and target weights (histograms, both sum to 1)</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_b</em><em>,</em><em>) or </em><em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_b</em><em>, </em><em>n_hists</em><em>)</em>) – samples in the target domain, compute sinkhorn with multiple targets
and fixed M if b is a matrix (return OT loss + dual variables in log)</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>ndarray, shape (dim_a, dim_b)</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">bregman</span><span class="o">.</span><span class="n">greenkhorn</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">array([[0.36552929, 0.13447071],</span>
<span class="go">       [0.13447071, 0.36552929]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id66"><span class="brackets">2</span></dt>
<dd><p>M. Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal Transport, Advances in Neural Information Processing Systems (NIPS) 26, 2013
[22] J. Altschuler, J.Weed, P. Rigollet : Near-linear time approximation algorithms for optimal transport via Sinkhorn iteration, Advances in Neural Information Processing Systems (NIPS) 31, 2017</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.jcpot_barycenter">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">jcpot_barycenter</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span></em>, <em class="sig-param"><span class="n">Ys</span></em>, <em class="sig-param"><span class="n">Xt</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">'sqeuclidean'</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-06</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#jcpot_barycenter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.jcpot_barycenter" title="Permalink to this definition">¶</a></dt>
<dd><p>Joint OT and proportion estimation for multi-source target shift as proposed in [27]</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{h} = arg\min_{\mathbf{h}}\quad \sum_{k=1}^{K} \lambda_k
            W_{reg}((\mathbf{D}_2^{(k)} \mathbf{h})^T, \mathbf{a})\\s.t. \ \forall k, \mathbf{D}_1^{(k)} \gamma_k \mathbf{1}_n= \mathbf{h}\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\lambda_k\)</span> is the weight of k-th source domain</p></li>
<li><p><span class="math notranslate nohighlight">\(W_{reg}(\cdot,\cdot)\)</span> is the entropic regularized Wasserstein distance (see ot.bregman.sinkhorn)</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{D}_2^{(k)}\)</span> is a matrix of weights related to k-th source domain defined as in [p. 5, 27], its expected shape is <cite>(n_k, C)</cite> where <cite>n_k</cite> is the number of elements in the k-th source domain and <cite>C</cite> is the number of classes</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{h}\)</span> is a vector of estimated proportions in the target domain of size C</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> is a uniform vector of weights in the target domain of size <cite>n</cite></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{D}_1^{(k)}\)</span> is a matrix of class assignments defined as in [p. 5, 27], its expected shape is <cite>(n_k, C)</cite></p></li>
</ul>
<p>The problem consist in solving a Wasserstein barycenter problem to estimate the proportions <span class="math notranslate nohighlight">\(\mathbf{h}\)</span> in the target domain.</p>
<p>The algorithm used for solving the problem is the Iterative Bregman projections algorithm
with two sets of marginal constraints related to the unknown vector <span class="math notranslate nohighlight">\(\mathbf{h}\)</span> and uniform target distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<em>list of K np.ndarray</em><em>(</em><em>nsk</em><em>,</em><em>d</em><em>)</em>) – features of all source domains’ samples</p></li>
<li><p><strong>Ys</strong> (<em>list of K np.ndarray</em><em>(</em><em>nsk</em><em>,</em><em>)</em>) – labels of all source domains’ samples</p></li>
<li><p><strong>Xt</strong> (<em>np.ndarray</em><em> (</em><em>nt</em><em>,</em><em>d</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;sqeuclidean&quot;</em><em>)</em>) – The ground metric for the Wasserstein problem</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative change in the barycenter (&gt;0)</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Controls the verbosity of the optimization algorithm</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>h</strong> (<em>(C,) ndarray</em>) – proportion estimation in the target domain</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id67"><span class="brackets">27</span></dt>
<dd><p>Ievgen Redko, Nicolas Courty, Rémi Flamary, Devis Tuia
“Optimal transport for multi-source domain adaptation under target shift”,
International Conference on Artificial Intelligence and Statistics (AISTATS), 2019.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.projC">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">projC</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">gamma</span></em>, <em class="sig-param"><span class="n">q</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#projC"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.projC" title="Permalink to this definition">¶</a></dt>
<dd><p>return the KL projection on the column constrints</p>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.projR">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">projR</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">gamma</span></em>, <em class="sig-param"><span class="n">p</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#projR"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.projR" title="Permalink to this definition">¶</a></dt>
<dd><p>return the KL projection on the row constrints</p>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.screenkhorn">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">screenkhorn</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">ns_budget</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">nt_budget</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">uniform</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">restricted</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">maxiter</span><span class="o">=</span><span class="default_value">10000</span></em>, <em class="sig-param"><span class="n">maxfun</span><span class="o">=</span><span class="default_value">10000</span></em>, <em class="sig-param"><span class="n">pgtol</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#screenkhorn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.screenkhorn" title="Permalink to this definition">¶</a></dt>
<dd><p>”
Screening Sinkhorn Algorithm for Regularized Optimal Transport</p>
<p>The function solves an approximate dual of Sinkhorn divergence [2] which is written as the following optimization problem:</p>
<dl>
<dt>..math::</dt><dd><p>(u, v) = argmin_{u, v} 1_{ns}^T B(u,v) 1_{nt} - &lt;kappa u, a&gt; - &lt;v/kappa, b&gt;</p>
<p>where B(u,v) = diag(e^u) K diag(e^v), with K = e^{-M/reg} and</p>
<p>s.t. e^{u_i} geq epsilon / kappa, for all i in {1, …, ns}</p>
<blockquote>
<div><p>e^{v_j} geq epsilon kappa, for all j in {1, …, nt}</p>
</div></blockquote>
<p>The parameters kappa and epsilon are determined w.r.t the couple number budget of points (ns_budget, nt_budget), see Equation (5) in [26]</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<cite>numpy.ndarray</cite>, shape=(ns,)) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<cite>numpy.ndarray</cite>, shape=(nt,)) – samples weights in the target domain</p></li>
<li><p><strong>M</strong> (<cite>numpy.ndarray</cite>, shape=(ns, nt)) – Cost matrix</p></li>
<li><p><strong>reg</strong> (<cite>float</cite>) – Level of the entropy regularisation</p></li>
<li><p><strong>ns_budget</strong> (<cite>int</cite>, deafult=None) – Number budget of points to be keeped in the source domain
If it is None then 50% of the source sample points will be keeped</p></li>
<li><p><strong>nt_budget</strong> (<cite>int</cite>, deafult=None) – Number budget of points to be keeped in the target domain
If it is None then 50% of the target sample points will be keeped</p></li>
<li><p><strong>uniform</strong> (<cite>bool</cite>, default=False) – If <cite>True</cite>, the source and target distribution are supposed to be uniform, i.e., a_i = 1 / ns and b_j = 1 / nt</p></li>
<li><p><strong>restricted</strong> (<cite>bool</cite>, default=True) – If <cite>True</cite>, a warm-start initialization for the  L-BFGS-B solver
using a restricted Sinkhorn algorithm with at most 5 iterations</p></li>
<li><p><strong>maxiter</strong> (<cite>int</cite>, default=10000) – Maximum number of iterations in LBFGS solver</p></li>
<li><p><strong>maxfun</strong> (<cite>int</cite>, default=10000) – Maximum  number of function evaluations in LBFGS solver</p></li>
<li><p><strong>pgtol</strong> (<cite>float</cite>, default=1e-09) – Final objective function accuracy in LBFGS solver</p></li>
<li><p><strong>verbose</strong> (<cite>bool</cite>, default=False) – If <cite>True</cite>, dispaly informations about the cardinals of the active sets and the paramerters kappa
and epsilon</p></li>
<li><p><strong>Dependency</strong> – </p></li>
<li><p><strong>----------</strong> – </p></li>
<li><p><strong>gain more efficiency</strong><strong>, </strong><strong>screenkhorn needs to call the &quot;Bottleneck&quot; package</strong><strong> (</strong><strong>https</strong> (<em>To</em>) – </p></li>
<li><p><strong>the screening pre-processing step. If Bottleneck isn't installed</strong><strong>, </strong><strong>the following error message appears</strong> (<em>in</em>) – </p></li>
<li><p><strong>module doesn't exist. Install it from https</strong> (<em>&quot;Bottleneck</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<cite>numpy.ndarray</cite>, shape=(ns, nt)) – Screened optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<cite>dict</cite>, default=False) – Log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id68"><span class="brackets">26</span></dt>
<dd><p>Alaya M. Z., Bérar M., Gasso G., Rakotomamonjy A. (2019). Screening Sinkhorn Algorithm for Regularized Optimal Transport (NIPS) 33, 2019</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.sinkhorn">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">sinkhorn</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'sinkhorn'</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#sinkhorn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.sinkhorn" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the entropic regularization optimal transport problem and return the OT matrix</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (dim_a, dim_b) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p>a and b are source and target weights (histograms, both sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the Sinkhorn-Knopp matrix scaling algorithm as proposed in <a href="#id244"><span class="problematic" id="id69">[2]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_b</em><em>,</em><em>) or </em><em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_b</em><em>, </em><em>n_hists</em><em>)</em>) – samples in the target domain, compute sinkhorn with multiple targets
and fixed M if b is a matrix (return OT loss + dual variables in log)</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – method used for the solver either ‘sinkhorn’, ‘greenkhorn’, ‘sinkhorn_stabilized’ or
‘sinkhorn_epsilon_scaling’, see those function for specific parameters</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>ndarray, shape (dim_a, dim_b)</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">sinkhorn</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">array([[0.36552929, 0.13447071],</span>
<span class="go">       [0.13447071, 0.36552929]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id70"><span class="brackets">2</span></dt>
<dd><ol class="upperalpha simple" start="13">
<li><p>Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal Transport, Advances in Neural Information Processing Systems (NIPS) 26, 2013</p></li>
</ol>
</dd>
<dt class="label" id="id71"><span class="brackets">9</span></dt>
<dd><p>Schmitzer, B. (2016). Stabilized Sparse Scaling Algorithms for Entropy Regularized Transport Problems. arXiv preprint arXiv:1610.06519.</p>
</dd>
<dt class="label" id="id72"><span class="brackets">10</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016). Scaling algorithms for unbalanced transport problems. arXiv preprint arXiv:1607.05816.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.bregman.sinkhorn_knopp" title="ot.bregman.sinkhorn_knopp"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn_knopp()</span></code></a></dt><dd><p>Classic Sinkhorn [2]</p>
</dd>
<dt><a class="reference internal" href="#ot.bregman.sinkhorn_stabilized" title="ot.bregman.sinkhorn_stabilized"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn_stabilized()</span></code></a></dt><dd><p>Stabilized sinkhorn [9][10]</p>
</dd>
<dt><a class="reference internal" href="#ot.bregman.sinkhorn_epsilon_scaling" title="ot.bregman.sinkhorn_epsilon_scaling"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn_epsilon_scaling()</span></code></a></dt><dd><p>Sinkhorn with epslilon scaling [9][10]</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.sinkhorn2">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">sinkhorn2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'sinkhorn'</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#sinkhorn2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.sinkhorn2" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the entropic regularization optimal transport problem and return the loss</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}W = \min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (dim_a, dim_b) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p>a and b are source and target weights (histograms, both sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the Sinkhorn-Knopp matrix scaling algorithm as proposed in <a href="#id245"><span class="problematic" id="id73">[2]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_b</em><em>,</em><em>) or </em><em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_b</em><em>, </em><em>n_hists</em><em>)</em>) – samples in the target domain, compute sinkhorn with multiple targets
and fixed M if b is a matrix (return OT loss + dual variables in log)</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – method used for the solver either ‘sinkhorn’,  ‘sinkhorn_stabilized’ or
‘sinkhorn_epsilon_scaling’, see those function for specific parameters</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>W</strong> (<em>(n_hists) ndarray or float</em>) – Optimal transportation loss for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">sinkhorn2</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">array([0.26894142])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id74"><span class="brackets">2</span></dt>
<dd><ol class="upperalpha simple" start="13">
<li><p>Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal Transport, Advances in Neural Information Processing Systems (NIPS) 26, 2013</p></li>
</ol>
</dd>
<dt class="label" id="id75"><span class="brackets">9</span></dt>
<dd><p>Schmitzer, B. (2016). Stabilized Sparse Scaling Algorithms for Entropy Regularized Transport Problems. arXiv preprint arXiv:1610.06519.</p>
</dd>
<dt class="label" id="id76"><span class="brackets">10</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016). Scaling algorithms for unbalanced transport problems. arXiv preprint arXiv:1607.05816.</p>
<p>[21] Altschuler J., Weed J., Rigollet P. : Near-linear time approximation algorithms for optimal transport via Sinkhorn iteration, Advances in Neural Information Processing Systems (NIPS) 31, 2017</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.bregman.sinkhorn_knopp" title="ot.bregman.sinkhorn_knopp"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn_knopp()</span></code></a></dt><dd><p>Classic Sinkhorn [2]</p>
</dd>
<dt><a class="reference internal" href="#ot.bregman.greenkhorn" title="ot.bregman.greenkhorn"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.greenkhorn()</span></code></a></dt><dd><p>Greenkhorn [21]</p>
</dd>
<dt><a class="reference internal" href="#ot.bregman.sinkhorn_stabilized" title="ot.bregman.sinkhorn_stabilized"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn_stabilized()</span></code></a></dt><dd><p>Stabilized sinkhorn [9][10]</p>
</dd>
<dt><a class="reference internal" href="#ot.bregman.sinkhorn_epsilon_scaling" title="ot.bregman.sinkhorn_epsilon_scaling"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn_epsilon_scaling()</span></code></a></dt><dd><p>Sinkhorn with epslilon scaling [9][10]</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.sinkhorn_epsilon_scaling">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">sinkhorn_epsilon_scaling</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">epsilon0</span><span class="o">=</span><span class="default_value">10000.0</span></em>, <em class="sig-param"><span class="n">numInnerItermax</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">tau</span><span class="o">=</span><span class="default_value">1000.0</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">warmstart</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">print_period</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#sinkhorn_epsilon_scaling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.sinkhorn_epsilon_scaling" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the entropic regularization optimal transport problem with log
stabilization and epsilon scaling.</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (dim_a, dim_b) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p>a and b are source and target weights (histograms, both sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the Sinkhorn-Knopp matrix
scaling algorithm as proposed in <a href="#id246"><span class="problematic" id="id77">[2]_</span></a> but with the log stabilization
proposed in <a href="#id247"><span class="problematic" id="id78">[10]_</span></a> and the log scaling proposed in <a href="#id248"><span class="problematic" id="id79">[9]_</span></a> algorithm 3.2</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_b</em><em>,</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>tau</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – thershold for max value in u or v for log scaling</p></li>
<li><p><strong>warmstart</strong> (<em>tuple of vectors</em>) – if given then sarting values for alpha an beta log scalings</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>numInnerItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterationsin the inner slog stabilized sinkhorn</p></li>
<li><p><strong>epsilon0</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – first epsilon regularization value (then exponential decrease to reg)</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>ndarray, shape (dim_a, dim_b)</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">bregman</span><span class="o">.</span><span class="n">sinkhorn_epsilon_scaling</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">array([[0.36552929, 0.13447071],</span>
<span class="go">       [0.13447071, 0.36552929]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id80"><span class="brackets">2</span></dt>
<dd><ol class="upperalpha simple" start="13">
<li><p>Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal Transport, Advances in Neural Information Processing Systems (NIPS) 26, 2013</p></li>
</ol>
</dd>
<dt class="label" id="id81"><span class="brackets">9</span></dt>
<dd><p>Schmitzer, B. (2016). Stabilized Sparse Scaling Algorithms for Entropy Regularized Transport Problems. arXiv preprint arXiv:1610.06519.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.sinkhorn_knopp">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">sinkhorn_knopp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#sinkhorn_knopp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.sinkhorn_knopp" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the entropic regularization optimal transport problem and return the OT matrix</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (dim_a, dim_b) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p>a and b are source and target weights (histograms, both sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the Sinkhorn-Knopp matrix scaling algorithm as proposed in <a href="#id249"><span class="problematic" id="id82">[2]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_b</em><em>,</em><em>) or </em><em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_b</em><em>, </em><em>n_hists</em><em>)</em>) – samples in the target domain, compute sinkhorn with multiple targets
and fixed M if b is a matrix (return OT loss + dual variables in log)</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>ndarray, shape (dim_a, dim_b)</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">sinkhorn</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">array([[0.36552929, 0.13447071],</span>
<span class="go">       [0.13447071, 0.36552929]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id83"><span class="brackets">2</span></dt>
<dd><ol class="upperalpha simple" start="13">
<li><p>Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal Transport, Advances in Neural Information Processing Systems (NIPS) 26, 2013</p></li>
</ol>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.sinkhorn_stabilized">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">sinkhorn_stabilized</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">tau</span><span class="o">=</span><span class="default_value">1000.0</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">warmstart</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">print_period</span><span class="o">=</span><span class="default_value">20</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#sinkhorn_stabilized"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.sinkhorn_stabilized" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the entropic regularization OT problem with log stabilization</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (dim_a, dim_b) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p>a and b are source and target weights (histograms, both sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the Sinkhorn-Knopp matrix
scaling algorithm as proposed in <a href="#id250"><span class="problematic" id="id84">[2]_</span></a> but with the log stabilization
proposed in <a href="#id251"><span class="problematic" id="id85">[10]_</span></a> an defined in <a href="#id252"><span class="problematic" id="id86">[9]_</span></a> (Algo 3.1) .</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_b</em><em>,</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>tau</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – thershold for max value in u or v for log scaling</p></li>
<li><p><strong>warmstart</strong> (<em>tible of vectors</em>) – if given then sarting values for alpha an beta log scalings</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>ndarray, shape (dim_a, dim_b)</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span><span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span><span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span><span class="mf">1.</span><span class="p">],[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">bregman</span><span class="o">.</span><span class="n">sinkhorn_stabilized</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">array([[0.36552929, 0.13447071],</span>
<span class="go">       [0.13447071, 0.36552929]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id87"><span class="brackets">2</span></dt>
<dd><ol class="upperalpha simple" start="13">
<li><p>Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal Transport, Advances in Neural Information Processing Systems (NIPS) 26, 2013</p></li>
</ol>
</dd>
<dt class="label" id="id88"><span class="brackets">9</span></dt>
<dd><p>Schmitzer, B. (2016). Stabilized Sparse Scaling Algorithms for Entropy Regularized Transport Problems. arXiv preprint arXiv:1610.06519.</p>
</dd>
<dt class="label" id="id89"><span class="brackets">10</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016). Scaling algorithms for unbalanced transport problems. arXiv preprint arXiv:1607.05816.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.bregman.unmix">
<code class="sig-prename descclassname">ot.bregman.</code><code class="sig-name descname">unmix</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">D</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">M0</span></em>, <em class="sig-param"><span class="n">h0</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">reg0</span></em>, <em class="sig-param"><span class="n">alpha</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">0.001</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/bregman.html#unmix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.bregman.unmix" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the unmixing of an observation with a given dictionary using Wasserstein distance</p>
<p>The function solve the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{h} = arg\min_\mathbf{h}  (1- \\alpha) W_{M,reg}(\mathbf{a},\mathbf{Dh})+\\alpha W_{M0,reg0}(\mathbf{h}_0,\mathbf{h})\end{split}\]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(W_{M,reg}(\cdot,\cdot)\)</span> is the entropic regularized Wasserstein distance with M loss matrix (see ot.bregman.sinkhorn)</p></li>
<li><dl class="field-list simple">
<dt class="field-odd">math</dt>
<dd class="field-odd"><p><cite>mathbf{D}</cite> is a dictionary of <cite>n_atoms</cite> atoms of dimension <cite>dim_a</cite>, its expected shape is <cite>(dim_a, n_atoms)</cite></p>
</dd>
</dl>
</li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{h}\)</span> is the estimated unmixing of dimension <cite>n_atoms</cite></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{a}\)</span> is an observed distribution of dimension <cite>dim_a</cite></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{h}_0\)</span> is a prior on <cite>h</cite> of dimension <cite>dim_prior</cite></p></li>
<li><p>reg and <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> are respectively the regularization term and the cost matrix (dim_a, dim_a) for OT data fitting</p></li>
<li><p>reg0 and <span class="math notranslate nohighlight">\(\mathbf{M0}\)</span> are respectively the regularization term and the cost matrix (dim_prior, n_atoms) regularization</p></li>
<li><p>:math:<a href="#id90"><span class="problematic" id="id91">`</span></a>\alpha`weight data fitting and regularization</p></li>
</ul>
<p>The optimization problem is solved suing the algorithm described in [4]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>)</em>) – observed distribution (histogram, sums to 1)</p></li>
<li><p><strong>D</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>, </em><em>n_atoms</em><em>)</em>) – dictionary matrix</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>dim_a</em><em>, </em><em>dim_a</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>M0</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_atoms</em><em>, </em><em>dim_prior</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>h0</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n_atoms</em><em>,</em><em>)</em>) – prior on the estimated unmixing h</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0 (Wasserstein data fitting)</p></li>
<li><p><strong>reg0</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0 (Wasserstein reg with h0)</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – How much should we trust the prior ([0,1])</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>h</strong> (<em>ndarray, shape (n_atoms,)</em>) – Wasserstein barycenter</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id92"><span class="brackets">4</span></dt>
<dd><ol class="upperalpha simple" start="19">
<li><p>Nakhostin, N. Courty, R. Flamary, D. Tuia, T. Corpetti, Supervised planetary unmixing with optimal transport, Whorkshop on Hyperspectral Image and Signal Processing : Evolution in Remote Sensing (WHISPERS), 2016.</p></li>
</ol>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="ot-smooth">
<h2>ot.smooth<a class="headerlink" href="#ot-smooth" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-ot.smooth"></span><p>Implementation of
Smooth and Sparse Optimal Transport.
Mathieu Blondel, Vivien Seguy, Antoine Rolet.
In Proc. of AISTATS 2018.
<a class="reference external" href="https://arxiv.org/abs/1710.06276">https://arxiv.org/abs/1710.06276</a></p>
<p>[17] Blondel, M., Seguy, V., &amp; Rolet, A. (2018). Smooth and Sparse Optimal
Transport. Proceedings of the Twenty-First International Conference on
Artificial Intelligence and Statistics (AISTATS).</p>
<p>Original code from <a class="reference external" href="https://github.com/mblondel/smooth-ot/">https://github.com/mblondel/smooth-ot/</a></p>
<dl class="py class">
<dt id="ot.smooth.NegEntropy">
<em class="property">class </em><code class="sig-prename descclassname">ot.smooth.</code><code class="sig-name descname">NegEntropy</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">gamma</span><span class="o">=</span><span class="default_value">1.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#NegEntropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.NegEntropy" title="Permalink to this definition">¶</a></dt>
<dd><p>NegEntropy regularization</p>
<dl class="py method">
<dt id="ot.smooth.NegEntropy.Omega">
<code class="sig-name descname">Omega</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">T</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#NegEntropy.Omega"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.NegEntropy.Omega" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute regularization term.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>T</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>) </em><em>x len</em><em>(</em><em>b</em><em>)</em>) – Input array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>value</strong> – Regularization term.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.smooth.NegEntropy.delta_Omega">
<code class="sig-name descname">delta_Omega</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#NegEntropy.delta_Omega"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.NegEntropy.delta_Omega" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute delta_Omega(X[:, j]) for each X[:, j].
delta_Omega(x) = sup_{y &gt;= 0} y^T x - Omega(y).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>) </em><em>x len</em><em>(</em><em>b</em><em>)</em>) – Input array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>v</strong> (<em>array, len(b)</em>) – Values: v[j] = delta_Omega(X[:, j])</p></li>
<li><p><strong>G</strong> (<em>array, len(a) x len(b)</em>) – Gradients: G[:, j] = nabla delta_Omega(X[:, j])</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.smooth.NegEntropy.max_Omega">
<code class="sig-name descname">max_Omega</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">b</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#NegEntropy.max_Omega"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.NegEntropy.max_Omega" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute max_Omega_j(X[:, j]) for each X[:, j].
max_Omega_j(x) = sup_{y &gt;= 0, sum(y) = 1} y^T x - Omega(b[j] y) / b[j].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>) </em><em>x len</em><em>(</em><em>b</em><em>)</em>) – Input array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>v</strong> (<em>array, len(b)</em>) – Values: v[j] = max_Omega_j(X[:, j])</p></li>
<li><p><strong>G</strong> (<em>array, len(a) x len(b)</em>) – Gradients: G[:, j] = nabla max_Omega_j(X[:, j])</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="ot.smooth.Regularization">
<em class="property">class </em><code class="sig-prename descclassname">ot.smooth.</code><code class="sig-name descname">Regularization</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">gamma</span><span class="o">=</span><span class="default_value">1.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#Regularization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.Regularization" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for Regularization objects</p>
<p class="rubric">Notes</p>
<p>This class is not intended for direct use but as aparent for true
regularizatiojn implementation.</p>
<dl class="py method">
<dt id="ot.smooth.Regularization.Omega">
<code class="sig-name descname">Omega</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#Regularization.Omega"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.Regularization.Omega" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute regularization term.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>T</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>) </em><em>x len</em><em>(</em><em>b</em><em>)</em>) – Input array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>value</strong> – Regularization term.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.smooth.Regularization.delta_Omega">
<code class="sig-name descname">delta_Omega</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#Regularization.delta_Omega"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.Regularization.delta_Omega" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute delta_Omega(X[:, j]) for each X[:, j].
delta_Omega(x) = sup_{y &gt;= 0} y^T x - Omega(y).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>) </em><em>x len</em><em>(</em><em>b</em><em>)</em>) – Input array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>v</strong> (<em>array, len(b)</em>) – Values: v[j] = delta_Omega(X[:, j])</p></li>
<li><p><strong>G</strong> (<em>array, len(a) x len(b)</em>) – Gradients: G[:, j] = nabla delta_Omega(X[:, j])</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.smooth.Regularization.max_Omega">
<code class="sig-name descname">max_Omega</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">b</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#Regularization.max_Omega"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.Regularization.max_Omega" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute max_Omega_j(X[:, j]) for each X[:, j].
max_Omega_j(x) = sup_{y &gt;= 0, sum(y) = 1} y^T x - Omega(b[j] y) / b[j].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>) </em><em>x len</em><em>(</em><em>b</em><em>)</em>) – Input array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>v</strong> (<em>array, len(b)</em>) – Values: v[j] = max_Omega_j(X[:, j])</p></li>
<li><p><strong>G</strong> (<em>array, len(a) x len(b)</em>) – Gradients: G[:, j] = nabla max_Omega_j(X[:, j])</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="ot.smooth.SquaredL2">
<em class="property">class </em><code class="sig-prename descclassname">ot.smooth.</code><code class="sig-name descname">SquaredL2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">gamma</span><span class="o">=</span><span class="default_value">1.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#SquaredL2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.SquaredL2" title="Permalink to this definition">¶</a></dt>
<dd><p>Squared L2 regularization</p>
<dl class="py method">
<dt id="ot.smooth.SquaredL2.Omega">
<code class="sig-name descname">Omega</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">T</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#SquaredL2.Omega"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.SquaredL2.Omega" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute regularization term.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>T</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>) </em><em>x len</em><em>(</em><em>b</em><em>)</em>) – Input array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>value</strong> – Regularization term.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.smooth.SquaredL2.delta_Omega">
<code class="sig-name descname">delta_Omega</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#SquaredL2.delta_Omega"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.SquaredL2.delta_Omega" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute delta_Omega(X[:, j]) for each X[:, j].
delta_Omega(x) = sup_{y &gt;= 0} y^T x - Omega(y).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>) </em><em>x len</em><em>(</em><em>b</em><em>)</em>) – Input array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>v</strong> (<em>array, len(b)</em>) – Values: v[j] = delta_Omega(X[:, j])</p></li>
<li><p><strong>G</strong> (<em>array, len(a) x len(b)</em>) – Gradients: G[:, j] = nabla delta_Omega(X[:, j])</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.smooth.SquaredL2.max_Omega">
<code class="sig-name descname">max_Omega</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">b</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#SquaredL2.max_Omega"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.SquaredL2.max_Omega" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute max_Omega_j(X[:, j]) for each X[:, j].
max_Omega_j(x) = sup_{y &gt;= 0, sum(y) = 1} y^T x - Omega(b[j] y) / b[j].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>) </em><em>x len</em><em>(</em><em>b</em><em>)</em>) – Input array.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>v</strong> (<em>array, len(b)</em>) – Values: v[j] = max_Omega_j(X[:, j])</p></li>
<li><p><strong>G</strong> (<em>array, len(a) x len(b)</em>) – Gradients: G[:, j] = nabla max_Omega_j(X[:, j])</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="ot.smooth.dual_obj_grad">
<code class="sig-prename descclassname">ot.smooth.</code><code class="sig-name descname">dual_obj_grad</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">alpha</span></em>, <em class="sig-param"><span class="n">beta</span></em>, <em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">C</span></em>, <em class="sig-param"><span class="n">regul</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#dual_obj_grad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.dual_obj_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute objective value and gradients of dual objective.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>)</em>) – </p></li>
<li><p><strong>beta</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>b</em><em>)</em>) – Current iterate of dual potentials.</p></li>
<li><p><strong>a</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>)</em>) – </p></li>
<li><p><strong>b</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>b</em><em>)</em>) – Input histograms (should be non-negative and sum to 1).</p></li>
<li><p><strong>C</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>) </em><em>x len</em><em>(</em><em>b</em><em>)</em>) – Ground cost matrix.</p></li>
<li><p><strong>regul</strong> (<em>Regularization object</em>) – Should implement a delta_Omega(X) method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>obj</strong> (<em>float</em>) – Objective value (higher is better).</p></li>
<li><p><strong>grad_alpha</strong> (<em>array, shape = len(a)</em>) – Gradient w.r.t. alpha.</p></li>
<li><p><strong>grad_beta</strong> (<em>array, shape = len(b)</em>) – Gradient w.r.t. beta.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.smooth.get_plan_from_dual">
<code class="sig-prename descclassname">ot.smooth.</code><code class="sig-name descname">get_plan_from_dual</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">alpha</span></em>, <em class="sig-param"><span class="n">beta</span></em>, <em class="sig-param"><span class="n">C</span></em>, <em class="sig-param"><span class="n">regul</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#get_plan_from_dual"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.get_plan_from_dual" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieve optimal transportation plan from optimal dual potentials.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>)</em>) – </p></li>
<li><p><strong>beta</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>b</em><em>)</em>) – Optimal dual potentials.</p></li>
<li><p><strong>C</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>) </em><em>x len</em><em>(</em><em>b</em><em>)</em>) – Ground cost matrix.</p></li>
<li><p><strong>regul</strong> (<em>Regularization object</em>) – Should implement a delta_Omega(X) method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>T</strong> – Optimal transportation plan.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array, shape = len(a) x len(b)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.smooth.get_plan_from_semi_dual">
<code class="sig-prename descclassname">ot.smooth.</code><code class="sig-name descname">get_plan_from_semi_dual</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">alpha</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">C</span></em>, <em class="sig-param"><span class="n">regul</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#get_plan_from_semi_dual"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.get_plan_from_semi_dual" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieve optimal transportation plan from optimal semi-dual potentials.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>)</em>) – Optimal semi-dual potentials.</p></li>
<li><p><strong>b</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>b</em><em>)</em>) – Second input histogram (should be non-negative and sum to 1).</p></li>
<li><p><strong>C</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>) </em><em>x len</em><em>(</em><em>b</em><em>)</em>) – Ground cost matrix.</p></li>
<li><p><strong>regul</strong> (<em>Regularization object</em>) – Should implement a delta_Omega(X) method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>T</strong> – Optimal transportation plan.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array, shape = len(a) x len(b)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.smooth.projection_simplex">
<code class="sig-prename descclassname">ot.smooth.</code><code class="sig-name descname">projection_simplex</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">V</span></em>, <em class="sig-param"><span class="n">z</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#projection_simplex"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.projection_simplex" title="Permalink to this definition">¶</a></dt>
<dd><p>Projection of x onto the simplex, scaled by z</p>
<blockquote>
<div><p>P(x; z) = argmin_{y &gt;= 0, sum(y) = z} ||y - x||^2</p>
</div></blockquote>
<dl class="simple">
<dt>z: float or array</dt><dd><p>If array, len(z) must be compatible with V</p>
</dd>
<dt>axis: None or int</dt><dd><ul class="simple">
<li><p>axis=None: project V by P(V.ravel(); z)</p></li>
<li><p>axis=1: project each V[i] by P(V[i]; z[i])</p></li>
<li><p>axis=0: project each V[:, j] by P(V[:, j]; z[j])</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.smooth.semi_dual_obj_grad">
<code class="sig-prename descclassname">ot.smooth.</code><code class="sig-name descname">semi_dual_obj_grad</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">alpha</span></em>, <em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">C</span></em>, <em class="sig-param"><span class="n">regul</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#semi_dual_obj_grad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.semi_dual_obj_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute objective value and gradient of semi-dual objective.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>)</em>) – Current iterate of semi-dual potentials.</p></li>
<li><p><strong>a</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>)</em>) – </p></li>
<li><p><strong>b</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>b</em><em>)</em>) – Input histograms (should be non-negative and sum to 1).</p></li>
<li><p><strong>C</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>) </em><em>x len</em><em>(</em><em>b</em><em>)</em>) – Ground cost matrix.</p></li>
<li><p><strong>regul</strong> (<em>Regularization object</em>) – Should implement a max_Omega(X) method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>obj</strong> (<em>float</em>) – Objective value (higher is better).</p></li>
<li><p><strong>grad</strong> (<em>array, shape = len(a)</em>) – Gradient w.r.t. alpha.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.smooth.smooth_ot_dual">
<code class="sig-prename descclassname">ot.smooth.</code><code class="sig-name descname">smooth_ot_dual</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">reg_type</span><span class="o">=</span><span class="default_value">'l2'</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'L-BFGS-B'</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">500</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#smooth_ot_dual"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.smooth_ot_dual" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the regularized OT problem in the dual and return the OT matrix</p>
<p>The function solves the smooth relaxed dual formulation (7) in <a href="#id253"><span class="problematic" id="id93">[17]_</span></a> :</p>
<div class="math notranslate nohighlight">
\[\max_{\alpha,\beta}\quad a^T\alpha+b^T\beta-\sum_j\delta_\Omega(\alpha+\beta_j-\mathbf{m}_j)\]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{m}_j\)</span> is the jth column of the cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\delta_\Omega\)</span> is the convex conjugate of the regularization term <span class="math notranslate nohighlight">\(\Omega\)</span></p></li>
<li><p>a and b are source and target weights (sum to 1)</p></li>
</ul>
<p>The OT matrix can is reconstructed from the gradient of <span class="math notranslate nohighlight">\(\delta_\Omega\)</span>
(See <a href="#id254"><span class="problematic" id="id94">[17]_</span></a> Proposition 1).
The optimization algorithm is using gradient decent (L-BFGS by default).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>np.ndarray</em><em> (</em><em>nt</em><em>,</em><em>) or </em><em>np.ndarray</em><em> (</em><em>nt</em><em>,</em><em>nbb</em><em>)</em>) – samples in the target domain, compute sinkhorn with multiple targets
and fixed M if b is a matrix (return OT loss + dual variables in log)</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>reg_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Regularization type,  can be the following (default =’l2’):
- ‘kl’ : Kullback Leibler (~ Neg-entropy used in sinkhorn <a href="#id255"><span class="problematic" id="id95">[2]_</span></a>)
- ‘l2’ : Squared Euclidean regularization</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Solver to use for scipy.optimize.minimize</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id96"><span class="brackets">2</span></dt>
<dd><ol class="upperalpha simple" start="13">
<li><p>Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal Transport, Advances in Neural Information Processing Systems (NIPS) 26, 2013</p></li>
</ol>
</dd>
<dt class="label" id="id97"><span class="brackets">17</span></dt>
<dd><p>Blondel, M., Seguy, V., &amp; Rolet, A. (2018). Smooth and Sparse Optimal Transport. Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics (AISTATS).</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.sinhorn()</span></code></dt><dd><p>Entropic regularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.smooth.smooth_ot_semi_dual">
<code class="sig-prename descclassname">ot.smooth.</code><code class="sig-name descname">smooth_ot_semi_dual</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">reg_type</span><span class="o">=</span><span class="default_value">'l2'</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'L-BFGS-B'</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">500</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#smooth_ot_semi_dual"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.smooth_ot_semi_dual" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the regularized OT problem in the semi-dual and return the OT matrix</p>
<p>The function solves the smooth relaxed dual formulation (10) in <a href="#id256"><span class="problematic" id="id98">[17]_</span></a> :</p>
<div class="math notranslate nohighlight">
\[\max_{\alpha}\quad a^T\alpha-OT_\Omega^*(\alpha,b)\]</div>
<p>where :</p>
<div class="math notranslate nohighlight">
\[OT_\Omega^*(\alpha,b)=\sum_j b_j\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{m}_j\)</span> is the jth column of the cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(OT_\Omega^*(\alpha,b)\)</span> is defined in Eq. (9) in [17]</p></li>
<li><p>a and b are source and target weights (sum to 1)</p></li>
</ul>
<p>The OT matrix can is reconstructed using <a href="#id257"><span class="problematic" id="id99">[17]_</span></a> Proposition 2.
The optimization algorithm is using gradient decent (L-BFGS by default).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>np.ndarray</em><em> (</em><em>nt</em><em>,</em><em>) or </em><em>np.ndarray</em><em> (</em><em>nt</em><em>,</em><em>nbb</em><em>)</em>) – samples in the target domain, compute sinkhorn with multiple targets
and fixed M if b is a matrix (return OT loss + dual variables in log)</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>reg_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Regularization type,  can be the following (default =’l2’):
- ‘kl’ : Kullback Leibler (~ Neg-entropy used in sinkhorn <a href="#id258"><span class="problematic" id="id100">[2]_</span></a>)
- ‘l2’ : Squared Euclidean regularization</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Solver to use for scipy.optimize.minimize</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id101"><span class="brackets">2</span></dt>
<dd><ol class="upperalpha simple" start="13">
<li><p>Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal Transport, Advances in Neural Information Processing Systems (NIPS) 26, 2013</p></li>
</ol>
</dd>
<dt class="label" id="id102"><span class="brackets">17</span></dt>
<dd><p>Blondel, M., Seguy, V., &amp; Rolet, A. (2018). Smooth and Sparse Optimal Transport. Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics (AISTATS).</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.sinhorn()</span></code></dt><dd><p>Entropic regularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.smooth.solve_dual">
<code class="sig-prename descclassname">ot.smooth.</code><code class="sig-name descname">solve_dual</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">C</span></em>, <em class="sig-param"><span class="n">regul</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'L-BFGS-B'</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">0.001</span></em>, <em class="sig-param"><span class="n">max_iter</span><span class="o">=</span><span class="default_value">500</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#solve_dual"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.solve_dual" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the “smoothed” dual objective.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>)</em>) – </p></li>
<li><p><strong>b</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>b</em><em>)</em>) – Input histograms (should be non-negative and sum to 1).</p></li>
<li><p><strong>C</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>) </em><em>x len</em><em>(</em><em>b</em><em>)</em>) – Ground cost matrix.</p></li>
<li><p><strong>regul</strong> (<em>Regularization object</em>) – Should implement a delta_Omega(X) method.</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Solver to be used (passed to <cite>scipy.optimize.minimize</cite>).</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Tolerance parameter.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Maximum number of iterations.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>alpha</strong> (<em>array, shape = len(a)</em>)</p></li>
<li><p><strong>beta</strong> (<em>array, shape = len(b)</em>) – Dual potentials.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.smooth.solve_semi_dual">
<code class="sig-prename descclassname">ot.smooth.</code><code class="sig-name descname">solve_semi_dual</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">C</span></em>, <em class="sig-param"><span class="n">regul</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'L-BFGS-B'</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">0.001</span></em>, <em class="sig-param"><span class="n">max_iter</span><span class="o">=</span><span class="default_value">500</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/smooth.html#solve_semi_dual"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.smooth.solve_semi_dual" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the “smoothed” semi-dual objective.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>)</em>) – </p></li>
<li><p><strong>b</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>b</em><em>)</em>) – Input histograms (should be non-negative and sum to 1).</p></li>
<li><p><strong>C</strong> (<em>array</em><em>, </em><em>shape = len</em><em>(</em><em>a</em><em>) </em><em>x len</em><em>(</em><em>b</em><em>)</em>) – Ground cost matrix.</p></li>
<li><p><strong>regul</strong> (<em>Regularization object</em>) – Should implement a max_Omega(X) method.</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Solver to be used (passed to <cite>scipy.optimize.minimize</cite>).</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Tolerance parameter.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Maximum number of iterations.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>alpha</strong> – Semi-dual potentials.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array, shape = len(a)</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ot.gromov">
<span id="ot-gromov"></span><h2>ot.gromov<a class="headerlink" href="#module-ot.gromov" title="Permalink to this headline">¶</a></h2>
<p>Gromov-Wasserstein transport method</p>
<dl class="py function">
<dt id="ot.gromov.entropic_gromov_barycenters">
<code class="sig-prename descclassname">ot.gromov.</code><code class="sig-name descname">entropic_gromov_barycenters</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">N</span></em>, <em class="sig-param"><span class="n">Cs</span></em>, <em class="sig-param"><span class="n">ps</span></em>, <em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">lambdas</span></em>, <em class="sig-param"><span class="n">loss_fun</span></em>, <em class="sig-param"><span class="n">epsilon</span></em>, <em class="sig-param"><span class="n">max_iter</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">init_C</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/gromov.html#entropic_gromov_barycenters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.gromov.entropic_gromov_barycenters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the gromov-wasserstein barycenters of S measured similarity matrices</p>
<p>(Cs)_{s=1}^{s=S}</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[C = argmin_{C\in R^{NxN}} \sum_s \lambda_s GW(C,C_s,p,p_s)\]</div>
<p>Where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(C_s\)</span> : metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(p_s\)</span>  : distribution</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of the targeted barycenter</p></li>
<li><p><strong>Cs</strong> (<em>list of S np.ndarray of shape</em><em> (</em><em>ns</em><em>,</em><em>ns</em><em>)</em>) – Metric cost matrices</p></li>
<li><p><strong>ps</strong> (<em>list of S np.ndarray of shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Sample weights in the S spaces</p></li>
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em>(</em><em>N</em><em>,</em><em>)</em>) – Weights in the targeted barycenter</p></li>
<li><p><strong>lambdas</strong> (<em>list of float</em>) – List of the S spaces’ weights.</p></li>
<li><p><strong>loss_fun</strong> (<em>callable</em>) – Tensor-matrix multiplication function based on specific loss function.</p></li>
<li><p><strong>update</strong> (<em>callable</em>) – function(p,lambdas,T,Cs) that updates C according to a specific Kernel
with the S Ts couplings calculated at each iteration</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>init_C</strong> (<em>bool | ndarray</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>, </em><em>N</em><em>)</em>) – Random initial value for the C matrix provided by user.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>C</strong> – Similarity matrix in the barycenter space (permutated arbitrarily)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, shape (N, N)</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id103"><span class="brackets">12</span></dt>
<dd><p>Peyré, Gabriel, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.gromov.entropic_gromov_wasserstein">
<code class="sig-prename descclassname">ot.gromov.</code><code class="sig-name descname">entropic_gromov_wasserstein</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">C1</span></em>, <em class="sig-param"><span class="n">C2</span></em>, <em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">q</span></em>, <em class="sig-param"><span class="n">loss_fun</span></em>, <em class="sig-param"><span class="n">epsilon</span></em>, <em class="sig-param"><span class="n">max_iter</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/gromov.html#entropic_gromov_wasserstein"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.gromov.entropic_gromov_wasserstein" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the gromov-wasserstein transport between (C1,p) and (C2,q)</p>
<p>(C1,p) and (C2,q)</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}GW = arg\min_T \sum_{i,j,k,l} L(C1_{i,k},C2_{j,l})*T_{i,j}*T_{k,l}-\epsilon(H(T))\\s.t. T 1 = p\\     T^T 1= q\\     T\geq 0\end{aligned}\end{align} \]</div>
<p>Where :
- C1 : Metric cost matrix in the source space
- C2 : Metric cost matrix in the target space
- p  : distribution in the source space
- q  : distribution in the target space
- L  : loss function to account for the misfit between the similarity matrices
- H  : entropy</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric costfr matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space</p></li>
<li><p><strong>loss_fun</strong> (<em>string</em>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>T</strong> – Optimal coupling between the two spaces</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, shape (ns, nt)</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id104"><span class="brackets">12</span></dt>
<dd><p>Peyré, Gabriel, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.gromov.entropic_gromov_wasserstein2">
<code class="sig-prename descclassname">ot.gromov.</code><code class="sig-name descname">entropic_gromov_wasserstein2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">C1</span></em>, <em class="sig-param"><span class="n">C2</span></em>, <em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">q</span></em>, <em class="sig-param"><span class="n">loss_fun</span></em>, <em class="sig-param"><span class="n">epsilon</span></em>, <em class="sig-param"><span class="n">max_iter</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/gromov.html#entropic_gromov_wasserstein2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.gromov.entropic_gromov_wasserstein2" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the entropic gromov-wasserstein discrepancy between the two measured similarity matrices</p>
<p>(C1,p) and (C2,q)</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[GW = \min_T \sum_{i,j,k,l} L(C1_{i,k},C2_{j,l})*T_{i,j}*T_{k,l}-\epsilon(H(T))\]</div>
<p>Where :
- C1 : Metric cost matrix in the source space
- C2 : Metric cost matrix in the target space
- p  : distribution in the source space
- q  : distribution in the target space
- L  : loss function to account for the misfit between the similarity matrices
- H  : entropy</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric costfr matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>gw_dist</strong> – Gromov-Wasserstein distance</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id105"><span class="brackets">12</span></dt>
<dd><p>Peyré, Gabriel, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.gromov.fgw_barycenters">
<code class="sig-prename descclassname">ot.gromov.</code><code class="sig-name descname">fgw_barycenters</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">N</span></em>, <em class="sig-param"><span class="n">Ys</span></em>, <em class="sig-param"><span class="n">Cs</span></em>, <em class="sig-param"><span class="n">ps</span></em>, <em class="sig-param"><span class="n">lambdas</span></em>, <em class="sig-param"><span class="n">alpha</span></em>, <em class="sig-param"><span class="n">fixed_structure</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">fixed_features</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">p</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">loss_fun</span><span class="o">=</span><span class="default_value">'square_loss'</span></em>, <em class="sig-param"><span class="n">max_iter</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">init_C</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">init_X</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/gromov.html#fgw_barycenters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.gromov.fgw_barycenters" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the fgw barycenter as presented eq (5) in [24].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<em>integer</em>) – Desired number of samples of the target barycenter</p></li>
<li><p><strong>Ys</strong> (<em>list of ndarray</em><em>, </em><em>each element has shape</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – Features of all samples</p></li>
<li><p><strong>Cs</strong> (<em>list of ndarray</em><em>, </em><em>each element has shape</em><em> (</em><em>ns</em><em>,</em><em>ns</em><em>)</em>) – Structure matrices of all samples</p></li>
<li><p><strong>ps</strong> (<em>list of ndarray</em><em>, </em><em>each element has shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Masses of all samples.</p></li>
<li><p><strong>lambdas</strong> (<em>list of float</em>) – List of the S spaces’ weights</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Alpha parameter for the fgw distance</p></li>
<li><p><strong>fixed_structure</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to fix the structure of the barycenter during the updates</p></li>
<li><p><strong>fixed_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Whether to fix the feature of the barycenter during the updates</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0).</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>init_C</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>N</em><em>)</em><em>, </em><em>optional</em>) – Initialization for the barycenters’ structure matrix. If not set
a random init is used.</p></li>
<li><p><strong>init_X</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>d</em><em>)</em><em>, </em><em>optional</em>) – Initialization for the barycenters’ features. If not set a
random init is used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>X</strong> (<em>ndarray, shape (N, d)</em>) – Barycenters’ features</p></li>
<li><p><strong>C</strong> (<em>ndarray, shape (N, N)</em>) – Barycenters’ structure matrix</p></li>
<li><p><strong>log_</strong> (<em>dict</em>) – Only returned when log=True. It contains the keys:
T : list of (N,ns) transport matrices
Ms : all distance matrices between the feature of the barycenter and the
other features dist(X,Ys) shape (N,ns)</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id106"><span class="brackets">24</span></dt>
<dd><p>Vayer Titouan, Chapel Laetitia, Flamary R{‘e}mi, Tavenard Romain
and Courty Nicolas
“Optimal Transport for structured data with application on graphs”
International Conference on Machine Learning (ICML). 2019.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.gromov.fused_gromov_wasserstein">
<code class="sig-prename descclassname">ot.gromov.</code><code class="sig-name descname">fused_gromov_wasserstein</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">C1</span></em>, <em class="sig-param"><span class="n">C2</span></em>, <em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">q</span></em>, <em class="sig-param"><span class="n">loss_fun</span><span class="o">=</span><span class="default_value">'square_loss'</span></em>, <em class="sig-param"><span class="n">alpha</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">armijo</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/gromov.html#fused_gromov_wasserstein"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.gromov.fused_gromov_wasserstein" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the FGW transport between two graphs see [24]</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma (1-\alpha)*&lt;\gamma,M&gt;_F + \alpha* \sum_{i,j,k,l}
L(C1_{i,k},C2_{j,l})*T_{i,j}*T_{k,l}\\s.t. \gamma 1 = p
     \gamma^T 1= q
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :
- M is the (ns,nt) metric cost matrix
- p and q are source and target weights (sum to 1)
- L is a loss function to account for the misfit between the similarity matrices</p>
<p>The algorithm used for solving the problem is conditional gradient as discussed in  <a href="#id259"><span class="problematic" id="id107">[24]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix representative of the structure in the source space</p></li>
<li><p><strong>C2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix representative of the structure in the target space</p></li>
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the steps of the line-search is found via an armijo research. Else closed form is used.
If there is convergence issues use False.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>ndarray, shape (ns, nt)</em>) – Optimal transportation matrix for the given parameters.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Log dictionary return only if log==True in parameters.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id108"><span class="brackets">24</span></dt>
<dd><p>Vayer Titouan, Chapel Laetitia, Flamary R{‘e}mi, Tavenard Romain
and Courty Nicolas “Optimal Transport for structured data with
application on graphs”, International Conference on Machine Learning
(ICML). 2019.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.gromov.fused_gromov_wasserstein2">
<code class="sig-prename descclassname">ot.gromov.</code><code class="sig-name descname">fused_gromov_wasserstein2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">C1</span></em>, <em class="sig-param"><span class="n">C2</span></em>, <em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">q</span></em>, <em class="sig-param"><span class="n">loss_fun</span><span class="o">=</span><span class="default_value">'square_loss'</span></em>, <em class="sig-param"><span class="n">alpha</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">armijo</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/gromov.html#fused_gromov_wasserstein2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.gromov.fused_gromov_wasserstein2" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the FGW distance between two graphs see [24]</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\min_\gamma (1-\alpha)*&lt;\gamma,M&gt;_F + \alpha* \sum_{i,j,k,l}
L(C1_{i,k},C2_{j,l})*T_{i,j}*T_{k,l}\\s.t. \gamma 1 = p
     \gamma^T 1= q
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :
- M is the (ns,nt) metric cost matrix
- p and q are source and target weights (sum to 1)
- L is a loss function to account for the misfit between the similarity matrices
The algorithm used for solving the problem is conditional gradient as discussed in  <a href="#id260"><span class="problematic" id="id109">[1]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix between features across domains</p></li>
<li><p><strong>C1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix respresentative of the structure in the source space.</p></li>
<li><p><strong>C2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix espresentative of the structure in the target space.</p></li>
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space.</p></li>
<li><p><strong>q</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – Loss function used for the solver.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Trade-off parameter (0 &lt; alpha &lt; 1)</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the steps of the line-search is found via an armijo research.
Else closed form is used. If there is convergence issues use False.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – Parameters can be directly pased to the ot.optim.cg solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>ndarray, shape (ns, nt)</em>) – Optimal transportation matrix for the given parameters.</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – Log dictionary return only if log==True in parameters.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id110"><span class="brackets">24</span></dt>
<dd><p>Vayer Titouan, Chapel Laetitia, Flamary R{‘e}mi, Tavenard Romain
and Courty Nicolas
“Optimal Transport for structured data with application on graphs”
International Conference on Machine Learning (ICML). 2019.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.gromov.gromov_barycenters">
<code class="sig-prename descclassname">ot.gromov.</code><code class="sig-name descname">gromov_barycenters</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">N</span></em>, <em class="sig-param"><span class="n">Cs</span></em>, <em class="sig-param"><span class="n">ps</span></em>, <em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">lambdas</span></em>, <em class="sig-param"><span class="n">loss_fun</span></em>, <em class="sig-param"><span class="n">max_iter</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">init_C</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/gromov.html#gromov_barycenters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.gromov.gromov_barycenters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the gromov-wasserstein barycenters of S measured similarity matrices</p>
<p>(Cs)_{s=1}^{s=S}</p>
<p>The function solves the following optimization problem with block
coordinate descent:</p>
<div class="math notranslate nohighlight">
\[C = argmin_C\in R^NxN \sum_s \lambda_s GW(C,Cs,p,ps)\]</div>
<p>Where :</p>
<ul class="simple">
<li><p>Cs : metric cost matrix</p></li>
<li><p>ps  : distribution</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of the targeted barycenter</p></li>
<li><p><strong>Cs</strong> (<em>list of S np.ndarray of shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrices</p></li>
<li><p><strong>ps</strong> (<em>list of S np.ndarray of shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Sample weights in the S spaces</p></li>
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>)</em>) – Weights in the targeted barycenter</p></li>
<li><p><strong>lambdas</strong> (<em>list of float</em>) – List of the S spaces’ weights</p></li>
<li><p><strong>loss_fun</strong> (<em>tensor-matrix multiplication function based on specific loss function</em>) – </p></li>
<li><p><strong>update</strong> (<em>function</em><em>(</em><em>p</em><em>,</em><em>lambdas</em><em>,</em><em>T</em><em>,</em><em>Cs</em><em>) </em><em>that updates C according to a specific Kernel</em>) – with the S Ts couplings calculated at each iteration</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0).</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Record log if True.</p></li>
<li><p><strong>init_C</strong> (<em>bool | ndarray</em><em>, </em><em>shape</em><em>(</em><em>N</em><em>,</em><em>N</em><em>)</em>) – Random initial value for the C matrix provided by user.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>C</strong> – Similarity matrix in the barycenter space (permutated arbitrarily)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, shape (N, N)</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id111"><span class="brackets">12</span></dt>
<dd><p>Peyré, Gabriel, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.gromov.gromov_wasserstein">
<code class="sig-prename descclassname">ot.gromov.</code><code class="sig-name descname">gromov_wasserstein</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">C1</span></em>, <em class="sig-param"><span class="n">C2</span></em>, <em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">q</span></em>, <em class="sig-param"><span class="n">loss_fun</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">armijo</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/gromov.html#gromov_wasserstein"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.gromov.gromov_wasserstein" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the gromov-wasserstein transport between (C1,p) and (C2,q)</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[GW = \min_T \sum_{i,j,k,l} L(C1_{i,k},C2_{j,l})*T_{i,j}*T_{k,l}\]</div>
<p>Where :
- C1 : Metric cost matrix in the source space
- C2 : Metric cost matrix in the target space
- p  : distribution in the source space
- q  : distribution in the target space
- L  : loss function to account for the misfit between the similarity matrices</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric costfr matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the steps of the line-search is found via an armijo research. Else closed form is used.
If there is convergence issues use False.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – parameters can be directly passed to the ot.optim.cg solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul>
<li><p><strong>T</strong> (<em>ndarray, shape (ns, nt)</em>) –</p>
<dl class="simple">
<dt>Doupling between the two spaces that minimizes:</dt><dd><p>sum_{i,j,k,l} L(C1_{i,k},C2_{j,l})*T_{i,j}*T_{k,l}</p>
</dd>
</dl>
</li>
<li><p><strong>log</strong> (<em>dict</em>) – Convergence information and loss.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id112"><span class="brackets">12</span></dt>
<dd><p>Peyré, Gabriel, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</dd>
<dt class="label" id="id113"><span class="brackets">13</span></dt>
<dd><p>Mémoli, Facundo. Gromov–Wasserstein distances and the
metric approach to object matching. Foundations of computational
mathematics 11.4 (2011): 417-487.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.gromov.gromov_wasserstein2">
<code class="sig-prename descclassname">ot.gromov.</code><code class="sig-name descname">gromov_wasserstein2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">C1</span></em>, <em class="sig-param"><span class="n">C2</span></em>, <em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">q</span></em>, <em class="sig-param"><span class="n">loss_fun</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">armijo</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/gromov.html#gromov_wasserstein2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.gromov.gromov_wasserstein2" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the gromov-wasserstein discrepancy between (C1,p) and (C2,q)</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[GW = \min_T \sum_{i,j,k,l} L(C1_{i,k},C2_{j,l})*T_{i,j}*T_{k,l}\]</div>
<p>Where :
- C1 : Metric cost matrix in the source space
- C2 : Metric cost matrix in the target space
- p  : distribution in the source space
- q  : distribution in the target space
- L  : loss function to account for the misfit between the similarity matrices</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric cost matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space.</p></li>
<li><p><strong>q</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space.</p></li>
<li><p><strong>loss_fun</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – loss function used for the solver either ‘square_loss’ or ‘kl_loss’</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>armijo</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If True the steps of the line-search is found via an armijo research. Else closed form is used.
If there is convergence issues use False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gw_dist</strong> (<em>float</em>) – Gromov-Wasserstein distance</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – convergence information and Coupling marix</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id114"><span class="brackets">12</span></dt>
<dd><p>Peyré, Gabriel, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</dd>
<dt class="label" id="id115"><span class="brackets">13</span></dt>
<dd><p>Mémoli, Facundo. Gromov–Wasserstein distances and the
metric approach to object matching. Foundations of computational
mathematics 11.4 (2011): 417-487.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.gromov.gwggrad">
<code class="sig-prename descclassname">ot.gromov.</code><code class="sig-name descname">gwggrad</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">constC</span></em>, <em class="sig-param"><span class="n">hC1</span></em>, <em class="sig-param"><span class="n">hC2</span></em>, <em class="sig-param"><span class="n">T</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/gromov.html#gwggrad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.gromov.gwggrad" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the gradient for Gromov-Wasserstein</p>
<p>The gradient is computed as described in Proposition 2 in [12].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>constC</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Constant C matrix in Eq. (6)</p></li>
<li><p><strong>hC1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – h1(C1) matrix in Eq. (6)</p></li>
<li><p><strong>hC2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – h2(C) matrix in Eq. (6)</p></li>
<li><p><strong>T</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Current value of transport matrix T</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>grad</strong> – Gromov Wasserstein gradient</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, shape (ns, nt)</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id116"><span class="brackets">12</span></dt>
<dd><p>Peyré, Gabriel, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.gromov.gwloss">
<code class="sig-prename descclassname">ot.gromov.</code><code class="sig-name descname">gwloss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">constC</span></em>, <em class="sig-param"><span class="n">hC1</span></em>, <em class="sig-param"><span class="n">hC2</span></em>, <em class="sig-param"><span class="n">T</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/gromov.html#gwloss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.gromov.gwloss" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the Loss for Gromov-Wasserstein</p>
<p>The loss is computed as described in Proposition 1 Eq. (6) in [12].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>constC</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Constant C matrix in Eq. (6)</p></li>
<li><p><strong>hC1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – h1(C1) matrix in Eq. (6)</p></li>
<li><p><strong>hC2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – h2(C) matrix in Eq. (6)</p></li>
<li><p><strong>T</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Current value of transport matrix T</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>loss</strong> – Gromov Wasserstein loss</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id117"><span class="brackets">12</span></dt>
<dd><p>Peyré, Gabriel, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.gromov.init_matrix">
<code class="sig-prename descclassname">ot.gromov.</code><code class="sig-name descname">init_matrix</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">C1</span></em>, <em class="sig-param"><span class="n">C2</span></em>, <em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">q</span></em>, <em class="sig-param"><span class="n">loss_fun</span><span class="o">=</span><span class="default_value">'square_loss'</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/gromov.html#init_matrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.gromov.init_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Return loss matrices and tensors for Gromov-Wasserstein fast computation</p>
<p>Returns the value of mathcal{L}(C1,C2) otimes T with the selected loss
function as the loss function of Gromow-Wasserstein discrepancy.</p>
<p>The matrices are computed as described in Proposition 1 in [12]</p>
<dl class="simple">
<dt>Where :</dt><dd><ul class="simple">
<li><p>C1 : Metric cost matrix in the source space</p></li>
<li><p>C2 : Metric cost matrix in the target space</p></li>
<li><p>T : A coupling between those two spaces</p></li>
</ul>
</dd>
<dt>The square-loss function L(a,b)=|a-b|^2 is read as :</dt><dd><dl class="simple">
<dt>L(a,b) = f1(a)+f2(b)-h1(a)*h2(b) with :</dt><dd><ul class="simple">
<li><p>f1(a)=(a^2)</p></li>
<li><p>f2(b)=(b^2)</p></li>
<li><p>h1(a)=a</p></li>
<li><p>h2(b)=2*b</p></li>
</ul>
</dd>
</dl>
</dd>
<dt>The kl-loss function L(a,b)=a*log(a/b)-a+b is read as :</dt><dd><dl class="simple">
<dt>L(a,b) = f1(a)+f2(b)-h1(a)*h2(b) with :</dt><dd><ul class="simple">
<li><p>f1(a)=a*log(a)-a</p></li>
<li><p>f2(b)=b</p></li>
<li><p>h1(a)=a</p></li>
<li><p>h2(b)=log(b)</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric costfr matrix in the target space</p></li>
<li><p><strong>T</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Coupling between source and target spaces</p></li>
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>constC</strong> (<em>ndarray, shape (ns, nt)</em>) – Constant C matrix in Eq. (6)</p></li>
<li><p><strong>hC1</strong> (<em>ndarray, shape (ns, ns)</em>) – h1(C1) matrix in Eq. (6)</p></li>
<li><p><strong>hC2</strong> (<em>ndarray, shape (nt, nt)</em>) – h2(C) matrix in Eq. (6)</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id118"><span class="brackets">12</span></dt>
<dd><p>Peyré, Gabriel, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.gromov.tensor_product">
<code class="sig-prename descclassname">ot.gromov.</code><code class="sig-name descname">tensor_product</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">constC</span></em>, <em class="sig-param"><span class="n">hC1</span></em>, <em class="sig-param"><span class="n">hC2</span></em>, <em class="sig-param"><span class="n">T</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/gromov.html#tensor_product"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.gromov.tensor_product" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the tensor for Gromov-Wasserstein fast computation</p>
<p>The tensor is computed as described in Proposition 1 Eq. (6) in [12].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>constC</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Constant C matrix in Eq. (6)</p></li>
<li><p><strong>hC1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – h1(C1) matrix in Eq. (6)</p></li>
<li><p><strong>hC2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – h2(C) matrix in Eq. (6)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>tens</strong> – mathcal{L}(C1,C2) otimes T tensor-matrix multiplication result</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, shape (ns, nt)</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id119"><span class="brackets">12</span></dt>
<dd><p>Peyré, Gabriel, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.gromov.update_feature_matrix">
<code class="sig-prename descclassname">ot.gromov.</code><code class="sig-name descname">update_feature_matrix</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lambdas</span></em>, <em class="sig-param"><span class="n">Ys</span></em>, <em class="sig-param"><span class="n">Ts</span></em>, <em class="sig-param"><span class="n">p</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/gromov.html#update_feature_matrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.gromov.update_feature_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates the feature with respect to the S Ts couplings.</p>
<p>See “Solving the barycenter problem with Block Coordinate Descent (BCD)”
in [24] calculated at each iteration</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>)</em>) – masses in the targeted barycenter</p></li>
<li><p><strong>lambdas</strong> (<em>list of float</em>) – List of the S spaces’ weights</p></li>
<li><p><strong>Ts</strong> (<em>list of S np.ndarray</em><em>(</em><em>ns</em><em>,</em><em>N</em><em>)</em>) – the S Ts couplings calculated at each iteration</p></li>
<li><p><strong>Ys</strong> (<em>list of S ndarray</em><em>, </em><em>shape</em><em>(</em><em>d</em><em>,</em><em>ns</em><em>)</em>) – The features.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, shape (d, N)</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id120"><span class="brackets">24</span></dt>
<dd><dl class="simple">
<dt>Vayer Titouan, Chapel Laetitia, Flamary R{‘e}mi, Tavenard Romain</dt><dd><p>and Courty Nicolas</p>
</dd>
</dl>
<p>“Optimal Transport for structured data with application on graphs”
International Conference on Machine Learning (ICML). 2019.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.gromov.update_kl_loss">
<code class="sig-prename descclassname">ot.gromov.</code><code class="sig-name descname">update_kl_loss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">lambdas</span></em>, <em class="sig-param"><span class="n">T</span></em>, <em class="sig-param"><span class="n">Cs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/gromov.html#update_kl_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.gromov.update_kl_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates C according to the KL Loss kernel with the S Ts couplings calculated at each iteration</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>)</em>) – Weights in the targeted barycenter.</p></li>
<li><p><strong>lambdas</strong> (<em>list of the S spaces' weights</em>) – </p></li>
<li><p><strong>T</strong> (<em>list of S np.ndarray of shape</em><em> (</em><em>ns</em><em>,</em><em>N</em><em>)</em>) – The S Ts couplings calculated at each iteration.</p></li>
<li><p><strong>Cs</strong> (<em>list of S ndarray</em><em>, </em><em>shape</em><em>(</em><em>ns</em><em>,</em><em>ns</em><em>)</em>) – Metric cost matrices.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>C</strong> – updated C matrix</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, shape (ns,ns)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.gromov.update_square_loss">
<code class="sig-prename descclassname">ot.gromov.</code><code class="sig-name descname">update_square_loss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">lambdas</span></em>, <em class="sig-param"><span class="n">T</span></em>, <em class="sig-param"><span class="n">Cs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/gromov.html#update_square_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.gromov.update_square_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates C according to the L2 Loss kernel with the S Ts couplings
calculated at each iteration</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>)</em>) – Masses in the targeted barycenter.</p></li>
<li><p><strong>lambdas</strong> (<em>list of float</em>) – List of the S spaces’ weights.</p></li>
<li><p><strong>T</strong> (<em>list of S np.ndarray of shape</em><em> (</em><em>ns</em><em>,</em><em>N</em><em>)</em>) – The S Ts couplings calculated at each iteration.</p></li>
<li><p><strong>Cs</strong> (<em>list of S ndarray</em><em>, </em><em>shape</em><em>(</em><em>ns</em><em>,</em><em>ns</em><em>)</em>) – Metric cost matrices.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>C</strong> – Updated C matrix.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, shape (nt, nt)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.gromov.update_sructure_matrix">
<code class="sig-prename descclassname">ot.gromov.</code><code class="sig-name descname">update_sructure_matrix</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">lambdas</span></em>, <em class="sig-param"><span class="n">T</span></em>, <em class="sig-param"><span class="n">Cs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/gromov.html#update_sructure_matrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.gromov.update_sructure_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates C according to the L2 Loss kernel with the S Ts couplings.</p>
<p>It is calculated at each iteration</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>N</em><em>,</em><em>)</em>) – Masses in the targeted barycenter.</p></li>
<li><p><strong>lambdas</strong> (<em>list of float</em>) – List of the S spaces’ weights.</p></li>
<li><p><strong>T</strong> (<em>list of S ndarray of shape</em><em> (</em><em>ns</em><em>, </em><em>N</em><em>)</em>) – The S Ts couplings calculated at each iteration.</p></li>
<li><p><strong>Cs</strong> (<em>list of S ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrices.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>C</strong> – Updated C matrix.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, shape (nt, nt)</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ot.optim">
<span id="ot-optim"></span><h2>ot.optim<a class="headerlink" href="#module-ot.optim" title="Permalink to this headline">¶</a></h2>
<p>Optimization algorithms for OT</p>
<dl class="py function">
<dt id="ot.optim.cg">
<code class="sig-prename descclassname">ot.optim.</code><code class="sig-name descname">cg</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">f</span></em>, <em class="sig-param"><span class="n">df</span></em>, <em class="sig-param"><span class="n">G0</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">200</span></em>, <em class="sig-param"><span class="n">numItermaxEmd</span><span class="o">=</span><span class="default_value">100000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">stopThr2</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/optim.html#cg"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.optim.cg" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the general regularized OT problem with conditional gradient</p>
<blockquote>
<div><p>The function solves the following optimization problem:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg*f(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (ns,nt) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> is the regularization term ( and df is its gradient)</p></li>
<li><p>a and b are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is conditional gradient as discussed in  <a href="#id261"><span class="problematic" id="id121">[1]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt;0</p></li>
<li><p><strong>G0</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – initial guess (default is indep joint density)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>numItermaxEmd</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations for emd</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on the relative variation (&gt;0)</p></li>
<li><p><strong>stopThr2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on the absolute variation (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – Parameters for linesearch</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id122"><span class="brackets">1</span></dt>
<dd><p>Ferradans, S., Papadakis, N., Peyré, G., &amp; Aujol, J. F. (2014). Regularized discrete optimal transport. SIAM Journal on Imaging Sciences, 7(3), 1853-1882.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized optimal ransport</p>
</dd>
<dt><a class="reference internal" href="#ot.bregman.sinkhorn" title="ot.bregman.sinkhorn"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn()</span></code></a></dt><dd><p>Entropic regularized optimal transport</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.optim.gcg">
<code class="sig-prename descclassname">ot.optim.</code><code class="sig-name descname">gcg</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg1</span></em>, <em class="sig-param"><span class="n">reg2</span></em>, <em class="sig-param"><span class="n">f</span></em>, <em class="sig-param"><span class="n">df</span></em>, <em class="sig-param"><span class="n">G0</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">numInnerItermax</span><span class="o">=</span><span class="default_value">200</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">stopThr2</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/optim.html#gcg"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.optim.gcg" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the general regularized OT problem with the generalized conditional gradient</p>
<blockquote>
<div><p>The function solves the following optimization problem:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg1\cdot\Omega(\gamma) + reg2\cdot f(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (ns,nt) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> is the regularization term ( and df is its gradient)</p></li>
<li><p>a and b are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the generalized conditional gradient as discussed in  [5,7]_</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>ndarrayv</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg1</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Entropic Regularization term &gt;0</p></li>
<li><p><strong>reg2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Second Regularization term &gt;0</p></li>
<li><p><strong>G0</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – initial guess (default is indep joint density)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>numInnerItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations of Sinkhorn</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on the relative variation (&gt;0)</p></li>
<li><p><strong>stopThr2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on the absolute variation (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>ndarray, shape (ns, nt)</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id123"><span class="brackets">5</span></dt>
<dd><ol class="upperalpha simple" start="14">
<li><p>Courty; R. Flamary; D. Tuia; A. Rakotomamonjy, “Optimal Transport for Domain Adaptation,” in IEEE Transactions on Pattern Analysis and Machine Intelligence , vol.PP, no.99, pp.1-1</p></li>
</ol>
</dd>
<dt class="label" id="id124"><span class="brackets">7</span></dt>
<dd><p>Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015). Generalized conditional gradient: analysis of convergence and applications. arXiv preprint arXiv:1510.06567.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>conditional gradient</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.optim.line_search_armijo">
<code class="sig-prename descclassname">ot.optim.</code><code class="sig-name descname">line_search_armijo</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">f</span></em>, <em class="sig-param"><span class="n">xk</span></em>, <em class="sig-param"><span class="n">pk</span></em>, <em class="sig-param"><span class="n">gfk</span></em>, <em class="sig-param"><span class="n">old_fval</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">()</span></em>, <em class="sig-param"><span class="n">c1</span><span class="o">=</span><span class="default_value">0.0001</span></em>, <em class="sig-param"><span class="n">alpha0</span><span class="o">=</span><span class="default_value">0.99</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/optim.html#line_search_armijo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.optim.line_search_armijo" title="Permalink to this definition">¶</a></dt>
<dd><p>Armijo linesearch function that works with matrices</p>
<p>find an approximate minimum of f(xk+alpha*pk) that satifies the
armijo conditions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>f</strong> (<em>callable</em>) – loss function</p></li>
<li><p><strong>xk</strong> (<em>ndarray</em>) – initial position</p></li>
<li><p><strong>pk</strong> (<em>ndarray</em>) – descent direction</p></li>
<li><p><strong>gfk</strong> (<em>ndarray</em>) – gradient of f at xk</p></li>
<li><p><strong>old_fval</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – loss value at xk</p></li>
<li><p><strong>args</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><em>optional</em>) – arguments given to f</p></li>
<li><p><strong>c1</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – c1 const in armijo rule (&gt;0)</p></li>
<li><p><strong>alpha0</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – initial step (&gt;0)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>alpha</strong> (<em>float</em>) – step that satisfy armijo conditions</p></li>
<li><p><strong>fc</strong> (<em>int</em>) – nb of function call</p></li>
<li><p><strong>fa</strong> (<em>float</em>) – loss value at step alpha</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.optim.solve_1d_linesearch_quad">
<code class="sig-prename descclassname">ot.optim.</code><code class="sig-name descname">solve_1d_linesearch_quad</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">c</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/optim.html#solve_1d_linesearch_quad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.optim.solve_1d_linesearch_quad" title="Permalink to this definition">¶</a></dt>
<dd><p>For any convex or non-convex 1d quadratic function f, solve on [0,1] the following problem:
.. math:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>rgmin f(x)=a*x^{2}+b*x+c
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>a</strong><strong>,</strong><strong>b</strong><strong>,</strong><strong>c</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The coefficients of the quadratic function</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>x</strong> – The optimal value which leads to the minimal cost</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.optim.solve_linesearch">
<code class="sig-prename descclassname">ot.optim.</code><code class="sig-name descname">solve_linesearch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cost</span></em>, <em class="sig-param"><span class="n">G</span></em>, <em class="sig-param"><span class="n">deltaG</span></em>, <em class="sig-param"><span class="n">Mi</span></em>, <em class="sig-param"><span class="n">f_val</span></em>, <em class="sig-param"><span class="n">armijo</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">C1</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">C2</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">reg</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Gc</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">constC</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">M</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/optim.html#solve_linesearch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.optim.solve_linesearch" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the linesearch in the FW iterations
:param cost: Cost in the FW for the linesearch
:type cost: method
:param G: The transport map at a given iteration of the FW
:type G: ndarray, shape(ns,nt)
:param deltaG: Difference between the optimal map found by linearization in the FW algorithm and the value at a given iteration
:type deltaG: ndarray (ns,nt)
:param Mi: Cost matrix of the linearized transport problem. Corresponds to the gradient of the cost
:type Mi: ndarray (ns,nt)
:param f_val: Value of the cost at G
:type f_val: float
:param armijo: If True the steps of the line-search is found via an armijo research. Else closed form is used.</p>
<blockquote>
<div><p>If there is convergence issues use False.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>ndarray</em><em> (</em><em>ns</em><em>,</em><em>ns</em><em>)</em><em>, </em><em>optional</em>) – Structure matrix in the source domain. Only used and necessary when armijo=False</p></li>
<li><p><strong>C2</strong> (<em>ndarray</em><em> (</em><em>nt</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Structure matrix in the target domain. Only used and necessary when armijo=False</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization parameter. Only used and necessary when armijo=False</p></li>
<li><p><strong>Gc</strong> (<em>ndarray</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – Optimal map found by linearization in the FW algorithm. Only used and necessary when armijo=False</p></li>
<li><p><strong>constC</strong> (<em>ndarray</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – Constant for the gromov cost. See [24]. Only used and necessary when armijo=False</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Cost matrix between the features. Only used and necessary when armijo=False</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>alpha</strong> (<em>float</em>) – The optimal step size of the FW</p></li>
<li><p><strong>fc</strong> (<em>int</em>) – nb of function call. Useless here</p></li>
<li><p><strong>f_val</strong> (<em>float</em>) – The value of the cost for the next iteration</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id125"><span class="brackets">24</span></dt>
<dd><dl class="simple">
<dt>Vayer Titouan, Chapel Laetitia, Flamary R{‘e}mi, Tavenard Romain</dt><dd><p>and Courty Nicolas</p>
</dd>
</dl>
<p>“Optimal Transport for structured data with application on graphs”
International Conference on Machine Learning (ICML). 2019.</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ot.da">
<span id="ot-da"></span><h2>ot.da<a class="headerlink" href="#module-ot.da" title="Permalink to this headline">¶</a></h2>
<p>Domain adaptation with optimal transport</p>
<dl class="py class">
<dt id="ot.da.BaseTransport">
<em class="property">class </em><code class="sig-prename descclassname">ot.da.</code><code class="sig-name descname">BaseTransport</code><a class="reference internal" href="_modules/ot/da.html#BaseTransport"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.BaseTransport" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for OTDA objects</p>
<p class="rubric">Notes</p>
<p>All estimators should specify all the parameters that can be set
at the class level in their <code class="docutils literal notranslate"><span class="pre">__init__</span></code> as explicit keyword
arguments (no <code class="docutils literal notranslate"><span class="pre">*args</span></code> or <code class="docutils literal notranslate"><span class="pre">**kwargs</span></code>).</p>
<p>fit method should:
- estimate a cost matrix and store it in a <cite>cost_</cite> attribute
- estimate a coupling matrix and store it in a <cite>coupling_</cite>
attribute
- estimate distributions from source and target data and store them in
mu_s and mu_t attributes
- store Xs and Xt in attributes to be used later on in transform and
inverse_transform methods</p>
<p>transform method should always get as input a Xs parameter
inverse_transform method should always get as input a Xt parameter</p>
<p>transform_labels method should always get as input a ys parameter
inverse_transform_labels method should always get as input a yt parameter</p>
<dl class="py method">
<dt id="ot.da.BaseTransport.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Xt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#BaseTransport.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.BaseTransport.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Build a coupling matrix from source and target sets of samples
(Xs, ys) and (Xt, yt)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>ys</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>,</em><em>)</em>) – The class labels</p></li>
<li><p><strong>Xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>,</em><em>)</em>) – <p>The class labels. If some target samples are unlabeled, fill the
yt’s elements with -1.</p>
<p>Warning: Note that, due to this convention -1 cannot be used as a
class label</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Returns self.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)">object</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.da.BaseTransport.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Xt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#BaseTransport.fit_transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.BaseTransport.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Build a coupling matrix from source and target sets of samples
(Xs, ys) and (Xt, yt) and transports source samples Xs onto target
ones Xt</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>ys</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>,</em><em>)</em>) – The class labels</p></li>
<li><p><strong>Xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>,</em><em>)</em>) – <p>The class labels. If some target samples are unlabeled, fill the
yt’s elements with -1.</p>
<p>Warning: Note that, due to this convention -1 cannot be used as a
class label</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>transp_Xs</strong> – The source samples samples.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array-like, shape (n_source_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.da.BaseTransport.inverse_transform">
<code class="sig-name descname">inverse_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Xt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">batch_size</span><span class="o">=</span><span class="default_value">128</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#BaseTransport.inverse_transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.BaseTransport.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transports target samples Xt onto target samples Xs</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>ys</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>,</em><em>)</em>) – The class labels</p></li>
<li><p><strong>Xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>,</em><em>)</em>) – <p>The class labels. If some target samples are unlabeled, fill the
yt’s elements with -1.</p>
<p>Warning: Note that, due to this convention -1 cannot be used as a
class label</p>
</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=128</em><em>)</em>) – The batch size for out of sample inverse transform</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>transp_Xt</strong> – The transported target samples.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array-like, shape (n_source_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.da.BaseTransport.inverse_transform_labels">
<code class="sig-name descname">inverse_transform_labels</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#BaseTransport.inverse_transform_labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.BaseTransport.inverse_transform_labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Propagate target labels yt to obtain estimated source labels ys</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>,</em><em>)</em>) – </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>transp_ys</strong> – Estimated soft source labels.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array-like, shape (n_source_samples, nb_classes)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.da.BaseTransport.transform">
<code class="sig-name descname">transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Xt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">batch_size</span><span class="o">=</span><span class="default_value">128</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#BaseTransport.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.BaseTransport.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transports source samples Xs onto target ones Xt</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>ys</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>,</em><em>)</em>) – The class labels</p></li>
<li><p><strong>Xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>,</em><em>)</em>) – <p>The class labels. If some target samples are unlabeled, fill the
yt’s elements with -1.</p>
<p>Warning: Note that, due to this convention -1 cannot be used as a
class label</p>
</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=128</em><em>)</em>) – The batch size for out of sample inverse transform</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>transp_Xs</strong> – The transport source samples.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array-like, shape (n_source_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.da.BaseTransport.transform_labels">
<code class="sig-name descname">transform_labels</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#BaseTransport.transform_labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.BaseTransport.transform_labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Propagate source labels ys to obtain estimated target labels as in [27]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>ys</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>,</em><em>)</em>) – The class labels</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>transp_ys</strong> – Estimated soft target labels.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array-like, shape (n_target_samples, nb_classes)</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id126"><span class="brackets">27</span></dt>
<dd><p>Ievgen Redko, Nicolas Courty, Rémi Flamary, Devis Tuia
“Optimal transport for multi-source domain adaptation under target shift”,
International Conference on Artificial Intelligence and Statistics (AISTATS), 2019.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="ot.da.EMDLaplaceTransport">
<em class="property">class </em><code class="sig-prename descclassname">ot.da.</code><code class="sig-name descname">EMDLaplaceTransport</code><span class="sig-paren">(</span><em class="sig-param">reg_type='pos'</em>, <em class="sig-param">reg_lap=1.0</em>, <em class="sig-param">reg_src=1.0</em>, <em class="sig-param">metric='sqeuclidean'</em>, <em class="sig-param">norm=None</em>, <em class="sig-param">similarity='knn'</em>, <em class="sig-param">similarity_param=None</em>, <em class="sig-param">max_iter=100</em>, <em class="sig-param">tol=1e-09</em>, <em class="sig-param">max_inner_iter=100000</em>, <em class="sig-param">inner_tol=1e-09</em>, <em class="sig-param">log=False</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">distribution_estimation=&lt;function distribution_estimation_uniform&gt;</em>, <em class="sig-param">out_of_sample_map='ferradans'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#EMDLaplaceTransport"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.EMDLaplaceTransport" title="Permalink to this definition">¶</a></dt>
<dd><p>Domain Adapatation OT method based on Earth Mover’s Distance with Laplacian regularization</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reg_type</strong> (<em>string optional</em><em> (</em><em>default='pos'</em><em>)</em>) – Type of the regularization term: ‘pos’ and ‘disp’ for
regularization term defined in [2] and [6], respectively.</p></li>
<li><p><strong>reg_lap</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – Laplacian regularization parameter</p></li>
<li><p><strong>reg_src</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=0.5</em><em>)</em>) – Source relative importance in regularization</p></li>
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;sqeuclidean&quot;</em><em>)</em>) – The ground metric for the Wasserstein problem</p></li>
<li><p><strong>norm</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If given, normalize the ground metric to avoid numerical errors that
can occur with large metric values.</p></li>
<li><p><strong>similarity</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;knn&quot;</em><em>)</em>) – The similarity to use either knn or gaussian</p></li>
<li><p><strong>similarity_param</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – Parameter for the similarity: number of nearest neighbors or bandwidth
if similarity=”knn” or “gaussian”, respectively. If None is provided,
it is set to 3 or the average pairwise squared Euclidean distance, respectively.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=100</em><em>)</em>) – Max number of BCD iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1e-5</em><em>)</em>) – Stop threshold on relative loss decrease (&gt;0)</p></li>
<li><p><strong>max_inner_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – Max number of iterations (inner CG solver)</p></li>
<li><p><strong>inner_tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1e-6</em><em>)</em>) – Stop threshold on error (inner CG solver) (&gt;0)</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Controls the logs of the optimization algorithm</p></li>
<li><p><strong>distribution_estimation</strong> (<em>callable</em><em>, </em><em>optional</em><em> (</em><em>defaults to the uniform</em><em>)</em>) – The kind of distribution estimation to employ</p></li>
<li><p><strong>out_of_sample_map</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;ferradans&quot;</em><em>)</em>) – The kind of out of sample mapping to apply to transport samples
from a domain into another one. Currently the only possible option is
“ferradans” which uses the method proposed in [6].</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt>
<code class="sig-name descname">coupling\_</code></dt>
<dd><p>The optimal coupling</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like, shape (n_source_samples, n_target_samples)</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id127"><span class="brackets">1</span></dt>
<dd><p>N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,
“Optimal Transport for Domain Adaptation,” in IEEE Transactions
on Pattern Analysis and Machine Intelligence , vol.PP, no.99, pp.1-1</p>
</dd>
<dt class="label" id="id128"><span class="brackets">2</span></dt>
<dd><p>R. Flamary, N. Courty, D. Tuia, A. Rakotomamonjy,
“Optimal transport with Laplacian regularization: Applications to domain adaptation and shape matching,”</p>
<blockquote>
<div><p>in NIPS Workshop on Optimal Transport and Machine Learning OTML, 2014.</p>
</div></blockquote>
</dd>
</dl>
<dl class="py method">
<dt id="ot.da.EMDLaplaceTransport.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span></em>, <em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Xt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#EMDLaplaceTransport.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.EMDLaplaceTransport.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Build a coupling matrix from source and target sets of samples
(Xs, ys) and (Xt, yt)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>ys</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>,</em><em>)</em>) – The class labels</p></li>
<li><p><strong>Xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>,</em><em>)</em>) – <p>The class labels. If some target samples are unlabeled, fill the
yt’s elements with -1.</p>
<p>Warning: Note that, due to this convention -1 cannot be used as a
class label</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Returns self.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)">object</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="ot.da.EMDTransport">
<em class="property">class </em><code class="sig-prename descclassname">ot.da.</code><code class="sig-name descname">EMDTransport</code><span class="sig-paren">(</span><em class="sig-param">metric='sqeuclidean'</em>, <em class="sig-param">norm=None</em>, <em class="sig-param">log=False</em>, <em class="sig-param">distribution_estimation=&lt;function distribution_estimation_uniform&gt;</em>, <em class="sig-param">out_of_sample_map='ferradans'</em>, <em class="sig-param">limit_max=10</em>, <em class="sig-param">max_iter=100000</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#EMDTransport"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.EMDTransport" title="Permalink to this definition">¶</a></dt>
<dd><p>Domain Adapatation OT method based on Earth Mover’s Distance</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;sqeuclidean&quot;</em><em>)</em>) – The ground metric for the Wasserstein problem</p></li>
<li><p><strong>norm</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If given, normalize the ground metric to avoid numerical errors that
can occur with large metric values.</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Controls the logs of the optimization algorithm</p></li>
<li><p><strong>distribution_estimation</strong> (<em>callable</em><em>, </em><em>optional</em><em> (</em><em>defaults to the uniform</em><em>)</em>) – The kind of distribution estimation to employ</p></li>
<li><p><strong>out_of_sample_map</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;ferradans&quot;</em><em>)</em>) – The kind of out of sample mapping to apply to transport samples
from a domain into another one. Currently the only possible option is
“ferradans” which uses the method proposed in [6].</p></li>
<li><p><strong>limit_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – Controls the semi supervised mode. Transport between labeled source
and target samples of different classes will exhibit an infinite cost
(10 times the maximum value of the cost matrix)</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=100000</em><em>)</em>) – The maximum number of iterations before stopping the optimization
algorithm if it has not converged.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt>
<code class="sig-name descname">coupling\_</code></dt>
<dd><p>The optimal coupling</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like, shape (n_source_samples, n_target_samples)</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id129"><span class="brackets">1</span></dt>
<dd><p>N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,
“Optimal Transport for Domain Adaptation,” in IEEE Transactions
on Pattern Analysis and Machine Intelligence , vol.PP, no.99, pp.1-1</p>
</dd>
</dl>
<dl class="py method">
<dt id="ot.da.EMDTransport.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span></em>, <em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Xt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#EMDTransport.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.EMDTransport.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Build a coupling matrix from source and target sets of samples
(Xs, ys) and (Xt, yt)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>ys</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>,</em><em>)</em>) – The class labels</p></li>
<li><p><strong>Xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>,</em><em>)</em>) – <p>The class labels. If some target samples are unlabeled, fill the
yt’s elements with -1.</p>
<p>Warning: Note that, due to this convention -1 cannot be used as a
class label</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Returns self.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)">object</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="ot.da.JCPOTTransport">
<em class="property">class </em><code class="sig-prename descclassname">ot.da.</code><code class="sig-name descname">JCPOTTransport</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">reg_e</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">max_iter</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">1e-08</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">'sqeuclidean'</span></em>, <em class="sig-param"><span class="n">out_of_sample_map</span><span class="o">=</span><span class="default_value">'ferradans'</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#JCPOTTransport"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.JCPOTTransport" title="Permalink to this definition">¶</a></dt>
<dd><p>Domain Adapatation OT method for multi-source target shift based on Wasserstein barycenter algorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reg_e</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – Entropic regularization parameter</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – The minimum number of iteration before stopping the optimization
algorithm if no it has not converged</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=10e-9</em><em>)</em>) – Stop threshold on error (inner sinkhorn solver) (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Controls the verbosity of the optimization algorithm</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Controls the logs of the optimization algorithm</p></li>
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;sqeuclidean&quot;</em><em>)</em>) – The ground metric for the Wasserstein problem</p></li>
<li><p><strong>norm</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If given, normalize the ground metric to avoid numerical errors that
can occur with large metric values.</p></li>
<li><p><strong>distribution_estimation</strong> (<em>callable</em><em>, </em><em>optional</em><em> (</em><em>defaults to the uniform</em><em>)</em>) – The kind of distribution estimation to employ</p></li>
<li><p><strong>out_of_sample_map</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;ferradans&quot;</em><em>)</em>) – The kind of out of sample mapping to apply to transport samples
from a domain into another one. Currently the only possible option is
“ferradans” which uses the method proposed in [6].</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt>
<code class="sig-name descname">coupling\_</code></dt>
<dd><p>A set of optimal couplings between each source domain and the target domain</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list of array-like objects, shape K x (n_source_samples, n_target_samples)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt>
<code class="sig-name descname">proportions\_</code></dt>
<dd><p>Estimated class proportions in the target domain</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like, shape (n_classes,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt>
<code class="sig-name descname">log\_</code></dt>
<dd><p>The dictionary of log, empty dic if parameter log is not True</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dictionary</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id130"><span class="brackets">1</span></dt>
<dd><p>Ievgen Redko, Nicolas Courty, Rémi Flamary, Devis Tuia
“Optimal transport for multi-source domain adaptation under target shift”,
International Conference on Artificial Intelligence and Statistics (AISTATS),
vol. 89, p.849-858, 2019.</p>
</dd>
</dl>
<dl class="py method">
<dt id="ot.da.JCPOTTransport.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span></em>, <em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Xt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#JCPOTTransport.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.JCPOTTransport.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Building coupling matrices from a list of source and target sets of samples
(Xs, ys) and (Xt, yt)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<em>list of K array-like objects</em><em>, </em><em>shape K x</em><em> (</em><em>nk_source_samples</em><em>, </em><em>n_features</em><em>)</em>) – A list of the training input samples.</p></li>
<li><p><strong>ys</strong> (<em>list of K array-like objects</em><em>, </em><em>shape K x</em><em> (</em><em>nk_source_samples</em><em>,</em><em>)</em>) – A list of the class labels</p></li>
<li><p><strong>Xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>,</em><em>)</em>) – <p>The class labels. If some target samples are unlabeled, fill the
yt’s elements with -1.</p>
<p>Warning: Note that, due to this convention -1 cannot be used as a
class label</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Returns self.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)">object</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.da.JCPOTTransport.inverse_transform_labels">
<code class="sig-name descname">inverse_transform_labels</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#JCPOTTransport.inverse_transform_labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.JCPOTTransport.inverse_transform_labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Propagate source labels ys to obtain target labels</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>,</em><em>)</em>) – The target class labels</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>transp_ys</strong> – A list of estimated soft source labels</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list of K array-like objects, shape K x (nk_source_samples, nb_classes)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.da.JCPOTTransport.transform">
<code class="sig-name descname">transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Xt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">batch_size</span><span class="o">=</span><span class="default_value">128</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#JCPOTTransport.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.JCPOTTransport.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transports source samples Xs onto target ones Xt</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<em>list of K array-like objects</em><em>, </em><em>shape K x</em><em> (</em><em>nk_source_samples</em><em>, </em><em>n_features</em><em>)</em>) – A list of the training input samples.</p></li>
<li><p><strong>ys</strong> (<em>list of K array-like objects</em><em>, </em><em>shape K x</em><em> (</em><em>nk_source_samples</em><em>,</em><em>)</em>) – A list of the class labels</p></li>
<li><p><strong>Xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>,</em><em>)</em>) – <p>The class labels. If some target samples are unlabeled, fill the
yt’s elements with -1.</p>
<p>Warning: Note that, due to this convention -1 cannot be used as a
class label</p>
</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=128</em><em>)</em>) – The batch size for out of sample inverse transform</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.da.JCPOTTransport.transform_labels">
<code class="sig-name descname">transform_labels</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#JCPOTTransport.transform_labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.JCPOTTransport.transform_labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Propagate source labels ys to obtain target labels as in [27]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>ys</strong> (<em>list of K array-like objects</em><em>, </em><em>shape K x</em><em> (</em><em>nk_source_samples</em><em>,</em><em>)</em>) – A list of the class labels</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>yt</strong> – Estimated soft target labels.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array-like, shape (n_target_samples, nb_classes)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="ot.da.LinearTransport">
<em class="property">class </em><code class="sig-prename descclassname">ot.da.</code><code class="sig-name descname">LinearTransport</code><span class="sig-paren">(</span><em class="sig-param">reg=1e-08</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">log=False</em>, <em class="sig-param">distribution_estimation=&lt;function distribution_estimation_uniform&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#LinearTransport"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.LinearTransport" title="Permalink to this definition">¶</a></dt>
<dd><p>OT linear operator between empirical distributions</p>
<p>The function estimates the optimal linear operator that aligns the two
empirical distributions. This is equivalent to estimating the closed
form mapping between two Gaussian distributions <span class="math notranslate nohighlight">\(N(\mu_s,\Sigma_s)\)</span>
and <span class="math notranslate nohighlight">\(N(\mu_t,\Sigma_t)\)</span> as proposed in [14] and discussed in
remark 2.29 in [15].</p>
<p>The linear operator from source to target <span class="math notranslate nohighlight">\(M\)</span></p>
<div class="math notranslate nohighlight">
\[M(x)=Ax+b\]</div>
<p>where :</p>
<div class="math notranslate nohighlight">
\[A=\Sigma_s^{-1/2}(\Sigma_s^{1/2}\Sigma_t\Sigma_s^{1/2})^{1/2}
\Sigma_s^{-1/2}\]</div>
<div class="math notranslate nohighlight">
\[b=\mu_t-A\mu_s\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>,</em><em>optional</em>) – regularization added to the daigonals of convariances (&gt;0)</p></li>
<li><p><strong>bias</strong> (<em>boolean</em><em>, </em><em>optional</em>) – estimate bias b else b=0 (default:True)</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id131"><span class="brackets">14</span></dt>
<dd><p>Knott, M. and Smith, C. S. “On the optimal mapping of
distributions”, Journal of Optimization Theory and Applications
Vol 43, 1984</p>
</dd>
<dt class="label" id="id132"><span class="brackets">15</span></dt>
<dd><p>Peyré, G., &amp; Cuturi, M. (2017). “Computational Optimal
Transport”, 2018.</p>
</dd>
</dl>
<dl class="py method">
<dt id="ot.da.LinearTransport.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Xt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#LinearTransport.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.LinearTransport.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Build a coupling matrix from source and target sets of samples
(Xs, ys) and (Xt, yt)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>ys</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>,</em><em>)</em>) – The class labels</p></li>
<li><p><strong>Xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>,</em><em>)</em>) – <p>The class labels. If some target samples are unlabeled, fill the
yt’s elements with -1.</p>
<p>Warning: Note that, due to this convention -1 cannot be used as a
class label</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Returns self.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)">object</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.da.LinearTransport.inverse_transform">
<code class="sig-name descname">inverse_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Xt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">batch_size</span><span class="o">=</span><span class="default_value">128</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#LinearTransport.inverse_transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.LinearTransport.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transports target samples Xt onto target samples Xs</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>ys</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>,</em><em>)</em>) – The class labels</p></li>
<li><p><strong>Xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>,</em><em>)</em>) – <p>The class labels. If some target samples are unlabeled, fill the
yt’s elements with -1.</p>
<p>Warning: Note that, due to this convention -1 cannot be used as a
class label</p>
</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=128</em><em>)</em>) – The batch size for out of sample inverse transform</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>transp_Xt</strong> – The transported target samples.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array-like, shape (n_source_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.da.LinearTransport.transform">
<code class="sig-name descname">transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Xt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">batch_size</span><span class="o">=</span><span class="default_value">128</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#LinearTransport.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.LinearTransport.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transports source samples Xs onto target ones Xt</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>ys</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>,</em><em>)</em>) – The class labels</p></li>
<li><p><strong>Xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>,</em><em>)</em>) – <p>The class labels. If some target samples are unlabeled, fill the
yt’s elements with -1.</p>
<p>Warning: Note that, due to this convention -1 cannot be used as a
class label</p>
</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=128</em><em>)</em>) – The batch size for out of sample inverse transform</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>transp_Xs</strong> – The transport source samples.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array-like, shape (n_source_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="ot.da.MappingTransport">
<em class="property">class </em><code class="sig-prename descclassname">ot.da.</code><code class="sig-name descname">MappingTransport</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mu</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">eta</span><span class="o">=</span><span class="default_value">0.001</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">'sqeuclidean'</span></em>, <em class="sig-param"><span class="n">norm</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">kernel</span><span class="o">=</span><span class="default_value">'linear'</span></em>, <em class="sig-param"><span class="n">sigma</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">max_iter</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">1e-05</span></em>, <em class="sig-param"><span class="n">max_inner_iter</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">inner_tol</span><span class="o">=</span><span class="default_value">1e-06</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose2</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#MappingTransport"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.MappingTransport" title="Permalink to this definition">¶</a></dt>
<dd><p>MappingTransport: DA methods that aims at jointly estimating a optimal
transport coupling and the associated mapping</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mu</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – Weight for the linear OT loss (&gt;0)</p></li>
<li><p><strong>eta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=0.001</em><em>)</em>) – Regularization term for the linear mapping L (&gt;0)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Estimate linear mapping with constant bias</p></li>
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;sqeuclidean&quot;</em><em>)</em>) – The ground metric for the Wasserstein problem</p></li>
<li><p><strong>norm</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If given, normalize the ground metric to avoid numerical errors that
can occur with large metric values.</p></li>
<li><p><strong>kernel</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;linear&quot;</em><em>)</em>) – The kernel to use either linear or gaussian</p></li>
<li><p><strong>sigma</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – The gaussian kernel parameter</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=100</em><em>)</em>) – Max number of BCD iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1e-5</em><em>)</em>) – Stop threshold on relative loss decrease (&gt;0)</p></li>
<li><p><strong>max_inner_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – Max number of iterations (inner CG solver)</p></li>
<li><p><strong>inner_tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1e-6</em><em>)</em>) – Stop threshold on error (inner CG solver) (&gt;0)</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – record log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Print information along iterations</p></li>
<li><p><strong>verbose2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Print information along iterations</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt>
<code class="sig-name descname">coupling\_</code></dt>
<dd><p>The optimal coupling</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like, shape (n_source_samples, n_target_samples)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt>
<code class="sig-name descname">mapping\_</code></dt>
<dd><p>(if bias) for kernel == linear
The associated mapping
array-like, shape (n_source_samples (+ 1), n_features)
(if bias) for kernel == gaussian</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like, shape (n_features (+ 1), n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt>
<code class="sig-name descname">log\_</code></dt>
<dd><p>The dictionary of log, empty dic if parameter log is not True</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dictionary</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id133"><span class="brackets">8</span></dt>
<dd><p>M. Perrot, N. Courty, R. Flamary, A. Habrard,
“Mapping estimation for discrete optimal transport”,
Neural Information Processing Systems (NIPS), 2016.</p>
</dd>
</dl>
<dl class="py method">
<dt id="ot.da.MappingTransport.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Xt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#MappingTransport.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.MappingTransport.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds an optimal coupling and estimates the associated mapping
from source and target sets of samples (Xs, ys) and (Xt, yt)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>ys</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>,</em><em>)</em>) – The class labels</p></li>
<li><p><strong>Xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>,</em><em>)</em>) – <p>The class labels. If some target samples are unlabeled, fill the
yt’s elements with -1.</p>
<p>Warning: Note that, due to this convention -1 cannot be used as a
class label</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Returns self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)">object</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.da.MappingTransport.transform">
<code class="sig-name descname">transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#MappingTransport.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.MappingTransport.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transports source samples Xs onto target ones Xt</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>Xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>transp_Xs</strong> – The transport source samples.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array-like, shape (n_source_samples, n_features)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="ot.da.OT_mapping_linear">
<code class="sig-prename descclassname">ot.da.</code><code class="sig-name descname">OT_mapping_linear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">xs</span></em>, <em class="sig-param"><span class="n">xt</span></em>, <em class="sig-param"><span class="n">reg</span><span class="o">=</span><span class="default_value">1e-06</span></em>, <em class="sig-param"><span class="n">ws</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">wt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#OT_mapping_linear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.OT_mapping_linear" title="Permalink to this definition">¶</a></dt>
<dd><p>return OT linear operator between samples</p>
<p>The function estimates the optimal linear operator that aligns the two
empirical distributions. This is equivalent to estimating the closed
form mapping between two Gaussian distributions <span class="math notranslate nohighlight">\(N(\mu_s,\Sigma_s)\)</span>
and <span class="math notranslate nohighlight">\(N(\mu_t,\Sigma_t)\)</span> as proposed in [14] and discussed in remark
2.29 in [15].</p>
<p>The linear operator from source to target <span class="math notranslate nohighlight">\(M\)</span></p>
<div class="math notranslate nohighlight">
\[M(x)=Ax+b\]</div>
<p>where :</p>
<div class="math notranslate nohighlight">
\[A=\Sigma_s^{-1/2}(\Sigma_s^{1/2}\Sigma_t\Sigma_s^{1/2})^{1/2}
\Sigma_s^{-1/2}\]</div>
<div class="math notranslate nohighlight">
\[b=\mu_t-A\mu_s\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – samples in the source domain</p></li>
<li><p><strong>xt</strong> (<em>np.ndarray</em><em> (</em><em>nt</em><em>,</em><em>d</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>,</em><em>optional</em>) – regularization added to the diagonals of convariances (&gt;0)</p></li>
<li><p><strong>ws</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>1</em><em>)</em><em>, </em><em>optional</em>) – weights for the source samples</p></li>
<li><p><strong>wt</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>1</em><em>)</em><em>, </em><em>optional</em>) – weights for the target samples</p></li>
<li><p><strong>bias</strong> (<em>boolean</em><em>, </em><em>optional</em>) – estimate bias b else b=0 (default:True)</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>A</strong> (<em>(d x d) ndarray</em>) – Linear operator</p></li>
<li><p><strong>b</strong> (<em>(1 x d) ndarray</em>) – bias</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id134"><span class="brackets">14</span></dt>
<dd><p>Knott, M. and Smith, C. S. “On the optimal mapping of
distributions”, Journal of Optimization Theory and Applications
Vol 43, 1984</p>
</dd>
<dt class="label" id="id135"><span class="brackets">15</span></dt>
<dd><p>Peyré, G., &amp; Cuturi, M. (2017). “Computational Optimal
Transport”, 2018.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="ot.da.SinkhornL1l2Transport">
<em class="property">class </em><code class="sig-prename descclassname">ot.da.</code><code class="sig-name descname">SinkhornL1l2Transport</code><span class="sig-paren">(</span><em class="sig-param">reg_e=1.0</em>, <em class="sig-param">reg_cl=0.1</em>, <em class="sig-param">max_iter=10</em>, <em class="sig-param">max_inner_iter=200</em>, <em class="sig-param">tol=1e-08</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">log=False</em>, <em class="sig-param">metric='sqeuclidean'</em>, <em class="sig-param">norm=None</em>, <em class="sig-param">distribution_estimation=&lt;function distribution_estimation_uniform&gt;</em>, <em class="sig-param">out_of_sample_map='ferradans'</em>, <em class="sig-param">limit_max=10</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#SinkhornL1l2Transport"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.SinkhornL1l2Transport" title="Permalink to this definition">¶</a></dt>
<dd><p>Domain Adapatation OT method based on sinkhorn algorithm +
l1l2 class regularization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reg_e</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – Entropic regularization parameter</p></li>
<li><p><strong>reg_cl</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – Class regularization parameter</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – The minimum number of iteration before stopping the optimization
algorithm if no it has not converged</p></li>
<li><p><strong>max_inner_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=200</em><em>)</em>) – The number of iteration in the inner loop</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=10e-9</em><em>)</em>) – Stop threshold on error (inner sinkhorn solver) (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Controls the verbosity of the optimization algorithm</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Controls the logs of the optimization algorithm</p></li>
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;sqeuclidean&quot;</em><em>)</em>) – The ground metric for the Wasserstein problem</p></li>
<li><p><strong>norm</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If given, normalize the ground metric to avoid numerical errors that
can occur with large metric values.</p></li>
<li><p><strong>distribution_estimation</strong> (<em>callable</em><em>, </em><em>optional</em><em> (</em><em>defaults to the uniform</em><em>)</em>) – The kind of distribution estimation to employ</p></li>
<li><p><strong>out_of_sample_map</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;ferradans&quot;</em><em>)</em>) – The kind of out of sample mapping to apply to transport samples
from a domain into another one. Currently the only possible option is
“ferradans” which uses the method proposed in [6].</p></li>
<li><p><strong>limit_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – Controls the semi supervised mode. Transport between labeled source
and target samples of different classes will exhibit an infinite cost
(10 times the maximum value of the cost matrix)</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt>
<code class="sig-name descname">coupling\_</code></dt>
<dd><p>The optimal coupling</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like, shape (n_source_samples, n_target_samples)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt>
<code class="sig-name descname">log\_</code></dt>
<dd><p>The dictionary of log, empty dic if parameter log is not True</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dictionary</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id136"><span class="brackets">1</span></dt>
<dd><p>N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,
“Optimal Transport for Domain Adaptation,” in IEEE
Transactions on Pattern Analysis and Machine Intelligence ,
vol.PP, no.99, pp.1-1</p>
</dd>
<dt class="label" id="id137"><span class="brackets">2</span></dt>
<dd><p>Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015).
Generalized conditional gradient: analysis of convergence
and applications. arXiv preprint arXiv:1510.06567.</p>
</dd>
</dl>
<dl class="py method">
<dt id="ot.da.SinkhornL1l2Transport.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span></em>, <em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Xt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#SinkhornL1l2Transport.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.SinkhornL1l2Transport.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Build a coupling matrix from source and target sets of samples
(Xs, ys) and (Xt, yt)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>ys</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>,</em><em>)</em>) – The class labels</p></li>
<li><p><strong>Xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>,</em><em>)</em>) – <p>The class labels. If some target samples are unlabeled, fill the
yt’s elements with -1.</p>
<p>Warning: Note that, due to this convention -1 cannot be used as a
class label</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Returns self.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)">object</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="ot.da.SinkhornLpl1Transport">
<em class="property">class </em><code class="sig-prename descclassname">ot.da.</code><code class="sig-name descname">SinkhornLpl1Transport</code><span class="sig-paren">(</span><em class="sig-param">reg_e=1.0</em>, <em class="sig-param">reg_cl=0.1</em>, <em class="sig-param">max_iter=10</em>, <em class="sig-param">max_inner_iter=200</em>, <em class="sig-param">log=False</em>, <em class="sig-param">tol=1e-08</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">metric='sqeuclidean'</em>, <em class="sig-param">norm=None</em>, <em class="sig-param">distribution_estimation=&lt;function distribution_estimation_uniform&gt;</em>, <em class="sig-param">out_of_sample_map='ferradans'</em>, <em class="sig-param">limit_max=inf</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#SinkhornLpl1Transport"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.SinkhornLpl1Transport" title="Permalink to this definition">¶</a></dt>
<dd><p>Domain Adapatation OT method based on sinkhorn algorithm +
LpL1 class regularization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reg_e</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – Entropic regularization parameter</p></li>
<li><p><strong>reg_cl</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – Class regularization parameter</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – The minimum number of iteration before stopping the optimization
algorithm if no it has not converged</p></li>
<li><p><strong>max_inner_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=200</em><em>)</em>) – The number of iteration in the inner loop</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Controls the logs of the optimization algorithm</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=10e-9</em><em>)</em>) – Stop threshold on error (inner sinkhorn solver) (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Controls the verbosity of the optimization algorithm</p></li>
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;sqeuclidean&quot;</em><em>)</em>) – The ground metric for the Wasserstein problem</p></li>
<li><p><strong>norm</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If given, normalize the ground metric to avoid numerical errors that
can occur with large metric values.</p></li>
<li><p><strong>distribution_estimation</strong> (<em>callable</em><em>, </em><em>optional</em><em> (</em><em>defaults to the uniform</em><em>)</em>) – The kind of distribution estimation to employ</p></li>
<li><p><strong>out_of_sample_map</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;ferradans&quot;</em><em>)</em>) – The kind of out of sample mapping to apply to transport samples
from a domain into another one. Currently the only possible option is
“ferradans” which uses the method proposed in [6].</p></li>
<li><p><strong>limit_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>defaul=np.infty</em><em>)</em>) – Controls the semi supervised mode. Transport between labeled source
and target samples of different classes will exhibit a cost defined by
limit_max.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt>
<code class="sig-name descname">coupling\_</code></dt>
<dd><p>The optimal coupling</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like, shape (n_source_samples, n_target_samples)</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id138"><span class="brackets">1</span></dt>
<dd><p>N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,
“Optimal Transport for Domain Adaptation,” in IEEE
Transactions on Pattern Analysis and Machine Intelligence ,
vol.PP, no.99, pp.1-1</p>
</dd>
<dt class="label" id="id139"><span class="brackets">2</span></dt>
<dd><p>Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015).
Generalized conditional gradient: analysis of convergence
and applications. arXiv preprint arXiv:1510.06567.</p>
</dd>
</dl>
<dl class="py method">
<dt id="ot.da.SinkhornLpl1Transport.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span></em>, <em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Xt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#SinkhornLpl1Transport.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.SinkhornLpl1Transport.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Build a coupling matrix from source and target sets of samples
(Xs, ys) and (Xt, yt)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>ys</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>,</em><em>)</em>) – The class labels</p></li>
<li><p><strong>Xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>,</em><em>)</em>) – <p>The class labels. If some target samples are unlabeled, fill the
yt’s elements with -1.</p>
<p>Warning: Note that, due to this convention -1 cannot be used as a
class label</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Returns self.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)">object</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="ot.da.SinkhornTransport">
<em class="property">class </em><code class="sig-prename descclassname">ot.da.</code><code class="sig-name descname">SinkhornTransport</code><span class="sig-paren">(</span><em class="sig-param">reg_e=1.0</em>, <em class="sig-param">max_iter=1000</em>, <em class="sig-param">tol=1e-08</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">log=False</em>, <em class="sig-param">metric='sqeuclidean'</em>, <em class="sig-param">norm=None</em>, <em class="sig-param">distribution_estimation=&lt;function distribution_estimation_uniform&gt;</em>, <em class="sig-param">out_of_sample_map='ferradans'</em>, <em class="sig-param">limit_max=inf</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#SinkhornTransport"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.SinkhornTransport" title="Permalink to this definition">¶</a></dt>
<dd><p>Domain Adapatation OT method based on Sinkhorn Algorithm</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reg_e</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – Entropic regularization parameter</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1000</em><em>)</em>) – The minimum number of iteration before stopping the optimization
algorithm if no it has not converged</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=10e-9</em><em>)</em>) – The precision required to stop the optimization algorithm.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Controls the verbosity of the optimization algorithm</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Controls the logs of the optimization algorithm</p></li>
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;sqeuclidean&quot;</em><em>)</em>) – The ground metric for the Wasserstein problem</p></li>
<li><p><strong>norm</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If given, normalize the ground metric to avoid numerical errors that
can occur with large metric values.</p></li>
<li><p><strong>distribution_estimation</strong> (<em>callable</em><em>, </em><em>optional</em><em> (</em><em>defaults to the uniform</em><em>)</em>) – The kind of distribution estimation to employ</p></li>
<li><p><strong>out_of_sample_map</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;ferradans&quot;</em><em>)</em>) – The kind of out of sample mapping to apply to transport samples
from a domain into another one. Currently the only possible option is
“ferradans” which uses the method proposed in [6].</p></li>
<li><p><strong>limit_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>defaul=np.infty</em><em>)</em>) – Controls the semi supervised mode. Transport between labeled source
and target samples of different classes will exhibit an cost defined
by this variable</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt>
<code class="sig-name descname">coupling\_</code></dt>
<dd><p>The optimal coupling</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like, shape (n_source_samples, n_target_samples)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt>
<code class="sig-name descname">log\_</code></dt>
<dd><p>The dictionary of log, empty dic if parameter log is not True</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dictionary</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id140"><span class="brackets">1</span></dt>
<dd><p>N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,
“Optimal Transport for Domain Adaptation,” in IEEE Transactions
on Pattern Analysis and Machine Intelligence , vol.PP, no.99, pp.1-1</p>
</dd>
<dt class="label" id="id141"><span class="brackets">2</span></dt>
<dd><p>M. Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal
Transport, Advances in Neural Information Processing Systems (NIPS)
26, 2013</p>
</dd>
</dl>
<dl class="py method">
<dt id="ot.da.SinkhornTransport.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Xt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#SinkhornTransport.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.SinkhornTransport.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Build a coupling matrix from source and target sets of samples
(Xs, ys) and (Xt, yt)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>ys</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>,</em><em>)</em>) – The class labels</p></li>
<li><p><strong>Xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>,</em><em>)</em>) – <p>The class labels. If some target samples are unlabeled, fill the
yt’s elements with -1.</p>
<p>Warning: Note that, due to this convention -1 cannot be used as a
class label</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Returns self.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)">object</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="ot.da.UnbalancedSinkhornTransport">
<em class="property">class </em><code class="sig-prename descclassname">ot.da.</code><code class="sig-name descname">UnbalancedSinkhornTransport</code><span class="sig-paren">(</span><em class="sig-param">reg_e=1.0</em>, <em class="sig-param">reg_m=0.1</em>, <em class="sig-param">method='sinkhorn'</em>, <em class="sig-param">max_iter=10</em>, <em class="sig-param">tol=1e-09</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">log=False</em>, <em class="sig-param">metric='sqeuclidean'</em>, <em class="sig-param">norm=None</em>, <em class="sig-param">distribution_estimation=&lt;function distribution_estimation_uniform&gt;</em>, <em class="sig-param">out_of_sample_map='ferradans'</em>, <em class="sig-param">limit_max=10</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#UnbalancedSinkhornTransport"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.UnbalancedSinkhornTransport" title="Permalink to this definition">¶</a></dt>
<dd><p>Domain Adapatation unbalanced OT method based on sinkhorn algorithm</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reg_e</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=1</em><em>)</em>) – Entropic regularization parameter</p></li>
<li><p><strong>reg_m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=0.1</em><em>)</em>) – Mass regularization parameter</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – method used for the solver either ‘sinkhorn’,  ‘sinkhorn_stabilized’ or
‘sinkhorn_epsilon_scaling’, see those function for specific parameters</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – The minimum number of iteration before stopping the optimization
algorithm if no it has not converged</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=10e-9</em><em>)</em>) – Stop threshold on error (inner sinkhorn solver) (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Controls the verbosity of the optimization algorithm</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em><em> (</em><em>default=False</em><em>)</em>) – Controls the logs of the optimization algorithm</p></li>
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;sqeuclidean&quot;</em><em>)</em>) – The ground metric for the Wasserstein problem</p></li>
<li><p><strong>norm</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If given, normalize the ground metric to avoid numerical errors that
can occur with large metric values.</p></li>
<li><p><strong>distribution_estimation</strong> (<em>callable</em><em>, </em><em>optional</em><em> (</em><em>defaults to the uniform</em><em>)</em>) – The kind of distribution estimation to employ</p></li>
<li><p><strong>out_of_sample_map</strong> (<em>string</em><em>, </em><em>optional</em><em> (</em><em>default=&quot;ferradans&quot;</em><em>)</em>) – The kind of out of sample mapping to apply to transport samples
from a domain into another one. Currently the only possible option is
“ferradans” which uses the method proposed in [6].</p></li>
<li><p><strong>limit_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em> (</em><em>default=10</em><em>)</em>) – Controls the semi supervised mode. Transport between labeled source
and target samples of different classes will exhibit an infinite cost
(10 times the maximum value of the cost matrix)</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt>
<code class="sig-name descname">coupling\_</code></dt>
<dd><p>The optimal coupling</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like, shape (n_source_samples, n_target_samples)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt>
<code class="sig-name descname">log\_</code></dt>
<dd><p>The dictionary of log, empty dic if parameter log is not True</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dictionary</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id142"><span class="brackets">1</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016).</p>
</dd>
</dl>
<p>Scaling algorithms for unbalanced transport problems. arXiv preprint
arXiv:1607.05816.</p>
<dl class="py method">
<dt id="ot.da.UnbalancedSinkhornTransport.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xs</span></em>, <em class="sig-param"><span class="n">ys</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">Xt</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">yt</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#UnbalancedSinkhornTransport.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.UnbalancedSinkhornTransport.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Build a coupling matrix from source and target sets of samples
(Xs, ys) and (Xt, yt)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>ys</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_source_samples</em><em>,</em><em>)</em>) – The class labels</p></li>
<li><p><strong>Xt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>, </em><em>n_features</em><em>)</em>) – The training input samples.</p></li>
<li><p><strong>yt</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_target_samples</em><em>,</em><em>)</em>) – <p>The class labels. If some target samples are unlabeled, fill the
yt’s elements with -1.</p>
<p>Warning: Note that, due to this convention -1 cannot be used as a
class label</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – Returns self.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)">object</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="ot.da.distribution_estimation_uniform">
<code class="sig-prename descclassname">ot.da.</code><code class="sig-name descname">distribution_estimation_uniform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#distribution_estimation_uniform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.distribution_estimation_uniform" title="Permalink to this definition">¶</a></dt>
<dd><p>estimates a uniform distribution from an array of samples X</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The array of samples</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>mu</strong> – The uniform distribution estimated from X</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array-like, shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.da.emd_laplace">
<code class="sig-prename descclassname">ot.da.</code><code class="sig-name descname">emd_laplace</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">xs</span></em>, <em class="sig-param"><span class="n">xt</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">sim</span><span class="o">=</span><span class="default_value">'knn'</span></em>, <em class="sig-param"><span class="n">sim_param</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">reg</span><span class="o">=</span><span class="default_value">'pos'</span></em>, <em class="sig-param"><span class="n">eta</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">alpha</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">numInnerItermax</span><span class="o">=</span><span class="default_value">100000</span></em>, <em class="sig-param"><span class="n">stopInnerThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#emd_laplace"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.emd_laplace" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the optimal transport problem (OT) with Laplacian regularization</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + eta\Omega_\alpha(\gamma)\\s.t.\ \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where:</p>
<ul class="simple">
<li><p>a and b are source and target weights (sum to 1)</p></li>
<li><p>xs and xt are source and target samples</p></li>
<li><p>M is the (ns,nt) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega_\alpha\)</span> is the Laplacian regularization term
<span class="math notranslate nohighlight">\(\Omega_\alpha = (1-\alpha)/n_s^2\sum_{i,j}S^s_{i,j}\|T(\mathbf{x}^s_i)-T(\mathbf{x}^s_j)\|^2+\alpha/n_t^2\sum_{i,j}S^t_{i,j}^'\|T(\mathbf{x}^t_i)-T(\mathbf{x}^t_j)\|^2\)</span>
with <span class="math notranslate nohighlight">\(S^s_{i,j}, S^t_{i,j}\)</span> denoting source and target similarity matrices and <span class="math notranslate nohighlight">\(T(\cdot)\)</span> being a barycentric mapping</p></li>
</ul>
<p>The algorithm used for solving the problem is the conditional gradient algorithm as proposed in [5].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>b</strong> (<em>np.ndarray</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – samples weights in the target domain</p></li>
<li><p><strong>xs</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – samples in the source domain</p></li>
<li><p><strong>xt</strong> (<em>np.ndarray</em><em> (</em><em>nt</em><em>,</em><em>d</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>sim</strong> (<em>string</em><em>, </em><em>optional</em>) – Type of similarity (‘knn’ or ‘gauss’) used to construct the Laplacian.</p></li>
<li><p><strong>sim_param</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Parameter (number of the nearest neighbors for sim=’knn’
or bandwidth for sim=’gauss’) used to compute the Laplacian.</p></li>
<li><p><strong>reg</strong> (<em>string</em>) – Type of Laplacian regularization</p></li>
<li><p><strong>eta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term for Laplacian regularization</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term  for source domain’s importance in regularization</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (inner emd solver) (&gt;0)</p></li>
<li><p><strong>numInnerItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations (inner CG solver)</p></li>
<li><p><strong>stopInnerThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (inner CG solver) (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id143"><span class="brackets">5</span></dt>
<dd><p>N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,
“Optimal Transport for Domain Adaptation,” in IEEE
Transactions on Pattern Analysis and Machine Intelligence ,
vol.PP, no.99, pp.1-1</p>
</dd>
<dt class="label" id="id144"><span class="brackets">30</span></dt>
<dd><p>R. Flamary, N. Courty, D. Tuia, A. Rakotomamonjy,
“Optimal transport with Laplacian regularization: Applications to domain adaptation and shape matching,”</p>
<blockquote>
<div><p>in NIPS Workshop on Optimal Transport and Machine Learning OTML, 2014.</p>
</div></blockquote>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.da.joint_OT_mapping_kernel">
<code class="sig-prename descclassname">ot.da.</code><code class="sig-name descname">joint_OT_mapping_kernel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">xs</span></em>, <em class="sig-param"><span class="n">xt</span></em>, <em class="sig-param"><span class="n">mu</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">eta</span><span class="o">=</span><span class="default_value">0.001</span></em>, <em class="sig-param"><span class="n">kerneltype</span><span class="o">=</span><span class="default_value">'gaussian'</span></em>, <em class="sig-param"><span class="n">sigma</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose2</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">numInnerItermax</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">stopInnerThr</span><span class="o">=</span><span class="default_value">1e-06</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-05</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#joint_OT_mapping_kernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.joint_OT_mapping_kernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Joint OT and nonlinear mapping estimation with kernels as proposed in [8]</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\min_{\gamma,L\in\mathcal{H}}\quad \|L(X_s) -
n_s\gamma X_t\|^2_F + \mu&lt;\gamma,M&gt;_F + \eta  \|L\|^2_\mathcal{H}\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (ns,nt) squared euclidean cost matrix between samples in
Xs and Xt (scaled by ns)</p></li>
<li><p><span class="math notranslate nohighlight">\(L\)</span> is a ns x d linear operator on a kernel matrix that
approximates the barycentric mapping</p></li>
<li><p>a and b are uniform source and target weights</p></li>
</ul>
<p>The problem consist in solving jointly an optimal transport matrix
<span class="math notranslate nohighlight">\(\gamma\)</span> and the nonlinear mapping that fits the barycentric mapping
<span class="math notranslate nohighlight">\(n_s\gamma X_t\)</span>.</p>
<p>One can also estimate a mapping with constant bias (see supplementary
material of [8]) using the bias optional argument.</p>
<p>The algorithm used for solving the problem is the block coordinate
descent that alternates between updates of G (using conditionnal gradient)
and the update of L using a classical kernel least square solver.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – samples in the source domain</p></li>
<li><p><strong>xt</strong> (<em>np.ndarray</em><em> (</em><em>nt</em><em>,</em><em>d</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>mu</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>,</em><em>optional</em>) – Weight for the linear OT loss (&gt;0)</p></li>
<li><p><strong>eta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term  for the linear mapping L (&gt;0)</p></li>
<li><p><strong>kerneltype</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>,</em><em>optional</em>) – kernel used by calling function ot.utils.kernel (gaussian by default)</p></li>
<li><p><strong>sigma</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Gaussian kernel bandwidth.</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>,</em><em>optional</em>) – Estimate linear mapping with constant bias</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>verbose2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of BCD iterations</p></li>
<li><p><strong>numInnerItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations (inner CG solver)</p></li>
<li><p><strong>stopInnerThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (inner CG solver) (&gt;0)</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative loss decrease (&gt;0)</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>L</strong> (<em>(ns x d) ndarray</em>) – Nonlinear mapping matrix (ns+1 x d if bias)</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id145"><span class="brackets">8</span></dt>
<dd><p>M. Perrot, N. Courty, R. Flamary, A. Habrard,
“Mapping estimation for discrete optimal transport”,
Neural Information Processing Systems (NIPS), 2016.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.da.joint_OT_mapping_linear">
<code class="sig-prename descclassname">ot.da.</code><code class="sig-name descname">joint_OT_mapping_linear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">xs</span></em>, <em class="sig-param"><span class="n">xt</span></em>, <em class="sig-param"><span class="n">mu</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">eta</span><span class="o">=</span><span class="default_value">0.001</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose2</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">numInnerItermax</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">stopInnerThr</span><span class="o">=</span><span class="default_value">1e-06</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-05</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#joint_OT_mapping_linear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.joint_OT_mapping_linear" title="Permalink to this definition">¶</a></dt>
<dd><p>Joint OT and linear mapping estimation as proposed in [8]</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\min_{\gamma,L}\quad \|L(X_s) -n_s\gamma X_t\|^2_F +
  \mu&lt;\gamma,M&gt;_F + \eta  \|L -I\|^2_F\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><dl class="simple">
<dt>M is the (ns,nt) squared euclidean cost matrix between samples in</dt><dd><p>Xs and Xt (scaled by ns)</p>
</dd>
</dl>
</li>
<li><p><span class="math notranslate nohighlight">\(L\)</span> is a dxd linear operator that approximates the barycentric
mapping</p></li>
<li><p><span class="math notranslate nohighlight">\(I\)</span> is the identity matrix (neutral linear mapping)</p></li>
<li><p>a and b are uniform source and target weights</p></li>
</ul>
<p>The problem consist in solving jointly an optimal transport matrix
<span class="math notranslate nohighlight">\(\gamma\)</span> and a linear mapping that fits the barycentric mapping
<span class="math notranslate nohighlight">\(n_s\gamma X_t\)</span>.</p>
<p>One can also estimate a mapping with constant bias (see supplementary
material of [8]) using the bias optional argument.</p>
<p>The algorithm used for solving the problem is the block coordinate
descent that alternates between updates of G (using conditionnal gradient)
and the update of L using a classical least square solver.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>d</em><em>)</em>) – samples in the source domain</p></li>
<li><p><strong>xt</strong> (<em>np.ndarray</em><em> (</em><em>nt</em><em>,</em><em>d</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>mu</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>,</em><em>optional</em>) – Weight for the linear OT loss (&gt;0)</p></li>
<li><p><strong>eta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term  for the linear mapping L (&gt;0)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>,</em><em>optional</em>) – Estimate linear mapping with constant bias</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of BCD iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on relative loss decrease (&gt;0)</p></li>
<li><p><strong>numInnerItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations (inner CG solver)</p></li>
<li><p><strong>stopInnerThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (inner CG solver) (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>L</strong> (<em>(d x d) ndarray</em>) – Linear mapping matrix (d+1 x d if bias)</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id146"><span class="brackets">8</span></dt>
<dd><p>M. Perrot, N. Courty, R. Flamary, A. Habrard,
“Mapping estimation for discrete optimal transport”,
Neural Information Processing Systems (NIPS), 2016.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.da.sinkhorn_l1l2_gl">
<code class="sig-prename descclassname">ot.da.</code><code class="sig-name descname">sinkhorn_l1l2_gl</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">labels_a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">eta</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">numInnerItermax</span><span class="o">=</span><span class="default_value">200</span></em>, <em class="sig-param"><span class="n">stopInnerThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#sinkhorn_l1l2_gl"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.sinkhorn_l1l2_gl" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the entropic regularization optimal transport problem with group
lasso regularization</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega_e(\gamma)+
\eta \Omega_g(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (ns,nt) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega_e\)</span> is the entropic regularization term
<span class="math notranslate nohighlight">\(\Omega_e(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega_g\)</span> is the group lasso regulaization term
<span class="math notranslate nohighlight">\(\Omega_g(\gamma)=\sum_{i,c} \|\gamma_{i,\mathcal{I}_c}\|^2\)</span>
where  <span class="math notranslate nohighlight">\(\mathcal{I}_c\)</span> are the index of samples from class
c in the source domain.</p></li>
<li><p>a and b are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the generalised conditional
gradient as proposed in  <a href="#id262"><span class="problematic" id="id147">[5]_</span></a> <a href="#id263"><span class="problematic" id="id148">[7]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>labels_a</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – labels of samples in the source domain</p></li>
<li><p><strong>b</strong> (<em>np.ndarray</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – samples in the target domain</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term for entropic regularization &gt;0</p></li>
<li><p><strong>eta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term  for group lasso regularization &gt;0</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>numInnerItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations (inner sinkhorn solver)</p></li>
<li><p><strong>stopInnerThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (inner sinkhorn solver) (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id149"><span class="brackets">5</span></dt>
<dd><p>N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,
“Optimal Transport for Domain Adaptation,” in IEEE Transactions
on Pattern Analysis and Machine Intelligence , vol.PP, no.99, pp.1-1</p>
</dd>
<dt class="label" id="id150"><span class="brackets">7</span></dt>
<dd><p>Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015).
Generalized conditional gradient: analysis of convergence and
applications. arXiv preprint arXiv:1510.06567.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.optim.gcg" title="ot.optim.gcg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.gcg()</span></code></a></dt><dd><p>Generalized conditional gradient for OT problems</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.da.sinkhorn_lpl1_mm">
<code class="sig-prename descclassname">ot.da.</code><code class="sig-name descname">sinkhorn_lpl1_mm</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">labels_a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">eta</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">numInnerItermax</span><span class="o">=</span><span class="default_value">200</span></em>, <em class="sig-param"><span class="n">stopInnerThr</span><span class="o">=</span><span class="default_value">1e-09</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/da.html#sinkhorn_lpl1_mm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.da.sinkhorn_lpl1_mm" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the entropic regularization optimal transport problem with nonconvex
group lasso regularization</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega_e(\gamma)
+ \eta \Omega_g(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (ns,nt) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega_e\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega_e
(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega_g\)</span> is the group lasso  regularization term
<span class="math notranslate nohighlight">\(\Omega_g(\gamma)=\sum_{i,c} \|\gamma_{i,\mathcal{I}_c}\|^{1/2}_1\)</span>
where  <span class="math notranslate nohighlight">\(\mathcal{I}_c\)</span> are the index of samples from class c
in the source domain.</p></li>
<li><p>a and b are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the generalized conditional
gradient as proposed in  <a href="#id264"><span class="problematic" id="id151">[5]_</span></a> <a href="#id265"><span class="problematic" id="id152">[7]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – samples weights in the source domain</p></li>
<li><p><strong>labels_a</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – labels of samples in the source domain</p></li>
<li><p><strong>b</strong> (<em>np.ndarray</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – samples weights in the target domain</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>ns</em><em>,</em><em>nt</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term for entropic regularization &gt;0</p></li>
<li><p><strong>eta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term  for group lasso regularization &gt;0</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>numInnerItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations (inner sinkhorn solver)</p></li>
<li><p><strong>stopInnerThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (inner sinkhorn solver) (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(ns x nt) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id153"><span class="brackets">5</span></dt>
<dd><p>N. Courty; R. Flamary; D. Tuia; A. Rakotomamonjy,
“Optimal Transport for Domain Adaptation,” in IEEE
Transactions on Pattern Analysis and Machine Intelligence ,
vol.PP, no.99, pp.1-1</p>
</dd>
<dt class="label" id="id154"><span class="brackets">7</span></dt>
<dd><p>Rakotomamonjy, A., Flamary, R., &amp; Courty, N. (2015).
Generalized conditional gradient: analysis of convergence
and applications. arXiv preprint arXiv:1510.06567.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.bregman.sinkhorn" title="ot.bregman.sinkhorn"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.bregman.sinkhorn()</span></code></a></dt><dd><p>Entropic regularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

</div>
<div class="section" id="ot-gpu">
<h2>ot.gpu<a class="headerlink" href="#ot-gpu" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-ot.dr">
<span id="ot-dr"></span><h2>ot.dr<a class="headerlink" href="#module-ot.dr" title="Permalink to this headline">¶</a></h2>
<p>Dimension reduction with optimal transport</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Note that by default the module is not import in <a class="reference internal" href="#module-ot" title="ot"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ot</span></code></a>. In order to
use it you need to explicitely import <a class="reference internal" href="#module-ot.dr" title="ot.dr"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ot.dr</span></code></a></p>
</div>
<dl class="py function">
<dt id="ot.dr.dist">
<code class="sig-prename descclassname">ot.dr.</code><code class="sig-name descname">dist</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x1</span></em>, <em class="sig-param"><span class="n">x2</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/dr.html#dist"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.dr.dist" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute squared euclidean distance between samples (autograd)</p>
</dd></dl>

<dl class="py function">
<dt id="ot.dr.fda">
<code class="sig-prename descclassname">ot.dr.</code><code class="sig-name descname">fda</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">p</span><span class="o">=</span><span class="default_value">2</span></em>, <em class="sig-param"><span class="n">reg</span><span class="o">=</span><span class="default_value">1e-16</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/dr.html#fda"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.dr.fda" title="Permalink to this definition">¶</a></dt>
<dd><p>Fisher Discriminant Analysis</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>, </em><em>d</em><em>)</em>) – Training samples.</p></li>
<li><p><strong>y</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>,</em><em>)</em>) – Labels for training samples.</p></li>
<li><p><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Size of dimensionnality reduction.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0 (ridge regularization)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>P</strong> (<em>ndarray, shape (d, p)</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>proj</strong> (<em>callable</em>) – projection function including mean centering</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.dr.sinkhorn">
<code class="sig-prename descclassname">ot.dr.</code><code class="sig-name descname">sinkhorn</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">w1</span></em>, <em class="sig-param"><span class="n">w2</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">k</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/dr.html#sinkhorn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.dr.sinkhorn" title="Permalink to this definition">¶</a></dt>
<dd><p>Sinkhorn algorithm with fixed number of iteration (autograd)</p>
</dd></dl>

<dl class="py function">
<dt id="ot.dr.split_classes">
<code class="sig-prename descclassname">ot.dr.</code><code class="sig-name descname">split_classes</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/dr.html#split_classes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.dr.split_classes" title="Permalink to this definition">¶</a></dt>
<dd><p>split samples in X by classes in y</p>
</dd></dl>

<dl class="py function">
<dt id="ot.dr.wda">
<code class="sig-prename descclassname">ot.dr.</code><code class="sig-name descname">wda</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">p</span><span class="o">=</span><span class="default_value">2</span></em>, <em class="sig-param"><span class="n">reg</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">k</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">solver</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">maxiter</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">P0</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/dr.html#wda"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.dr.wda" title="Permalink to this definition">¶</a></dt>
<dd><p>Wasserstein Discriminant Analysis <a class="footnote-reference brackets" href="#id156" id="id155">11</a></p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[P = \text{arg}\min_P \frac{\sum_i W(PX^i,PX^i)}{\sum_{i,j\neq i} W(PX^i,PX^j)}\]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P\)</span> is a linear projection operator in the Stiefel(p,d) manifold</p></li>
<li><p><span class="math notranslate nohighlight">\(W\)</span> is entropic regularized Wasserstein distances</p></li>
<li><p><span class="math notranslate nohighlight">\(X^i\)</span> are samples in the dataset corresponding to class i</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>, </em><em>d</em><em>)</em>) – Training samples.</p></li>
<li><p><strong>y</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>,</em><em>)</em>) – Labels for training samples.</p></li>
<li><p><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Size of dimensionnality reduction.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Regularization term &gt;0 (entropic regularization)</p></li>
<li><p><strong>solver</strong> (<em>None | str</em><em>, </em><em>optional</em>) – None for steepest descent or ‘TrustRegions’ for trust regions algorithm
else should be a pymanopt.solvers</p></li>
<li><p><strong>P0</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>d</em><em>, </em><em>p</em><em>)</em>) – Initial starting point for projection.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Print information along iterations.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>P</strong> (<em>ndarray, shape (d, p)</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>proj</strong> (<em>callable</em>) – Projection function including mean centering.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id156"><span class="brackets"><a class="fn-backref" href="#id155">11</a></span></dt>
<dd><p>Flamary, R., Cuturi, M., Courty, N., &amp; Rakotomamonjy, A. (2016).
Wasserstein Discriminant Analysis. arXiv preprint arXiv:1608.08063.</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ot.utils">
<span id="ot-utils"></span><h2>ot.utils<a class="headerlink" href="#module-ot.utils" title="Permalink to this headline">¶</a></h2>
<p>Various useful functions</p>
<dl class="py class">
<dt id="ot.utils.BaseEstimator">
<em class="property">class </em><code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">BaseEstimator</code><a class="reference internal" href="_modules/ot/utils.html#BaseEstimator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.BaseEstimator" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for most objects in POT</p>
<p>Code adapted from sklearn BaseEstimator class</p>
<p class="rubric">Notes</p>
<p>All estimators should specify all the parameters that can be set
at the class level in their <code class="docutils literal notranslate"><span class="pre">__init__</span></code> as explicit keyword
arguments (no <code class="docutils literal notranslate"><span class="pre">*args</span></code> or <code class="docutils literal notranslate"><span class="pre">**kwargs</span></code>).</p>
<dl class="py method">
<dt id="ot.utils.BaseEstimator.get_params">
<code class="sig-name descname">get_params</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">deep</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#BaseEstimator.get_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.BaseEstimator.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>deep</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>params</strong> – Parameter names mapped to their values.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>mapping of string to any</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="ot.utils.BaseEstimator.set_params">
<code class="sig-name descname">set_params</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">params</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#BaseEstimator.set_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.BaseEstimator.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>self</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py exception">
<dt id="ot.utils.UndefinedParameter">
<em class="property">exception </em><code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">UndefinedParameter</code><a class="reference internal" href="_modules/ot/utils.html#UndefinedParameter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.UndefinedParameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Aim at raising an Exception when a undefined parameter is called</p>
</dd></dl>

<dl class="py function">
<dt id="ot.utils.check_params">
<code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">check_params</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#check_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.check_params" title="Permalink to this definition">¶</a></dt>
<dd><p>check_params: check whether some parameters are missing</p>
</dd></dl>

<dl class="py function">
<dt id="ot.utils.check_random_state">
<code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">check_random_state</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">seed</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#check_random_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.check_random_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Turn seed into a np.random.RandomState instance</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>seed</strong> (<em>None | int | instance of RandomState</em>) – If seed is None, return the RandomState singleton used by np.random.
If seed is an int, return a new RandomState instance seeded with seed.
If seed is already a RandomState instance, return it.
Otherwise raise ValueError.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.utils.clean_zeros">
<code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">clean_zeros</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#clean_zeros"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.clean_zeros" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove all components with zeros weights in a and b</p>
</dd></dl>

<dl class="py function">
<dt id="ot.utils.cost_normalization">
<code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">cost_normalization</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">C</span></em>, <em class="sig-param"><span class="n">norm</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#cost_normalization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.cost_normalization" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply normalization to the loss matrix</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n1</em><em>, </em><em>n2</em><em>)</em>) – The cost matrix to normalize.</p></li>
<li><p><strong>norm</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – Type of normalization from ‘median’, ‘max’, ‘log’, ‘loglog’. Any
other value do not normalize.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>C</strong> – The input cost matrix normalized according to given norm.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, shape (n1, n2)</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="ot.utils.deprecated">
<em class="property">class </em><code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">deprecated</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">extra</span><span class="o">=</span><span class="default_value">''</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#deprecated"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.deprecated" title="Permalink to this definition">¶</a></dt>
<dd><p>Decorator to mark a function or class as deprecated.</p>
<p>deprecated class from scikit-learn package
<a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/deprecation.py">https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/deprecation.py</a>
Issue a warning when the function is called/the class is instantiated and
adds a warning to the docstring.
The optional extra argument will be appended to the deprecation message
and the docstring. Note: to use this with the default value for extra, put
in an empty of parentheses:
&gt;&gt;&gt; from ot.deprecation import deprecated  # doctest: +SKIP
&gt;&gt;&gt; &#64;deprecated()  # doctest: +SKIP
… def some_function(): pass  # doctest: +SKIP</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>extra</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – To be added to the deprecation messages.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.utils.dist">
<code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">dist</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x1</span></em>, <em class="sig-param"><span class="n">x2</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">'sqeuclidean'</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#dist"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.dist" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute distance between samples in x1 and x2 using function scipy.spatial.distance.cdist</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>n1</em><em>,</em><em>d</em><em>)</em>) – matrix with n1 samples of size d</p></li>
<li><p><strong>x2</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n2</em><em>,</em><em>d</em><em>)</em><em>, </em><em>optional</em>) – matrix with n2 samples of size d (if None then x2=x1)</p></li>
<li><p><strong>metric</strong> (<em>str | callable</em><em>, </em><em>optional</em>) – Name of the metric to be computed (full list in the doc of scipy),  If a string,
the distance function can be ‘braycurtis’, ‘canberra’, ‘chebyshev’, ‘cityblock’,
‘correlation’, ‘cosine’, ‘dice’, ‘euclidean’, ‘hamming’, ‘jaccard’, ‘kulsinski’,
‘mahalanobis’, ‘matching’, ‘minkowski’, ‘rogerstanimoto’, ‘russellrao’, ‘seuclidean’,
‘sokalmichener’, ‘sokalsneath’, ‘sqeuclidean’, ‘wminkowski’, ‘yule’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>M</strong> – distance matrix computed with given metric</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>np.array (n1,n2)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.utils.dist0">
<code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">dist0</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'lin_square'</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#dist0"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.dist0" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute standard cost matrices of size (n, n) for OT problems</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of the cost matrix.</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – <p>Type of loss matrix chosen from:</p>
<ul>
<li><p>’lin_square’ : linear sampling between 0 and n-1, quadratic loss</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>M</strong> – Distance matrix computed with given metric.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, shape (n1,n2)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.utils.dots">
<code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">dots</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#dots"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.dots" title="Permalink to this definition">¶</a></dt>
<dd><p>dots function for multiple matrix multiply</p>
</dd></dl>

<dl class="py function">
<dt id="ot.utils.euclidean_distances">
<code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">euclidean_distances</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">squared</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#euclidean_distances"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.euclidean_distances" title="Permalink to this definition">¶</a></dt>
<dd><p>Considering the rows of X (and Y=X) as vectors, compute the
distance matrix between each pair of vectors.
:param X:
:type X: {array-like}, shape (n_samples_1, n_features)
:param Y:
:type Y: {array-like}, shape (n_samples_2, n_features)
:param squared: Return squared Euclidean distances.
:type squared: boolean, optional</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>distances</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>{array}, shape (n_samples_1, n_samples_2)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.utils.fun">
<code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">fun</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">f</span></em>, <em class="sig-param"><span class="n">q_in</span></em>, <em class="sig-param"><span class="n">q_out</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#fun"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.fun" title="Permalink to this definition">¶</a></dt>
<dd><p>Utility function for parmap with no serializing problems</p>
</dd></dl>

<dl class="py function">
<dt id="ot.utils.kernel">
<code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">kernel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x1</span></em>, <em class="sig-param"><span class="n">x2</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'gaussian'</span></em>, <em class="sig-param"><span class="n">sigma</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#kernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.kernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute kernel matrix</p>
</dd></dl>

<dl class="py function">
<dt id="ot.utils.label_normalization">
<code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">label_normalization</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">start</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#label_normalization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.label_normalization" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform labels to start at a given value</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n</em><em>, </em><em>)</em>) – The vector of labels to be normalized.</p></li>
<li><p><strong>start</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Desired value for the smallest label in y (default=0)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> – The input vector of labels normalized according to given start value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array-like, shape (n1, )</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.utils.laplacian">
<code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">laplacian</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#laplacian"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.laplacian" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Laplacian matrix</p>
</dd></dl>

<dl class="py function">
<dt id="ot.utils.parmap">
<code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">parmap</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">f</span></em>, <em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">nprocs</span><span class="o">=</span><span class="default_value">36</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#parmap"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.parmap" title="Permalink to this definition">¶</a></dt>
<dd><p>paralell map for multiprocessing (only map on windows)</p>
</dd></dl>

<dl class="py function">
<dt id="ot.utils.tic">
<code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">tic</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#tic"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.tic" title="Permalink to this definition">¶</a></dt>
<dd><p>Python implementation of Matlab tic() function</p>
</dd></dl>

<dl class="py function">
<dt id="ot.utils.toc">
<code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">toc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">message</span><span class="o">=</span><span class="default_value">'Elapsed time : {} s'</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#toc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.toc" title="Permalink to this definition">¶</a></dt>
<dd><p>Python implementation of Matlab toc() function</p>
</dd></dl>

<dl class="py function">
<dt id="ot.utils.toq">
<code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">toq</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#toq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.toq" title="Permalink to this definition">¶</a></dt>
<dd><p>Python implementation of Julia toc() function</p>
</dd></dl>

<dl class="py function">
<dt id="ot.utils.unif">
<code class="sig-prename descclassname">ot.utils.</code><code class="sig-name descname">unif</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/utils.html#unif"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.utils.unif" title="Permalink to this definition">¶</a></dt>
<dd><p>return a uniform histogram of length n (simplex)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>n</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – number of bins in the histogram</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>h</strong> – histogram of length n such that h_i=1/n for all i</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>np.array (n,)</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ot.datasets">
<span id="ot-datasets"></span><h2>ot.datasets<a class="headerlink" href="#module-ot.datasets" title="Permalink to this headline">¶</a></h2>
<p>Simple example datasets for OT</p>
<dl class="py function">
<dt id="ot.datasets.make_1D_gauss">
<code class="sig-prename descclassname">ot.datasets.</code><code class="sig-name descname">make_1D_gauss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n</span></em>, <em class="sig-param"><span class="n">m</span></em>, <em class="sig-param"><span class="n">s</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/datasets.html#make_1D_gauss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.datasets.make_1D_gauss" title="Permalink to this definition">¶</a></dt>
<dd><p>return a 1D histogram for a gaussian distribution (n bins, mean m and std s)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – number of bins in the histogram</p></li>
<li><p><strong>m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – mean value of the gaussian distribution</p></li>
<li><p><strong>s</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – standard deviaton of the gaussian distribution</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>h</strong> – 1D histogram for a gaussian distribution</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray (n,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.datasets.make_2D_samples_gauss">
<code class="sig-prename descclassname">ot.datasets.</code><code class="sig-name descname">make_2D_samples_gauss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n</span></em>, <em class="sig-param"><span class="n">m</span></em>, <em class="sig-param"><span class="n">sigma</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/datasets.html#make_2D_samples_gauss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.datasets.make_2D_samples_gauss" title="Permalink to this definition">¶</a></dt>
<dd><p>Return n samples drawn from 2D gaussian N(m,sigma)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – number of samples to make</p></li>
<li><p><strong>m</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>2</em><em>,</em><em>)</em>) – mean value of the gaussian distribution</p></li>
<li><p><strong>sigma</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>2</em><em>, </em><em>2</em><em>)</em>) – covariance matrix of the gaussian distribution</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X</strong> – n samples drawn from N(m, sigma).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, shape (n, 2)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.datasets.make_data_classif">
<code class="sig-prename descclassname">ot.datasets.</code><code class="sig-name descname">make_data_classif</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">n</span></em>, <em class="sig-param"><span class="n">nz</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">theta</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">p</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/datasets.html#make_data_classif"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.datasets.make_data_classif" title="Permalink to this definition">¶</a></dt>
<dd><p>Dataset generation for classification problems</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – type of classification problem (see code)</p></li>
<li><p><strong>n</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – number of training samples</p></li>
<li><p><strong>nz</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – noise level (&gt;0)</p></li>
<li><p><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – proportion of one class in the binary setting</p></li>
<li><p><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><em>optional</em><em> (</em><em>default=None</em><em>)</em>) – If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>X</strong> (<em>ndarray, shape (n, d)</em>) – n observation of size d</p></li>
<li><p><strong>y</strong> (<em>ndarray, shape (n,)</em>) – labels of the samples.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ot.plot">
<span id="ot-plot"></span><h2>ot.plot<a class="headerlink" href="#module-ot.plot" title="Permalink to this headline">¶</a></h2>
<p>Functions for plotting OT matrices</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Note that by default the module is not import in <a class="reference internal" href="#module-ot" title="ot"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ot</span></code></a>. In order to
use it you need to explicitely import <a class="reference internal" href="#module-ot.plot" title="ot.plot"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ot.plot</span></code></a></p>
</div>
<dl class="py function">
<dt id="ot.plot.plot1D_mat">
<code class="sig-prename descclassname">ot.plot.</code><code class="sig-name descname">plot1D_mat</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">title</span><span class="o">=</span><span class="default_value">''</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/plot.html#plot1D_mat"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.plot.plot1D_mat" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot matrix M  with the source and target 1D distribution</p>
<p>Creates a subplot with the source distribution a on the left and
target distribution b on the tot. The matrix M is shown in between.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>na</em><em>,</em><em>)</em>) – Source distribution</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nb</em><em>,</em><em>)</em>) – Target distribution</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>na</em><em>, </em><em>nb</em><em>)</em>) – Matrix to plot</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.plot.plot2D_samples_mat">
<code class="sig-prename descclassname">ot.plot.</code><code class="sig-name descname">plot2D_samples_mat</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">xs</span></em>, <em class="sig-param"><span class="n">xt</span></em>, <em class="sig-param"><span class="n">G</span></em>, <em class="sig-param"><span class="n">thr</span><span class="o">=</span><span class="default_value">1e-08</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/plot.html#plot2D_samples_mat"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.plot.plot2D_samples_mat" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot matrix M  in 2D with  lines using alpha values</p>
<p>Plot lines between source and target 2D samples with a color
proportional to the value of the matrix G between samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>2</em><em>)</em>) – Source samples positions</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>2</em><em>)</em>) – Target samples positions</p></li>
<li><p><strong>G</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>na</em><em>,</em><em>nb</em><em>)</em>) – OT matrix</p></li>
<li><p><strong>thr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – threshold above which the line is drawn</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – parameters given to the plot functions (default color is black if
nothing given)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ot.stochastic">
<span id="ot-stochastic"></span><h2>ot.stochastic<a class="headerlink" href="#module-ot.stochastic" title="Permalink to this headline">¶</a></h2>
<p>Stochastic solvers for regularized OT.</p>
<dl class="py function">
<dt id="ot.stochastic.averaged_sgd_entropic_transport">
<code class="sig-prename descclassname">ot.stochastic.</code><code class="sig-name descname">averaged_sgd_entropic_transport</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">300000</span></em>, <em class="sig-param"><span class="n">lr</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/stochastic.html#averaged_sgd_entropic_transport"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.stochastic.averaged_sgd_entropic_transport" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the ASGD algorithm to solve the regularized semi continous measures optimal transport max problem</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p>M is the (ns,nt) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term with <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p>a and b are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the ASGD algorithm
as proposed in <a href="#id266"><span class="problematic" id="id157">[18]_</span></a> [alg.2]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iteration.</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Learning rate.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ave_v</strong> – dual variable</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, shape (nt,)</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_source</span> <span class="o">=</span> <span class="mi">7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_target</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unif</span><span class="p">(</span><span class="n">n_source</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unif</span><span class="p">(</span><span class="n">n_target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_source</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_source</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_target</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">X_source</span><span class="p">,</span> <span class="n">Y_target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">stochastic</span><span class="o">.</span><span class="n">solve_semi_dual_entropic</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;ASGD&quot;</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="mi">300000</span><span class="p">)</span>
<span class="go">array([[2.53942342e-02, 9.98640673e-02, 1.75945647e-02, 4.27664307e-06],</span>
<span class="go">       [1.21556999e-01, 1.26350515e-02, 1.30491795e-03, 7.36017394e-03],</span>
<span class="go">       [3.54070702e-03, 7.63581358e-02, 6.29581672e-02, 1.32812798e-07],</span>
<span class="go">       [2.60578198e-02, 3.35916645e-02, 8.28023223e-02, 4.05336238e-04],</span>
<span class="go">       [9.86808864e-03, 7.59774324e-04, 1.08702729e-02, 1.21359007e-01],</span>
<span class="go">       [2.17218856e-02, 9.12931802e-04, 1.87962526e-03, 1.18342700e-01],</span>
<span class="go">       [4.14237512e-02, 2.67487857e-02, 7.23016955e-02, 2.38291052e-03]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>[Genevay et al., 2016] :</dt><dd><dl class="simple">
<dt>Stochastic Optimization for Large-scale Optimal Transport,</dt><dd><dl class="simple">
<dt>Advances in Neural Information Processing Systems (2016),</dt><dd><p>arXiv preprint arxiv:1605.08527.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.stochastic.batch_grad_dual">
<code class="sig-prename descclassname">ot.stochastic.</code><code class="sig-name descname">batch_grad_dual</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">alpha</span></em>, <em class="sig-param"><span class="n">beta</span></em>, <em class="sig-param"><span class="n">batch_size</span></em>, <em class="sig-param"><span class="n">batch_alpha</span></em>, <em class="sig-param"><span class="n">batch_beta</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/stochastic.html#batch_grad_dual"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.stochastic.batch_grad_dual" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the partial gradient of the dual optimal transport problem.</p>
<p>For each (i,j) in a batch of coordinates, the partial gradients are :</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\partial_{u_i} F = u_i * b_s/l_{v} - \sum_{j \in B_v} exp((u_i + v_j - M_{i,j})/reg) * a_i * b_j\\\partial_{v_j} F = v_j * b_s/l_{u} - \sum_{i \in B_u} exp((u_i + v_j - M_{i,j})/reg) * a_i * b_j\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p>M is the (ns,nt) metric cost matrix</p></li>
<li><p>u, v are dual variables in R^ixR^J</p></li>
<li><p>reg is the regularization term</p></li>
<li><p><span class="math notranslate nohighlight">\(B_u\)</span> and <span class="math notranslate nohighlight">\(B_v\)</span> are lists of index</p></li>
<li><p><span class="math notranslate nohighlight">\(b_s\)</span> is the size of the batchs <span class="math notranslate nohighlight">\(B_u\)</span> and <span class="math notranslate nohighlight">\(B_v\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(l_u\)</span> and <span class="math notranslate nohighlight">\(l_v\)</span> are the lenghts of <span class="math notranslate nohighlight">\(B_u\)</span> and <span class="math notranslate nohighlight">\(B_v\)</span></p></li>
<li><p>a and b are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the dual problem is the SGD algorithm
as proposed in <a href="#id267"><span class="problematic" id="id158">[19]_</span></a> [alg.1]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – source measure</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>alpha</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – dual variable</p></li>
<li><p><strong>beta</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – dual variable</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – size of the batch</p></li>
<li><p><strong>batch_alpha</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>bs</em><em>,</em><em>)</em>) – batch of index of alpha</p></li>
<li><p><strong>batch_beta</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>bs</em><em>,</em><em>)</em>) – batch of index of beta</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>grad</strong> – partial grad F</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, shape (ns,)</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_source</span> <span class="o">=</span> <span class="mi">7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_target</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unif</span><span class="p">(</span><span class="n">n_source</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unif</span><span class="p">(</span><span class="n">n_target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_source</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_source</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_target</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">X_source</span><span class="p">,</span> <span class="n">Y_target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sgd_dual_pi</span><span class="p">,</span> <span class="n">log</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">stochastic</span><span class="o">.</span><span class="n">solve_dual_entropic</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="mi">30000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">]</span>
<span class="go">array([0.71759102, 1.57057384, 0.85576566, 0.1208211 , 0.59190466,</span>
<span class="go">       1.197148  , 0.17805133])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;beta&#39;</span><span class="p">]</span>
<span class="go">array([0.49741367, 0.57478564, 1.40075528, 2.75890102])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sgd_dual_pi</span>
<span class="go">array([[2.09730063e-02, 8.38169324e-02, 7.50365455e-03, 8.72731415e-09],</span>
<span class="go">       [5.58432437e-03, 5.89881299e-04, 3.09558411e-05, 8.35469849e-07],</span>
<span class="go">       [3.26489515e-03, 7.15536035e-02, 2.99778211e-02, 3.02601593e-10],</span>
<span class="go">       [4.05390622e-02, 5.31085068e-02, 6.65191787e-02, 1.55812785e-06],</span>
<span class="go">       [7.82299812e-02, 6.12099102e-03, 4.44989098e-02, 2.37719187e-03],</span>
<span class="go">       [5.06266486e-02, 2.16230494e-03, 2.26215141e-03, 6.81514609e-04],</span>
<span class="go">       [6.06713990e-02, 3.98139808e-02, 5.46829338e-02, 8.62371424e-06]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>[Seguy et al., 2018] :</dt><dd><dl class="simple">
<dt>International Conference on Learning Representation (2018),</dt><dd><p>arXiv preprint arxiv:1711.02283.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.stochastic.c_transform_entropic">
<code class="sig-prename descclassname">ot.stochastic.</code><code class="sig-name descname">c_transform_entropic</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">beta</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/stochastic.html#c_transform_entropic"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.stochastic.c_transform_entropic" title="Permalink to this definition">¶</a></dt>
<dd><p>The goal is to recover u from the c-transform.</p>
<p>The function computes the c_transform of a dual variable from the other
dual variable:</p>
<div class="math notranslate nohighlight">
\[u = v^{c,reg} = -reg \sum_j exp((v - M)/reg) b_j\]</div>
<p>Where :</p>
<ul class="simple">
<li><p>M is the (ns,nt) metric cost matrix</p></li>
<li><p>u, v are dual variables in R^IxR^J</p></li>
<li><p>reg is the regularization term</p></li>
</ul>
<p>It is used to recover an optimal u from optimal v solving the semi dual
problem, see Proposition 2.1 of <a href="#id268"><span class="problematic" id="id159">[18]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>v</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Dual variable.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>u</strong> – Dual variable.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, shape (ns,)</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_source</span> <span class="o">=</span> <span class="mi">7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_target</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unif</span><span class="p">(</span><span class="n">n_source</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unif</span><span class="p">(</span><span class="n">n_target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_source</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_source</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_target</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">X_source</span><span class="p">,</span> <span class="n">Y_target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">stochastic</span><span class="o">.</span><span class="n">solve_semi_dual_entropic</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;ASGD&quot;</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="mi">300000</span><span class="p">)</span>
<span class="go">array([[2.53942342e-02, 9.98640673e-02, 1.75945647e-02, 4.27664307e-06],</span>
<span class="go">       [1.21556999e-01, 1.26350515e-02, 1.30491795e-03, 7.36017394e-03],</span>
<span class="go">       [3.54070702e-03, 7.63581358e-02, 6.29581672e-02, 1.32812798e-07],</span>
<span class="go">       [2.60578198e-02, 3.35916645e-02, 8.28023223e-02, 4.05336238e-04],</span>
<span class="go">       [9.86808864e-03, 7.59774324e-04, 1.08702729e-02, 1.21359007e-01],</span>
<span class="go">       [2.17218856e-02, 9.12931802e-04, 1.87962526e-03, 1.18342700e-01],</span>
<span class="go">       [4.14237512e-02, 2.67487857e-02, 7.23016955e-02, 2.38291052e-03]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>[Genevay et al., 2016] :</dt><dd><dl class="simple">
<dt>Stochastic Optimization for Large-scale Optimal Transport,</dt><dd><dl class="simple">
<dt>Advances in Neural Information Processing Systems (2016),</dt><dd><p>arXiv preprint arxiv:1605.08527.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.stochastic.coordinate_grad_semi_dual">
<code class="sig-prename descclassname">ot.stochastic.</code><code class="sig-name descname">coordinate_grad_semi_dual</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">beta</span></em>, <em class="sig-param"><span class="n">i</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/stochastic.html#coordinate_grad_semi_dual"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.stochastic.coordinate_grad_semi_dual" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the coordinate gradient update for regularized discrete distributions for (i, :)</p>
<p>The function computes the gradient of the semi dual problem:</p>
<div class="math notranslate nohighlight">
\[\max_v \sum_i (\sum_j v_j * b_j - reg * log(\sum_j exp((v_j - M_{i,j})/reg) * b_j)) * a_i\]</div>
<p>Where :</p>
<ul class="simple">
<li><p>M is the (ns,nt) metric cost matrix</p></li>
<li><p>v is a dual variable in R^J</p></li>
<li><p>reg is the regularization term</p></li>
<li><p>a and b are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the ASGD &amp; SAG algorithms
as proposed in <a href="#id269"><span class="problematic" id="id160">[18]_</span></a> [alg.1 &amp; alg.2]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Target measure.</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – Cost matrix.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt; 0.</p></li>
<li><p><strong>v</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Dual variable.</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Picked number i.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>coordinate gradient</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, shape (nt,)</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_source</span> <span class="o">=</span> <span class="mi">7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_target</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unif</span><span class="p">(</span><span class="n">n_source</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unif</span><span class="p">(</span><span class="n">n_target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_source</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_source</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_target</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">X_source</span><span class="p">,</span> <span class="n">Y_target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">stochastic</span><span class="o">.</span><span class="n">solve_semi_dual_entropic</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;ASGD&quot;</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="mi">300000</span><span class="p">)</span>
<span class="go">array([[2.53942342e-02, 9.98640673e-02, 1.75945647e-02, 4.27664307e-06],</span>
<span class="go">       [1.21556999e-01, 1.26350515e-02, 1.30491795e-03, 7.36017394e-03],</span>
<span class="go">       [3.54070702e-03, 7.63581358e-02, 6.29581672e-02, 1.32812798e-07],</span>
<span class="go">       [2.60578198e-02, 3.35916645e-02, 8.28023223e-02, 4.05336238e-04],</span>
<span class="go">       [9.86808864e-03, 7.59774324e-04, 1.08702729e-02, 1.21359007e-01],</span>
<span class="go">       [2.17218856e-02, 9.12931802e-04, 1.87962526e-03, 1.18342700e-01],</span>
<span class="go">       [4.14237512e-02, 2.67487857e-02, 7.23016955e-02, 2.38291052e-03]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>[Genevay et al., 2016] :</dt><dd><dl class="simple">
<dt>Stochastic Optimization for Large-scale Optimal Transport,</dt><dd><dl class="simple">
<dt>Advances in Neural Information Processing Systems (2016),</dt><dd><p>arXiv preprint arxiv:1605.08527.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.stochastic.sag_entropic_transport">
<code class="sig-prename descclassname">ot.stochastic.</code><code class="sig-name descname">sag_entropic_transport</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">10000</span></em>, <em class="sig-param"><span class="n">lr</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/stochastic.html#sag_entropic_transport"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.stochastic.sag_entropic_transport" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Compute the SAG algorithm to solve the regularized discrete measures</dt><dd><p>optimal transport max problem</p>
</dd>
</dl>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1 = b\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p>M is the (ns,nt) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term with <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p>a and b are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the SAG algorithm
as proposed in <a href="#id270"><span class="problematic" id="id161">[18]_</span></a> [alg.1]</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em><em>,</em>) – Source measure.</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em><em>,</em>) – Target measure.</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>,</em>) – Cost matrix.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iteration.</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Learning rate.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>v</strong> – Dual variable.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>ndarray, shape (nt,)</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_source</span> <span class="o">=</span> <span class="mi">7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_target</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unif</span><span class="p">(</span><span class="n">n_source</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unif</span><span class="p">(</span><span class="n">n_target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_source</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_source</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_target</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">X_source</span><span class="p">,</span> <span class="n">Y_target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">stochastic</span><span class="o">.</span><span class="n">solve_semi_dual_entropic</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;ASGD&quot;</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="mi">300000</span><span class="p">)</span>
<span class="go">array([[2.53942342e-02, 9.98640673e-02, 1.75945647e-02, 4.27664307e-06],</span>
<span class="go">       [1.21556999e-01, 1.26350515e-02, 1.30491795e-03, 7.36017394e-03],</span>
<span class="go">       [3.54070702e-03, 7.63581358e-02, 6.29581672e-02, 1.32812798e-07],</span>
<span class="go">       [2.60578198e-02, 3.35916645e-02, 8.28023223e-02, 4.05336238e-04],</span>
<span class="go">       [9.86808864e-03, 7.59774324e-04, 1.08702729e-02, 1.21359007e-01],</span>
<span class="go">       [2.17218856e-02, 9.12931802e-04, 1.87962526e-03, 1.18342700e-01],</span>
<span class="go">       [4.14237512e-02, 2.67487857e-02, 7.23016955e-02, 2.38291052e-03]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>[Genevay et al., 2016] :</dt><dd><dl class="simple">
<dt>Stochastic Optimization for Large-scale Optimal Transport,</dt><dd><dl class="simple">
<dt>Advances in Neural Information Processing Systems (2016),</dt><dd><p>arXiv preprint arxiv:1605.08527.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.stochastic.sgd_entropic_regularization">
<code class="sig-prename descclassname">ot.stochastic.</code><code class="sig-name descname">sgd_entropic_regularization</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">batch_size</span></em>, <em class="sig-param"><span class="n">numItermax</span></em>, <em class="sig-param"><span class="n">lr</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/stochastic.html#sgd_entropic_regularization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.stochastic.sgd_entropic_regularization" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Compute the sgd algorithm to solve the regularized discrete measures</dt><dd><p>optimal transport dual problem</p>
</dd>
</dl>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p>M is the (ns,nt) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term with <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p>a and b are source and target weights (sum to 1)</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – source measure</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – size of the batch</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – number of iteration</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – learning rate</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>alpha</strong> (<em>ndarray, shape (ns,)</em>) – dual variable</p></li>
<li><p><strong>beta</strong> (<em>ndarray, shape (nt,)</em>) – dual variable</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_source</span> <span class="o">=</span> <span class="mi">7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_target</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">numItermax</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unif</span><span class="p">(</span><span class="n">n_source</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unif</span><span class="p">(</span><span class="n">n_target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_source</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_source</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y_target</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_target</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">X_source</span><span class="p">,</span> <span class="n">Y_target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sgd_dual_pi</span><span class="p">,</span> <span class="n">log</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">stochastic</span><span class="o">.</span><span class="n">solve_dual_entropic</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">reg</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">numItermax</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">log</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">]</span>
<span class="go">array([0.64171798, 1.27932201, 0.78132257, 0.15638935, 0.54888354,</span>
<span class="go">       1.03663469, 0.20595781])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;beta&#39;</span><span class="p">]</span>
<span class="go">array([0.51207194, 0.58033189, 1.28922676, 2.26859736])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sgd_dual_pi</span>
<span class="go">array([[1.97276541e-02, 7.81248547e-02, 6.22136048e-03, 4.95442423e-09],</span>
<span class="go">       [4.23494310e-03, 4.43286263e-04, 2.06927079e-05, 3.82389139e-07],</span>
<span class="go">       [3.07542414e-03, 6.67897769e-02, 2.48904999e-02, 1.72030247e-10],</span>
<span class="go">       [4.26271990e-02, 5.53375455e-02, 6.16535024e-02, 9.88812650e-07],</span>
<span class="go">       [7.60423265e-02, 5.89585256e-03, 3.81267087e-02, 1.39458256e-03],</span>
<span class="go">       [4.37557504e-02, 1.85189176e-03, 1.72335760e-03, 3.55491279e-04],</span>
<span class="go">       [6.33096109e-02, 4.11683954e-02, 5.02962051e-02, 5.43097516e-06]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>[Seguy et al., 2018] :</dt><dd><dl class="simple">
<dt>International Conference on Learning Representation (2018),</dt><dd><p>arXiv preprint arxiv:1711.02283.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.stochastic.solve_dual_entropic">
<code class="sig-prename descclassname">ot.stochastic.</code><code class="sig-name descname">solve_dual_entropic</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">batch_size</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">10000</span></em>, <em class="sig-param"><span class="n">lr</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/stochastic.html#solve_dual_entropic"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.stochastic.solve_dual_entropic" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Compute the transportation matrix to solve the regularized discrete measures</dt><dd><p>optimal transport dual problem</p>
</dd>
</dl>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p>M is the (ns,nt) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p>a and b are source and target weights (sum to 1)</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – source measure</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – size of the batch</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – number of iteration</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – learning rate</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>pi</strong> (<em>ndarray, shape (ns, nt)</em>) – transportation matrix</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_source</span> <span class="o">=</span> <span class="mi">7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_target</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">numItermax</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unif</span><span class="p">(</span><span class="n">n_source</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unif</span><span class="p">(</span><span class="n">n_target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_source</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_source</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y_target</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_target</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">X_source</span><span class="p">,</span> <span class="n">Y_target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sgd_dual_pi</span><span class="p">,</span> <span class="n">log</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">stochastic</span><span class="o">.</span><span class="n">solve_dual_entropic</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">reg</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">numItermax</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">log</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">]</span>
<span class="go">array([0.64057733, 1.2683513 , 0.75610161, 0.16024284, 0.54926534,</span>
<span class="go">       1.0514201 , 0.19958936])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;beta&#39;</span><span class="p">]</span>
<span class="go">array([0.51372571, 0.58843489, 1.27993921, 2.24344807])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sgd_dual_pi</span>
<span class="go">array([[1.97377795e-02, 7.86706853e-02, 6.15682001e-03, 4.82586997e-09],</span>
<span class="go">       [4.19566963e-03, 4.42016865e-04, 2.02777272e-05, 3.68823708e-07],</span>
<span class="go">       [3.00379244e-03, 6.56562018e-02, 2.40462171e-02, 1.63579656e-10],</span>
<span class="go">       [4.28626062e-02, 5.60031599e-02, 6.13193826e-02, 9.67977735e-07],</span>
<span class="go">       [7.61972739e-02, 5.94609051e-03, 3.77886693e-02, 1.36046648e-03],</span>
<span class="go">       [4.44810042e-02, 1.89476742e-03, 1.73285847e-03, 3.51826036e-04],</span>
<span class="go">       [6.30118293e-02, 4.12398660e-02, 4.95148998e-02, 5.26247246e-06]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>[Seguy et al., 2018] :</dt><dd><dl class="simple">
<dt>International Conference on Learning Representation (2018),</dt><dd><p>arXiv preprint arxiv:1711.02283.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.stochastic.solve_semi_dual_entropic">
<code class="sig-prename descclassname">ot.stochastic.</code><code class="sig-name descname">solve_semi_dual_entropic</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">method</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">10000</span></em>, <em class="sig-param"><span class="n">lr</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/stochastic.html#solve_semi_dual_entropic"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.stochastic.solve_semi_dual_entropic" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Compute the transportation matrix to solve the regularized discrete</dt><dd><p>measures optimal transport max problem</p>
</dd>
</dl>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma)\\s.t. \gamma 1 = a\\     \gamma^T 1= b\\     \gamma \geq 0\end{aligned}\end{align} \]</div>
<p>Where :</p>
<ul class="simple">
<li><p>M is the (ns,nt) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term with <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p>a and b are source and target weights (sum to 1)</p></li>
</ul>
<p>The algorithm used for solving the problem is the SAG or ASGD algorithms
as proposed in <a href="#id271"><span class="problematic" id="id162">[18]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – source measure</p></li>
<li><p><strong>b</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – target measure</p></li>
<li><p><strong>M</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em>) – cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>methode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – used method (SAG or ASGD)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – number of iteration</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – learning rate</p></li>
<li><p><strong>n_source</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – size of the source measure</p></li>
<li><p><strong>n_target</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – size of the target measure</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>pi</strong> (<em>ndarray, shape (ns, nt)</em>) – transportation matrix</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_source</span> <span class="o">=</span> <span class="mi">7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_target</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unif</span><span class="p">(</span><span class="n">n_source</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unif</span><span class="p">(</span><span class="n">n_target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_source</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_source</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_target</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">X_source</span><span class="p">,</span> <span class="n">Y_target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">stochastic</span><span class="o">.</span><span class="n">solve_semi_dual_entropic</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;ASGD&quot;</span><span class="p">,</span> <span class="n">numItermax</span><span class="o">=</span><span class="mi">300000</span><span class="p">)</span>
<span class="go">array([[2.53942342e-02, 9.98640673e-02, 1.75945647e-02, 4.27664307e-06],</span>
<span class="go">       [1.21556999e-01, 1.26350515e-02, 1.30491795e-03, 7.36017394e-03],</span>
<span class="go">       [3.54070702e-03, 7.63581358e-02, 6.29581672e-02, 1.32812798e-07],</span>
<span class="go">       [2.60578198e-02, 3.35916645e-02, 8.28023223e-02, 4.05336238e-04],</span>
<span class="go">       [9.86808864e-03, 7.59774324e-04, 1.08702729e-02, 1.21359007e-01],</span>
<span class="go">       [2.17218856e-02, 9.12931802e-04, 1.87962526e-03, 1.18342700e-01],</span>
<span class="go">       [4.14237512e-02, 2.67487857e-02, 7.23016955e-02, 2.38291052e-03]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>[Genevay et al., 2016] :</dt><dd><dl class="simple">
<dt>Stochastic Optimization for Large-scale Optimal Transport,</dt><dd><dl class="simple">
<dt>Advances in Neural Information Processing Systems (2016),</dt><dd><p>arXiv preprint arxiv:1605.08527.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ot.unbalanced">
<span id="ot-unbalanced"></span><h2>ot.unbalanced<a class="headerlink" href="#module-ot.unbalanced" title="Permalink to this headline">¶</a></h2>
<p>Regularized Unbalanced OT</p>
<dl class="py function">
<dt id="ot.unbalanced.barycenter_unbalanced">
<code class="sig-prename descclassname">ot.unbalanced.</code><code class="sig-name descname">barycenter_unbalanced</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">A</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">reg_m</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'sinkhorn'</span></em>, <em class="sig-param"><span class="n">weights</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-06</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/unbalanced.html#barycenter_unbalanced"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.unbalanced.barycenter_unbalanced" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the entropic unbalanced wasserstein barycenter of A.</p>
<blockquote>
<div><p>The function solves the following optimization problem with a</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[\mathbf{a} = arg\min_\mathbf{a} \sum_i Wu_{reg}(\mathbf{a},\mathbf{a}_i)\]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Wu_{reg}(\cdot,\cdot)\)</span> is the unbalanced entropic regularized</p></li>
</ul>
<p>Wasserstein distance (see ot.unbalanced.sinkhorn_unbalanced)
- <span class="math notranslate nohighlight">\(\mathbf{a}_i\)</span> are training distributions in the columns of matrix
<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>
- reg and <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> are respectively the regularization term and
the cost matrix for OT
- reg_mis the marginal relaxation hyperparameter
The algorithm used for solving the problem is the generalized
Sinkhorn-Knopp matrix scaling algorithm as proposed in <a href="#id272"><span class="problematic" id="id163">[10]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>A</strong> (<em>np.ndarray</em><em> (</em><em>dim</em><em>, </em><em>n_hists</em><em>)</em>) – <cite>n_hists</cite> training distributions a_i of dimension dim</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>dim</em><em>, </em><em>dim</em><em>)</em>) – ground metric matrix for OT.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Entropy regularization term &gt; 0</p></li>
<li><p><strong>reg_m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Marginal relaxation term &gt; 0</p></li>
<li><p><strong>weights</strong> (<em>np.ndarray</em><em> (</em><em>n_hists</em><em>,</em><em>) </em><em>optional</em>) – Weight of each distribution (barycentric coodinates)
If None, uniform weights are used.</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt; 0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>a</strong> (<em>(dim,) ndarray</em>) – Unbalanced Wasserstein barycenter</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id164"><span class="brackets">3</span></dt>
<dd><p>Benamou, J. D., Carlier, G., Cuturi, M., Nenna, L., &amp; Peyré, G.
(2015). Iterative Bregman projections for regularized transportation
problems. SIAM Journal on Scientific Computing, 37(2), A1111-A1138.</p>
</dd>
<dt class="label" id="id165"><span class="brackets">10</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016).
Scaling algorithms for unbalanced transport problems. arXiv preprin
arXiv:1607.05816.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.unbalanced.barycenter_unbalanced_sinkhorn">
<code class="sig-prename descclassname">ot.unbalanced.</code><code class="sig-name descname">barycenter_unbalanced_sinkhorn</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">A</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">reg_m</span></em>, <em class="sig-param"><span class="n">weights</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-06</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/unbalanced.html#barycenter_unbalanced_sinkhorn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.unbalanced.barycenter_unbalanced_sinkhorn" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the entropic unbalanced wasserstein barycenter of A.</p>
<blockquote>
<div><p>The function solves the following optimization problem with a</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[\mathbf{a} = arg\min_\mathbf{a} \sum_i Wu_{reg}(\mathbf{a},\mathbf{a}_i)\]</div>
<p>where :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Wu_{reg}(\cdot,\cdot)\)</span> is the unbalanced entropic regularized</p></li>
</ul>
<p>Wasserstein distance (see ot.unbalanced.sinkhorn_unbalanced)
- <span class="math notranslate nohighlight">\(\mathbf{a}_i\)</span> are training distributions in the columns of matrix
<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>
- reg and <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> are respectively the regularization term and
the cost matrix for OT
- reg_mis the marginal relaxation hyperparameter
The algorithm used for solving the problem is the generalized
Sinkhorn-Knopp matrix scaling algorithm as proposed in <a href="#id273"><span class="problematic" id="id166">[10]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>A</strong> (<em>np.ndarray</em><em> (</em><em>dim</em><em>, </em><em>n_hists</em><em>)</em>) – <cite>n_hists</cite> training distributions a_i of dimension dim</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>dim</em><em>, </em><em>dim</em><em>)</em>) – ground metric matrix for OT.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Entropy regularization term &gt; 0</p></li>
<li><p><strong>reg_m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Marginal relaxation term &gt; 0</p></li>
<li><p><strong>weights</strong> (<em>np.ndarray</em><em> (</em><em>n_hists</em><em>,</em><em>) </em><em>optional</em>) – Weight of each distribution (barycentric coodinates)
If None, uniform weights are used.</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt; 0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>a</strong> (<em>(dim,) ndarray</em>) – Unbalanced Wasserstein barycenter</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id167"><span class="brackets">3</span></dt>
<dd><p>Benamou, J. D., Carlier, G., Cuturi, M., Nenna, L., &amp; Peyré, G.
(2015). Iterative Bregman projections for regularized transportation
problems. SIAM Journal on Scientific Computing, 37(2), A1111-A1138.</p>
</dd>
<dt class="label" id="id168"><span class="brackets">10</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016).
Scaling algorithms for unbalanced transport problems. arXiv preprin
arXiv:1607.05816.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.unbalanced.barycenter_unbalanced_stabilized">
<code class="sig-prename descclassname">ot.unbalanced.</code><code class="sig-name descname">barycenter_unbalanced_stabilized</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">A</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">reg_m</span></em>, <em class="sig-param"><span class="n">weights</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">tau</span><span class="o">=</span><span class="default_value">1000.0</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-06</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/unbalanced.html#barycenter_unbalanced_stabilized"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.unbalanced.barycenter_unbalanced_stabilized" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the entropic unbalanced wasserstein barycenter of A with stabilization.</p>
<blockquote>
<div><p>The function solves the following optimization problem:</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[\mathbf{a} = arg\min_\mathbf{a} \sum_i Wu_{reg}(\mathbf{a},\mathbf{a}_i)\]</div>
<p>where :</p>
<ul class="simple">
<li><dl class="simple">
<dt><span class="math notranslate nohighlight">\(Wu_{reg}(\cdot,\cdot)\)</span> is the unbalanced entropic regularized</dt><dd><p>Wasserstein distance (see ot.unbalanced.sinkhorn_unbalanced)</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><span class="math notranslate nohighlight">\(\mathbf{a}_i\)</span> are training distributions in the columns of</dt><dd><p>matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span></p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>reg and <span class="math notranslate nohighlight">\(\mathbf{M}\)</span> are respectively the regularization term and</dt><dd><p>the cost matrix for OT</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>reg_mis the marginal relaxation hyperparameter</dt><dd><p>The algorithm used for solving the problem is the generalized
Sinkhorn-Knopp matrix scaling algorithm as proposed in <a href="#id274"><span class="problematic" id="id169">[10]_</span></a></p>
</dd>
</dl>
</li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>A</strong> (<em>np.ndarray</em><em> (</em><em>dim</em><em>, </em><em>n_hists</em><em>)</em>) – <cite>n_hists</cite> training distributions a_i of dimension dim</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>dim</em><em>, </em><em>dim</em><em>)</em>) – ground metric matrix for OT.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Entropy regularization term &gt; 0</p></li>
<li><p><strong>reg_m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Marginal relaxation term &gt; 0</p></li>
<li><p><strong>tau</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Stabilization threshold for log domain absorption.</p></li>
<li><p><strong>weights</strong> (<em>np.ndarray</em><em> (</em><em>n_hists</em><em>,</em><em>) </em><em>optional</em>) – Weight of each distribution (barycentric coodinates)
If None, uniform weights are used.</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt; 0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>a</strong> (<em>(dim,) ndarray</em>) – Unbalanced Wasserstein barycenter</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary return only if log==True in parameters</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id170"><span class="brackets">3</span></dt>
<dd><p>Benamou, J. D., Carlier, G., Cuturi, M., Nenna, L., &amp; Peyré,
G. (2015). Iterative Bregman projections for regularized transportation
problems. SIAM Journal on Scientific Computing, 37(2), A1111-A1138.</p>
</dd>
<dt class="label" id="id171"><span class="brackets">10</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016).
Scaling algorithms for unbalanced transport problems. arXiv preprint
arXiv:1607.05816.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.unbalanced.sinkhorn_knopp_unbalanced">
<code class="sig-prename descclassname">ot.unbalanced.</code><code class="sig-name descname">sinkhorn_knopp_unbalanced</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">reg_m</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-06</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/unbalanced.html#sinkhorn_knopp_unbalanced"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.unbalanced.sinkhorn_knopp_unbalanced" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the entropic regularization unbalanced optimal transport problem and return the loss</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}W = \min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma) + \reg_m KL(\gamma 1, a) + \reg_m KL(\gamma^T 1, b)\\s.t.
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (dim_a, dim_b) metric cost matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p></li>
<li><p>a and b are source and target unbalanced distributions</p></li>
<li><p>KL is the Kullback-Leibler divergence</p></li>
</ul>
<p>The algorithm used for solving the problem is the generalized Sinkhorn-Knopp matrix scaling algorithm as proposed in [10, 23]_</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – Unnormalized histogram of dimension dim_a</p></li>
<li><p><strong>b</strong> (<em>np.ndarray</em><em> (</em><em>dim_b</em><em>,</em><em>) or </em><em>np.ndarray</em><em> (</em><em>dim_b</em><em>, </em><em>n_hists</em><em>)</em>) – One or multiple unnormalized histograms of dimension dim_b
If many, compute all the OT distances (a, b_i)</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Entropy regularization term &gt; 0</p></li>
<li><p><strong>reg_m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Marginal relaxation term &gt; 0</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt; 0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul>
<li><p><em>if n_hists == 1</em> –</p>
<dl class="simple">
<dt>gamma<span class="classifier">(dim_a x dim_b) ndarray</span></dt><dd><p>Optimal transportation matrix for the given parameters</p>
</dd>
<dt>log<span class="classifier">dict</span></dt><dd><p>log dictionary returned only if <cite>log</cite> is <cite>True</cite></p>
</dd>
</dl>
</li>
<li><p><em>else</em> –</p>
<dl class="simple">
<dt>ot_distance<span class="classifier">(n_hists,) ndarray</span></dt><dd><p>the OT distance between <cite>a</cite> and each of the histograms <cite>b_i</cite></p>
</dd>
<dt>log<span class="classifier">dict</span></dt><dd><p>log dictionary returned only if <cite>log</cite> is <cite>True</cite></p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">unbalanced</span><span class="o">.</span><span class="n">sinkhorn_knopp_unbalanced</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
<span class="go">array([[0.51122823, 0.18807035],</span>
<span class="go">       [0.18807035, 0.51122823]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id172"><span class="brackets">10</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016).
Scaling algorithms for unbalanced transport problems. arXiv preprint
arXiv:1607.05816.</p>
</dd>
<dt class="label" id="id173"><span class="brackets">25</span></dt>
<dd><p>Frogner C., Zhang C., Mobahi H., Araya-Polo M., Poggio T. :
Learning with a Wasserstein Loss,  Advances in Neural Information
Processing Systems (NIPS) 2015</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.unbalanced.sinkhorn_stabilized_unbalanced">
<code class="sig-prename descclassname">ot.unbalanced.</code><code class="sig-name descname">sinkhorn_stabilized_unbalanced</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">reg_m</span></em>, <em class="sig-param"><span class="n">tau</span><span class="o">=</span><span class="default_value">100000.0</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-06</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/unbalanced.html#sinkhorn_stabilized_unbalanced"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.unbalanced.sinkhorn_stabilized_unbalanced" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the entropic regularization unbalanced optimal transport
problem and return the loss</p>
<p>The function solves the following optimization problem using log-domain
stabilization as proposed in [10]:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}W = \min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma) + reg_m KL(\gamma 1, a) + reg_m KL(\gamma^T 1, b)\\s.t.
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (dim_a, dim_b) metric cost matrix</p></li>
<li><dl class="simple">
<dt><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization</dt><dd><p>term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p>
</dd>
</dl>
</li>
<li><p>a and b are source and target unbalanced distributions</p></li>
<li><p>KL is the Kullback-Leibler divergence</p></li>
</ul>
<p>The algorithm used for solving the problem is the generalized
Sinkhorn-Knopp matrix scaling algorithm as proposed in [10, 23]_</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – Unnormalized histogram of dimension dim_a</p></li>
<li><p><strong>b</strong> (<em>np.ndarray</em><em> (</em><em>dim_b</em><em>,</em><em>) or </em><em>np.ndarray</em><em> (</em><em>dim_b</em><em>, </em><em>n_hists</em><em>)</em>) – One or multiple unnormalized histograms of dimension dim_b
If many, compute all the OT distances (a, b_i)</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Entropy regularization term &gt; 0</p></li>
<li><p><strong>reg_m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Marginal relaxation term &gt; 0</p></li>
<li><p><strong>tau</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – thershold for max value in u or v for log scaling</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul>
<li><p><em>if n_hists == 1</em> –</p>
<dl class="simple">
<dt>gamma<span class="classifier">(dim_a x dim_b) ndarray</span></dt><dd><p>Optimal transportation matrix for the given parameters</p>
</dd>
<dt>log<span class="classifier">dict</span></dt><dd><p>log dictionary returned only if <cite>log</cite> is <cite>True</cite></p>
</dd>
</dl>
</li>
<li><p><em>else</em> –</p>
<dl class="simple">
<dt>ot_distance<span class="classifier">(n_hists,) ndarray</span></dt><dd><p>the OT distance between <cite>a</cite> and each of the histograms <cite>b_i</cite></p>
</dd>
<dt>log<span class="classifier">dict</span></dt><dd><p>log dictionary returned only if <cite>log</cite> is <cite>True</cite></p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">unbalanced</span><span class="o">.</span><span class="n">sinkhorn_stabilized_unbalanced</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
<span class="go">array([[0.51122823, 0.18807035],</span>
<span class="go">       [0.18807035, 0.51122823]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id174"><span class="brackets">10</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016).
Scaling algorithms for unbalanced transport problems. arXiv preprint arXiv:1607.05816.</p>
</dd>
<dt class="label" id="id175"><span class="brackets">25</span></dt>
<dd><p>Frogner C., Zhang C., Mobahi H., Araya-Polo M., Poggio T. :
Learning with a Wasserstein Loss,  Advances in Neural Information
Processing Systems (NIPS) 2015</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.lp.emd" title="ot.lp.emd"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.lp.emd()</span></code></a></dt><dd><p>Unregularized OT</p>
</dd>
<dt><a class="reference internal" href="#ot.optim.cg" title="ot.optim.cg"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.optim.cg()</span></code></a></dt><dd><p>General regularized OT</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.unbalanced.sinkhorn_unbalanced">
<code class="sig-prename descclassname">ot.unbalanced.</code><code class="sig-name descname">sinkhorn_unbalanced</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">reg_m</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'sinkhorn'</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-06</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/unbalanced.html#sinkhorn_unbalanced"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.unbalanced.sinkhorn_unbalanced" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the unbalanced entropic regularization optimal transport problem
and return the OT plan</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}W = \min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma) + reg_m KL(\gamma 1, a) + reg_m KL(\gamma^T 1, b)\\s.t.
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (dim_a, dim_b) metric cost matrix</p></li>
<li><dl class="simple">
<dt><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization</dt><dd><p>term <span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p>
</dd>
</dl>
</li>
<li><p>a and b are source and target unbalanced distributions</p></li>
<li><p>KL is the Kullback-Leibler divergence</p></li>
</ul>
<dl class="simple">
<dt>The algorithm used for solving the problem is the generalized</dt><dd><p>Sinkhorn-Knopp matrix scaling algorithm as proposed in [10, 23]_</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – Unnormalized histogram of dimension dim_a</p></li>
<li><p><strong>b</strong> (<em>np.ndarray</em><em> (</em><em>dim_b</em><em>,</em><em>) or </em><em>np.ndarray</em><em> (</em><em>dim_b</em><em>, </em><em>n_hists</em><em>)</em>) – One or multiple unnormalized histograms of dimension dim_b
If many, compute all the OT distances (a, b_i)</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Entropy regularization term &gt; 0</p></li>
<li><p><strong>reg_m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Marginal relaxation term &gt; 0</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – method used for the solver either ‘sinkhorn’,  ‘sinkhorn_stabilized’ or
‘sinkhorn_reg_scaling’, see those function for specific parameters</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul>
<li><p><em>if n_hists == 1</em> –</p>
<dl class="simple">
<dt>gamma<span class="classifier">(dim_a x dim_b) ndarray</span></dt><dd><p>Optimal transportation matrix for the given parameters</p>
</dd>
<dt>log<span class="classifier">dict</span></dt><dd><p>log dictionary returned only if <cite>log</cite> is <cite>True</cite></p>
</dd>
</dl>
</li>
<li><p><em>else</em> –</p>
<dl class="simple">
<dt>ot_distance<span class="classifier">(n_hists,) ndarray</span></dt><dd><p>the OT distance between <cite>a</cite> and each of the histograms <cite>b_i</cite></p>
</dd>
<dt>log<span class="classifier">dict</span></dt><dd><p>log dictionary returned only if <cite>log</cite> is <cite>True</cite></p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">sinkhorn_unbalanced</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">array([[0.51122823, 0.18807035],</span>
<span class="go">       [0.18807035, 0.51122823]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id176"><span class="brackets">2</span></dt>
<dd><p>M. Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal
Transport, Advances in Neural Information Processing Systems
(NIPS) 26, 2013</p>
</dd>
<dt class="label" id="id177"><span class="brackets">9</span></dt>
<dd><p>Schmitzer, B. (2016). Stabilized Sparse Scaling Algorithms for
Entropy Regularized Transport Problems. arXiv preprint arXiv:1610.06519.</p>
</dd>
<dt class="label" id="id178"><span class="brackets">10</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016).
Scaling algorithms for unbalanced transport problems. arXiv preprint
arXiv:1607.05816.</p>
</dd>
<dt class="label" id="id179"><span class="brackets">25</span></dt>
<dd><p>Frogner C., Zhang C., Mobahi H., Araya-Polo M., Poggio T. :
Learning with a Wasserstein Loss,  Advances in Neural Information
Processing Systems (NIPS) 2015</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.unbalanced.sinkhorn_knopp_unbalanced" title="ot.unbalanced.sinkhorn_knopp_unbalanced"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.unbalanced.sinkhorn_knopp_unbalanced()</span></code></a></dt><dd><p>Unbalanced Classic Sinkhorn [10]</p>
</dd>
<dt><a class="reference internal" href="#ot.unbalanced.sinkhorn_stabilized_unbalanced" title="ot.unbalanced.sinkhorn_stabilized_unbalanced"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.unbalanced.sinkhorn_stabilized_unbalanced()</span></code></a></dt><dd><p>Unbalanced Stabilized sinkhorn [9][10]</p>
</dd>
<dt><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.unbalanced.sinkhorn_reg_scaling_unbalanced()</span></code></dt><dd><p>Unbalanced Sinkhorn with epslilon scaling [9][10]</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.unbalanced.sinkhorn_unbalanced2">
<code class="sig-prename descclassname">ot.unbalanced.</code><code class="sig-name descname">sinkhorn_unbalanced2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">reg_m</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'sinkhorn'</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-06</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/unbalanced.html#sinkhorn_unbalanced2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.unbalanced.sinkhorn_unbalanced2" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve the entropic regularization unbalanced optimal transport problem and
return the loss</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}W = \min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma) + reg_m KL(\gamma 1, a) + reg_m KL(\gamma^T 1, b)\\s.t.
     \gamma\geq 0\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the (dim_a, dim_b) metric cost matrix</p></li>
<li><dl class="simple">
<dt><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term</dt><dd><p><span class="math notranslate nohighlight">\(\Omega(\gamma)=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p>
</dd>
</dl>
</li>
<li><p>a and b are source and target unbalanced distributions</p></li>
<li><p>KL is the Kullback-Leibler divergence</p></li>
</ul>
<p>The algorithm used for solving the problem is the generalized
Sinkhorn-Knopp matrix scaling algorithm as proposed in [10, 23]_</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – Unnormalized histogram of dimension dim_a</p></li>
<li><p><strong>b</strong> (<em>np.ndarray</em><em> (</em><em>dim_b</em><em>,</em><em>) or </em><em>np.ndarray</em><em> (</em><em>dim_b</em><em>, </em><em>n_hists</em><em>)</em>) – One or multiple unnormalized histograms of dimension dim_b
If many, compute all the OT distances (a, b_i)</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – loss matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Entropy regularization term &gt; 0</p></li>
<li><p><strong>reg_m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Marginal relaxation term &gt; 0</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – method used for the solver either ‘sinkhorn’,  ‘sinkhorn_stabilized’ or
‘sinkhorn_reg_scaling’, see those function for specific parameters</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshol on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>ot_distance</strong> (<em>(n_hists,) ndarray</em>) – the OT distance between <cite>a</cite> and each of the histograms <cite>b_i</cite></p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary returned only if <cite>log</cite> is <cite>True</cite></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">10</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ot</span><span class="o">.</span><span class="n">unbalanced</span><span class="o">.</span><span class="n">sinkhorn_unbalanced2</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
<span class="go">array([0.31912866])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id180"><span class="brackets">2</span></dt>
<dd><p>M. Cuturi, Sinkhorn Distances : Lightspeed Computation of Optimal
Transport, Advances in Neural Information Processing Systems
(NIPS) 26, 2013</p>
</dd>
<dt class="label" id="id181"><span class="brackets">9</span></dt>
<dd><p>Schmitzer, B. (2016). Stabilized Sparse Scaling Algorithms for
Entropy Regularized Transport Problems. arXiv preprint arXiv:1610.06519.</p>
</dd>
<dt class="label" id="id182"><span class="brackets">10</span></dt>
<dd><p>Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X. (2016).
Scaling algorithms for unbalanced transport problems. arXiv preprint
arXiv:1607.05816.</p>
</dd>
<dt class="label" id="id183"><span class="brackets">25</span></dt>
<dd><p>Frogner C., Zhang C., Mobahi H., Araya-Polo M., Poggio T. :
Learning with a Wasserstein Loss,  Advances in Neural Information
Processing Systems (NIPS) 2015</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.unbalanced.sinkhorn_knopp()</span></code></dt><dd><p>Unbalanced Classic Sinkhorn [10]</p>
</dd>
<dt><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.unbalanced.sinkhorn_stabilized()</span></code></dt><dd><p>Unbalanced Stabilized sinkhorn [9][10]</p>
</dd>
<dt><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.unbalanced.sinkhorn_reg_scaling()</span></code></dt><dd><p>Unbalanced Sinkhorn with epslilon scaling [9][10]</p>
</dd>
</dl>
</div>
</dd></dl>

</div>
<div class="section" id="module-ot.partial">
<span id="ot-partial"></span><h2>ot.partial<a class="headerlink" href="#module-ot.partial" title="Permalink to this headline">¶</a></h2>
<p>Partial OT</p>
<dl class="py function">
<dt id="ot.partial.entropic_partial_gromov_wasserstein">
<code class="sig-prename descclassname">ot.partial.</code><code class="sig-name descname">entropic_partial_gromov_wasserstein</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">C1</span></em>, <em class="sig-param"><span class="n">C2</span></em>, <em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">q</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">m</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">G0</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">1e-07</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/partial.html#entropic_partial_gromov_wasserstein"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.partial.entropic_partial_gromov_wasserstein" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the partial Gromov-Wasserstein transport between (C1,p) and (C2,q)</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}GW = \arg\min_{\gamma} \sum_{i,j,k,l} L(C1_{i,k},C2_{j,l})\cdot
    \gamma_{i,j}\cdot\gamma_{k,l} + reg\cdot\Omega(\gamma)\\\begin{split}s.t.
     \gamma\geq 0 \\
     \gamma 1 \leq a\\
     \gamma^T 1 \leq b\\
     1^T \gamma^T 1 = m \leq \min\{\|a\|_1, \|b\|_1\}\end{split}\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>C1 is the metric cost matrix in the source space</p></li>
<li><p>C2 is the metric cost matrix in the target space</p></li>
<li><p>p and q are the sample weights</p></li>
<li><p>L  : quadratic loss function</p></li>
<li><dl class="simple">
<dt><span class="math notranslate nohighlight">\(\Omega\)</span>  is the entropic regularization term</dt><dd><p><span class="math notranslate nohighlight">\(\Omega=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p>
</dd>
</dl>
</li>
<li><p>m is the amount of mass to be transported</p></li>
</ul>
<p>The formulation of the GW problem has been proposed in <a href="#id275"><span class="problematic" id="id184">[12]_</span></a> and the
partial GW in <a href="#id276"><span class="problematic" id="id185">[29]_</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric costfr matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – entropic regularization parameter</p></li>
<li><p><strong>m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Amount of mass to be transported (default: min (<a href="#id186"><span class="problematic" id="id187">|</span></a>p|_1, <a href="#id188"><span class="problematic" id="id189">|</span></a>q|_1))</p></li>
<li><p><strong>G0</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Initialisation of the transportation matrix</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – return log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">98</span><span class="p">,</span><span class="mi">199</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C1</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">spatial</span><span class="o">.</span><span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C2</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">spatial</span><span class="o">.</span><span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">entropic_partial_gromov_wasserstein</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">array([[0.12, 0.13, 0.  , 0.  ],</span>
<span class="go">       [0.13, 0.12, 0.  , 0.  ],</span>
<span class="go">       [0.  , 0.  , 0.25, 0.  ],</span>
<span class="go">       [0.  , 0.  , 0.  , 0.25]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">entropic_partial_gromov_wasserstein</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="mf">0.25</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">array([[0.02, 0.03, 0.  , 0.03],</span>
<span class="go">       [0.03, 0.03, 0.  , 0.03],</span>
<span class="go">       [0.  , 0.  , 0.03, 0.  ],</span>
<span class="go">       [0.02, 0.02, 0.  , 0.03]])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>math: <cite>gamma</cite> : (dim_a x dim_b) ndarray – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary returned only if <cite>log</cite> is <cite>True</cite></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id190"><span class="brackets">12</span></dt>
<dd><p>Peyré, Gabriel, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</dd>
<dt class="label" id="id191"><span class="brackets">29</span></dt>
<dd><p>Chapel, L., Alaya, M., Gasso, G. (2019). “Partial Gromov-
Wasserstein with Applications on Positive-Unlabeled Learning”.
arXiv preprint arXiv:2002.08276.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.partial.partial_gromov_wasserstein" title="ot.partial.partial_gromov_wasserstein"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.partial.partial_gromov_wasserstein()</span></code></a></dt><dd><p>exact Partial Gromov-Wasserstein</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.partial.entropic_partial_gromov_wasserstein2">
<code class="sig-prename descclassname">ot.partial.</code><code class="sig-name descname">entropic_partial_gromov_wasserstein2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">C1</span></em>, <em class="sig-param"><span class="n">C2</span></em>, <em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">q</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">m</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">G0</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">1e-07</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/partial.html#entropic_partial_gromov_wasserstein2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.partial.entropic_partial_gromov_wasserstein2" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the partial Gromov-Wasserstein discrepancy between (C1,p) and
(C2,q)</p>
<p>The function solves the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}GW = \arg\min_{\gamma} \sum_{i,j,k,l} L(C1_{i,k},C2_{j,l})\cdot
    \gamma_{i,j}\cdot\gamma_{k,l} + reg\cdot\Omega(\gamma)\\\begin{split}s.t.
     \gamma\geq 0 \\
     \gamma 1 \leq a\\
     \gamma^T 1 \leq b\\
     1^T \gamma^T 1 = m \leq \min\{\|a\|_1, \|b\|_1\}\end{split}\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>C1 is the metric cost matrix in the source space</p></li>
<li><p>C2 is the metric cost matrix in the target space</p></li>
<li><p>p and q are the sample weights</p></li>
<li><p>L  : quadratic loss function</p></li>
<li><dl class="simple">
<dt><span class="math notranslate nohighlight">\(\Omega\)</span>  is the entropic regularization term</dt><dd><p><span class="math notranslate nohighlight">\(\Omega=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p>
</dd>
</dl>
</li>
<li><p>m is the amount of mass to be transported</p></li>
</ul>
<p>The formulation of the GW problem has been proposed in <a href="#id277"><span class="problematic" id="id192">[12]_</span></a> and the
partial GW in <a href="#id278"><span class="problematic" id="id193">[29]_</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric costfr matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – entropic regularization parameter</p></li>
<li><p><strong>m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Amount of mass to be transported (default: min (<a href="#id194"><span class="problematic" id="id195">|</span></a>p|_1, <a href="#id196"><span class="problematic" id="id197">|</span></a>q|_1))</p></li>
<li><p><strong>G0</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Initialisation of the transportation matrix</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – return log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>partial_gw_dist</strong> (<em>float</em>) – Gromov-Wasserstein distance</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary returned only if <cite>log</cite> is <cite>True</cite></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">98</span><span class="p">,</span><span class="mi">199</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C1</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">spatial</span><span class="o">.</span><span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C2</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">spatial</span><span class="o">.</span><span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">entropic_partial_gromov_wasserstein2</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">1.87</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id198"><span class="brackets">12</span></dt>
<dd><p>Peyré, Gabriel, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</dd>
<dt class="label" id="id199"><span class="brackets">29</span></dt>
<dd><p>Chapel, L., Alaya, M., Gasso, G. (2019). “Partial Gromov-
Wasserstein with Applications on Positive-Unlabeled Learning”.
arXiv preprint arXiv:2002.08276.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.partial.entropic_partial_wasserstein">
<code class="sig-prename descclassname">ot.partial.</code><code class="sig-name descname">entropic_partial_wasserstein</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg</span></em>, <em class="sig-param"><span class="n">m</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">stopThr</span><span class="o">=</span><span class="default_value">1e-100</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/partial.html#entropic_partial_wasserstein"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.partial.entropic_partial_wasserstein" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the partial optimal transport problem
and returns the OT plan</p>
<p>The function considers the following problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F + reg\cdot\Omega(\gamma)\\\begin{split}s.t. \gamma 1 \leq a \\
     \gamma^T 1 \leq b \\
     \gamma\geq 0 \\
     1^T \gamma^T 1 = m \leq \min\{\|a\|_1, \|b\|_1\} \\\end{split}\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the metric cost matrix</p></li>
<li><dl class="simple">
<dt><span class="math notranslate nohighlight">\(\Omega\)</span>  is the entropic regularization term</dt><dd><p><span class="math notranslate nohighlight">\(\Omega=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p>
</dd>
</dl>
</li>
<li><p>a and b are the sample weights</p></li>
<li><p>m is the amount of mass to be transported</p></li>
</ul>
<p>The formulation of the problem has been proposed in <a href="#id279"><span class="problematic" id="id200">[3]_</span></a> (prop. 5)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – Unnormalized histogram of dimension dim_a</p></li>
<li><p><strong>b</strong> (<em>np.ndarray</em><em> (</em><em>dim_b</em><em>,</em><em>)</em>) – Unnormalized histograms of dimension dim_b</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – cost matrix</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Regularization term &gt; 0</p></li>
<li><p><strong>m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Amount of mass to be transported</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>stopThr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Stop threshold on error (&gt;0)</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(dim_a x dim_b) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary returned only if <cite>log</cite> is <cite>True</cite></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="p">[</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="p">[</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">entropic_partial_wasserstein</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">array([[0.06, 0.02],</span>
<span class="go">       [0.01, 0.  ]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id201"><span class="brackets">3</span></dt>
<dd><p>Benamou, J. D., Carlier, G., Cuturi, M., Nenna, L., &amp; Peyré, G.
(2015). Iterative Bregman projections for regularized transportation
problems. SIAM Journal on Scientific Computing, 37(2), A1111-A1138.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.partial.partial_wasserstein" title="ot.partial.partial_wasserstein"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.partial.partial_wasserstein()</span></code></a></dt><dd><p>exact Partial Wasserstein</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.partial.gwgrad_partial">
<code class="sig-prename descclassname">ot.partial.</code><code class="sig-name descname">gwgrad_partial</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">C1</span></em>, <em class="sig-param"><span class="n">C2</span></em>, <em class="sig-param"><span class="n">T</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/partial.html#gwgrad_partial"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.partial.gwgrad_partial" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the GW gradient. Note: we can not use the trick in <a href="#id280"><span class="problematic" id="id202">[12]_</span></a>  as
the marginals may not sum to 1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array of shape</em><em> (</em><em>n_p</em><em>,</em><em>n_p</em><em>)</em>) – intra-source (P) cost matrix</p></li>
<li><p><strong>C2</strong> (<em>array of shape</em><em> (</em><em>n_u</em><em>,</em><em>n_u</em><em>)</em>) – intra-target (U) cost matrix</p></li>
<li><p><strong>T</strong> (<em>array of shape</em><em>(</em><em>n_p+nb_dummies</em><em>, </em><em>n_u</em><em>) </em><em>(</em><em>default: None</em><em>)</em>) – Transport matrix</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>gradient</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy.array of shape (n_p+nb_dummies, n_u)</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id203"><span class="brackets">12</span></dt>
<dd><p>Peyré, Gabriel, Marco Cuturi, and Justin Solomon,
“Gromov-Wasserstein averaging of kernel and distance matrices.”
International Conference on Machine Learning (ICML). 2016.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.partial.gwloss_partial">
<code class="sig-prename descclassname">ot.partial.</code><code class="sig-name descname">gwloss_partial</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">C1</span></em>, <em class="sig-param"><span class="n">C2</span></em>, <em class="sig-param"><span class="n">T</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/partial.html#gwloss_partial"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.partial.gwloss_partial" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the GW loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>array of shape</em><em> (</em><em>n_p</em><em>,</em><em>n_p</em><em>)</em>) – intra-source (P) cost matrix</p></li>
<li><p><strong>C2</strong> (<em>array of shape</em><em> (</em><em>n_u</em><em>,</em><em>n_u</em><em>)</em>) – intra-target (U) cost matrix</p></li>
<li><p><strong>T</strong> (<em>array of shape</em><em>(</em><em>n_p+nb_dummies</em><em>, </em><em>n_u</em><em>) </em><em>(</em><em>default: None</em><em>)</em>) – Transport matrix</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>GW loss</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.partial.partial_gromov_wasserstein">
<code class="sig-prename descclassname">ot.partial.</code><code class="sig-name descname">partial_gromov_wasserstein</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">C1</span></em>, <em class="sig-param"><span class="n">C2</span></em>, <em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">q</span></em>, <em class="sig-param"><span class="n">m</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">nb_dummies</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">G0</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">thres</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">1e-07</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/partial.html#partial_gromov_wasserstein"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.partial.partial_gromov_wasserstein" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the partial optimal transport problem
and returns the OT plan</p>
<p>The function considers the following problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F\\\begin{split}s.t. \gamma 1 \leq a \\
     \gamma^T 1 \leq b \\
     \gamma\geq 0 \\
     1^T \gamma^T 1 = m \leq \min\{\|a\|_1, \|b\|_1\} \\\end{split}\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the metric cost matrix</p></li>
<li><dl class="simple">
<dt><span class="math notranslate nohighlight">\(\Omega\)</span> is the entropic regularization term :math:<a href="#id204"><span class="problematic" id="id205">`</span></a>Omega(gamma)</dt><dd><p>=sum_{i,j} gamma_{i,j}log(gamma_{i,j})`</p>
</dd>
</dl>
</li>
<li><p>a and b are the sample weights</p></li>
<li><p>m is the amount of mass to be transported</p></li>
</ul>
<p>The formulation of the problem has been proposed in <a href="#id281"><span class="problematic" id="id206">[29]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric costfr matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space</p></li>
<li><p><strong>m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Amount of mass to be transported (default: min (<a href="#id207"><span class="problematic" id="id208">|</span></a>p|_1, <a href="#id209"><span class="problematic" id="id210">|</span></a>q|_1))</p></li>
<li><p><strong>nb_dummies</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Number of dummy points to add (avoid instabilities in the EMD solver)</p></li>
<li><p><strong>G0</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Initialisation of the transportation matrix</p></li>
<li><p><strong>thres</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – quantile of the gradient matrix to populate the cost matrix when 0
(default: 1)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – tolerance for stopping iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – return log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – parameters can be directly passed to the emd solver</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(dim_a x dim_b) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary returned only if <cite>log</cite> is <cite>True</cite></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">98</span><span class="p">,</span><span class="mi">199</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C1</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">spatial</span><span class="o">.</span><span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C2</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">spatial</span><span class="o">.</span><span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">partial_gromov_wasserstein</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
<span class="go">array([[0.  , 0.25, 0.  , 0.  ],</span>
<span class="go">       [0.25, 0.  , 0.  , 0.  ],</span>
<span class="go">       [0.  , 0.  , 0.25, 0.  ],</span>
<span class="go">       [0.  , 0.  , 0.  , 0.25]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">partial_gromov_wasserstein</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="mf">0.25</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
<span class="go">array([[0.  , 0.  , 0.  , 0.  ],</span>
<span class="go">       [0.  , 0.  , 0.  , 0.  ],</span>
<span class="go">       [0.  , 0.  , 0.  , 0.  ],</span>
<span class="go">       [0.  , 0.  , 0.  , 0.25]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id211"><span class="brackets">29</span></dt>
<dd><p>Chapel, L., Alaya, M., Gasso, G. (2019). “Partial Gromov-
Wasserstein with Applications on Positive-Unlabeled Learning”.
arXiv preprint arXiv:2002.08276.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.partial.partial_gromov_wasserstein2">
<code class="sig-prename descclassname">ot.partial.</code><code class="sig-name descname">partial_gromov_wasserstein2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">C1</span></em>, <em class="sig-param"><span class="n">C2</span></em>, <em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">q</span></em>, <em class="sig-param"><span class="n">m</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">nb_dummies</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">G0</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">thres</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">numItermax</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">1e-07</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/partial.html#partial_gromov_wasserstein2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.partial.partial_gromov_wasserstein2" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the partial optimal transport problem
and returns the partial Gromov-Wasserstein discrepancy</p>
<p>The function considers the following problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = arg\min_\gamma &lt;\gamma,M&gt;_F\\\begin{split}s.t. \gamma 1 \leq a \\
     \gamma^T 1 \leq b \\
     \gamma\geq 0 \\
     1^T \gamma^T 1 = m \leq \min\{\|a\|_1, \|b\|_1\} \\\end{split}\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the metric cost matrix</p></li>
<li><dl class="simple">
<dt><span class="math notranslate nohighlight">\(\Omega\)</span>  is the entropic regularization term</dt><dd><p><span class="math notranslate nohighlight">\(\Omega=\sum_{i,j} \gamma_{i,j}\log(\gamma_{i,j})\)</span></p>
</dd>
</dl>
</li>
<li><p>a and b are the sample weights</p></li>
<li><p>m is the amount of mass to be transported</p></li>
</ul>
<p>The formulation of the problem has been proposed in <a href="#id282"><span class="problematic" id="id212">[29]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C1</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>ns</em><em>)</em>) – Metric cost matrix in the source space</p></li>
<li><p><strong>C2</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>, </em><em>nt</em><em>)</em>) – Metric costfr matrix in the target space</p></li>
<li><p><strong>p</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>,</em><em>)</em>) – Distribution in the source space</p></li>
<li><p><strong>q</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>nt</em><em>,</em><em>)</em>) – Distribution in the target space</p></li>
<li><p><strong>m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Amount of mass to be transported (default: min (<a href="#id213"><span class="problematic" id="id214">|</span></a>p|_1, <a href="#id215"><span class="problematic" id="id216">|</span></a>q|_1))</p></li>
<li><p><strong>nb_dummies</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Number of dummy points to add (avoid instabilities in the EMD solver)</p></li>
<li><p><strong>G0</strong> (<em>ndarray</em><em>, </em><em>shape</em><em> (</em><em>ns</em><em>, </em><em>nt</em><em>)</em><em>, </em><em>optional</em>) – Initialisation of the transportation matrix</p></li>
<li><p><strong>thres</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – quantile of the gradient matrix to populate the cost matrix when 0
(default: 1)</p></li>
<li><p><strong>numItermax</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Max number of iterations</p></li>
<li><p><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – tolerance for stopping iterations</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – return log if True</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Print information along iterations</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – parameters can be directly passed to the emd solver</p></li>
</ul>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When dealing with a large number of points, the EMD solver may face
some instabilities, especially when the mass associated to the dummy
point is large. To avoid them, increase the number of dummy points
(allows a smoother repartition of the mass over the points).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>partial_gw_dist</strong> (<em>(dim_a x dim_b) ndarray</em>) – partial GW discrepancy</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary returned only if <cite>log</cite> is <cite>True</cite></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">98</span><span class="p">,</span><span class="mi">199</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C1</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">spatial</span><span class="o">.</span><span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C2</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">spatial</span><span class="o">.</span><span class="n">distance</span><span class="o">.</span><span class="n">cdist</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">partial_gromov_wasserstein2</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
<span class="go">1.69</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">partial_gromov_wasserstein2</span><span class="p">(</span><span class="n">C1</span><span class="p">,</span> <span class="n">C2</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="mf">0.25</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id217"><span class="brackets">29</span></dt>
<dd><p>Chapel, L., Alaya, M., Gasso, G. (2019). “Partial Gromov-
Wasserstein with Applications on Positive-Unlabeled Learning”.
arXiv preprint arXiv:2002.08276.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.partial.partial_wasserstein">
<code class="sig-prename descclassname">ot.partial.</code><code class="sig-name descname">partial_wasserstein</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">m</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">nb_dummies</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/partial.html#partial_wasserstein"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.partial.partial_wasserstein" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the partial optimal transport problem for the quadratic cost
and returns the OT plan</p>
<p>The function considers the following problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \arg\min_\gamma &lt;\gamma,M&gt;_F\\\begin{split}s.t.
     \gamma\geq 0 \\
     \gamma 1 \leq a\\
     \gamma^T 1 \leq b\\
     1^T \gamma^T 1 = m \leq \min\{\|a\|_1, \|b\|_1\}\end{split}\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the metric cost matrix</p></li>
<li><p>a and b are source and target unbalanced distributions</p></li>
<li><p>m is the amount of mass to be transported</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – Unnormalized histogram of dimension dim_a</p></li>
<li><p><strong>b</strong> (<em>np.ndarray</em><em> (</em><em>dim_b</em><em>,</em><em>)</em>) – Unnormalized histograms of dimension dim_b</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – cost matrix for the quadratic cost</p></li>
<li><p><strong>m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – amount of mass to be transported</p></li>
<li><p><strong>nb_dummies</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default:1</em>) – number of reservoir points to be added (to avoid numerical
instabilities, increase its value if an error is raised)</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – parameters can be directly passed to the emd solver</p></li>
</ul>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When dealing with a large number of points, the EMD solver may face
some instabilities, especially when the mass associated to the dummy
point is large. To avoid them, increase the number of dummy points
(allows a smoother repartition of the mass over the points).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>:math:`gamma`</strong> (<em>(dim_a x dim_b) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary returned only if <cite>log</cite> is <cite>True</cite></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="p">[</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="p">[</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">partial_wasserstein</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">M</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">array([[0.1, 0. ],</span>
<span class="go">       [0. , 0.1]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">partial_wasserstein</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">m</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">array([[0.1, 0. ],</span>
<span class="go">       [0. , 0. ]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id218"><span class="brackets">28</span></dt>
<dd><p>Caffarelli, L. A., &amp; McCann, R. J. (2010) Free boundaries in
optimal transport and Monge-Ampere obstacle problems. Annals of
mathematics, 673-730.</p>
</dd>
<dt class="label" id="id219"><span class="brackets">29</span></dt>
<dd><p>Chapel, L., Alaya, M., Gasso, G. (2019). “Partial Gromov-
Wasserstein with Applications on Positive-Unlabeled Learning”.
arXiv preprint arXiv:2002.08276.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.partial.partial_wasserstein_lagrange" title="ot.partial.partial_wasserstein_lagrange"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.partial.partial_wasserstein_lagrange()</span></code></a></dt><dd><p>Partial Wasserstein with</p>
</dd>
</dl>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">regularization()</span></code></p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.partial.entropic_partial_wasserstein" title="ot.partial.entropic_partial_wasserstein"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.partial.entropic_partial_wasserstein()</span></code></a></dt><dd><p>Partial Wasserstein with a</p>
</dd>
</dl>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">entropic()</span></code></p>
</div>
</dd></dl>

<dl class="py function">
<dt id="ot.partial.partial_wasserstein2">
<code class="sig-prename descclassname">ot.partial.</code><code class="sig-name descname">partial_wasserstein2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">m</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">nb_dummies</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/partial.html#partial_wasserstein2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.partial.partial_wasserstein2" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the partial optimal transport problem for the quadratic cost
and returns the partial GW discrepancy</p>
<p>The function considers the following problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \arg\min_\gamma &lt;\gamma,M&gt;_F\\\begin{split}s.t.
     \gamma\geq 0 \\
     \gamma 1 \leq a\\
     \gamma^T 1 \leq b\\
     1^T \gamma^T 1 = m \leq \min\{\|a\|_1, \|b\|_1\}\end{split}\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the metric cost matrix</p></li>
<li><p>a and b are source and target unbalanced distributions</p></li>
<li><p>m is the amount of mass to be transported</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – Unnormalized histogram of dimension dim_a</p></li>
<li><p><strong>b</strong> (<em>np.ndarray</em><em> (</em><em>dim_b</em><em>,</em><em>)</em>) – Unnormalized histograms of dimension dim_b</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – cost matrix for the quadratic cost</p></li>
<li><p><strong>m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – amount of mass to be transported</p></li>
<li><p><strong>nb_dummies</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default:1</em>) – number of reservoir points to be added (to avoid numerical
instabilities, increase its value if an error is raised)</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – parameters can be directly passed to the emd solver</p></li>
</ul>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When dealing with a large number of points, the EMD solver may face
some instabilities, especially when the mass associated to the dummy
point is large. To avoid them, increase the number of dummy points
(allows a smoother repartition of the mass over the points).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>:math:`gamma`</strong> (<em>(dim_a x dim_b) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary returned only if <cite>log</cite> is <cite>True</cite></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">partial_wasserstein2</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">0.3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">partial_wasserstein2</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">m</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id220"><span class="brackets">28</span></dt>
<dd><p>Caffarelli, L. A., &amp; McCann, R. J. (2010) Free boundaries in
optimal transport and Monge-Ampere obstacle problems. Annals of
mathematics, 673-730.</p>
</dd>
<dt class="label" id="id221"><span class="brackets">29</span></dt>
<dd><p>Chapel, L., Alaya, M., Gasso, G. (2019). “Partial Gromov-
Wasserstein with Applications on Positive-Unlabeled Learning”.
arXiv preprint arXiv:2002.08276.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="ot.partial.partial_wasserstein_lagrange">
<code class="sig-prename descclassname">ot.partial.</code><code class="sig-name descname">partial_wasserstein_lagrange</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="n">reg_m</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">nb_dummies</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">log</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ot/partial.html#partial_wasserstein_lagrange"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ot.partial.partial_wasserstein_lagrange" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the partial optimal transport problem for the quadratic cost
and returns the OT plan</p>
<p>The function considers the following problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \arg\min_\gamma &lt;\gamma,(M-\lambda)&gt;_F\\\begin{split}s.t.
     \gamma\geq 0 \\
     \gamma 1 \leq a\\
     \gamma^T 1 \leq b\\
     1^T \gamma^T 1 = m \leq \min\{\|a\|_1, \|b\|_1\}\end{split}\end{aligned}\end{align} \]</div>
<p>or equivalently (see Chizat, L., Peyré, G., Schmitzer, B., &amp; Vialard, F. X.
(2018). An interpolating distance between optimal transport and Fisher–Rao
metrics. Foundations of Computational Mathematics, 18(1), 1-44.)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\gamma = \arg\min_\gamma &lt;\gamma,M&gt;_F  + \sqrt(\lambda/2)
(\|\gamma 1 - a\|_1 + \|\gamma^T 1 - b\|_1)\\\begin{split}s.t.
     \gamma\geq 0 \\\end{split}\end{aligned}\end{align} \]</div>
<p>where :</p>
<ul class="simple">
<li><p>M is the metric cost matrix</p></li>
<li><p>a and b are source and target unbalanced distributions</p></li>
<li><p><span class="math notranslate nohighlight">\(\lambda\)</span> is the lagragian cost. Tuning its value allows attaining
a given mass to be transported m</p></li>
</ul>
<p>The formulation of the problem has been proposed in <a href="#id283"><span class="problematic" id="id222">[28]_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>,</em><em>)</em>) – Unnormalized histogram of dimension dim_a</p></li>
<li><p><strong>b</strong> (<em>np.ndarray</em><em> (</em><em>dim_b</em><em>,</em><em>)</em>) – Unnormalized histograms of dimension dim_b</p></li>
<li><p><strong>M</strong> (<em>np.ndarray</em><em> (</em><em>dim_a</em><em>, </em><em>dim_b</em><em>)</em>) – cost matrix for the quadratic cost</p></li>
<li><p><strong>reg_m</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Lagragian cost</p></li>
<li><p><strong>nb_dummies</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default:1</em>) – number of reservoir points to be added (to avoid numerical
instabilities, increase its value if an error is raised)</p></li>
<li><p><strong>log</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – record log if True</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – parameters can be directly passed to the emd solver</p></li>
<li><p><strong>warning::</strong> (<em>.</em>) – When dealing with a large number of points, the EMD solver may face
some instabilities, especially when the mass associated to the dummy
point is large. To avoid them, increase the number of dummy points
(allows a smoother repartition of the mass over the points).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>gamma</strong> (<em>(dim_a x dim_b) ndarray</em>) – Optimal transportation matrix for the given parameters</p></li>
<li><p><strong>log</strong> (<em>dict</em>) – log dictionary returned only if <cite>log</cite> is <cite>True</cite></p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="p">[</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="p">[</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">partial_wasserstein_lagrange</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">M</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">array([[0.1, 0. ],</span>
<span class="go">       [0. , 0.1]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">partial_wasserstein_lagrange</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">reg_m</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">array([[0.1, 0. ],</span>
<span class="go">       [0. , 0. ]])</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id223"><span class="brackets">28</span></dt>
<dd><p>Caffarelli, L. A., &amp; McCann, R. J. (2010) Free boundaries in
optimal transport and Monge-Ampere obstacle problems. Annals of
mathematics, 673-730.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ot.partial.partial_wasserstein" title="ot.partial.partial_wasserstein"><code class="xref py py-func docutils literal notranslate"><span class="pre">ot.partial.partial_wasserstein()</span></code></a></dt><dd><p>Partial Wasserstein with fixed mass</p>
</dd>
</dl>
</div>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="auto_examples/index.html" class="btn btn-neutral float-right" title="POT Examples" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="quickstart.html" class="btn btn-neutral float-left" title="Quick start guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016-2019, Rémi Flamary, Nicolas Courty

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>